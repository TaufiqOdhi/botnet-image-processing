{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mengubah dataset menjadi gambar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "base_dataset_dir = '/mnt/Windows/Users/taufi/MyFile/Projects/datasets/N-BaIoT'\n",
    "base_generated_image_dir = 'generated_image'\n",
    "\n",
    "n_image_channel = 3\n",
    "\n",
    "# for height of image\n",
    "chunk_size_1 = 102\n",
    "chunk_size_2 = 51\n",
    "\n",
    "benign_file_name = '1.benign.csv'\n",
    "mirai_file_name = '1.mirai.ack.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### untuk dataset benign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MI_dir_L5_weight</th>\n",
       "      <th>MI_dir_L5_mean</th>\n",
       "      <th>MI_dir_L5_variance</th>\n",
       "      <th>MI_dir_L3_weight</th>\n",
       "      <th>MI_dir_L3_mean</th>\n",
       "      <th>MI_dir_L3_variance</th>\n",
       "      <th>MI_dir_L1_weight</th>\n",
       "      <th>MI_dir_L1_mean</th>\n",
       "      <th>MI_dir_L1_variance</th>\n",
       "      <th>MI_dir_L0.1_weight</th>\n",
       "      <th>...</th>\n",
       "      <th>HpHp_L0.1_covariance</th>\n",
       "      <th>HpHp_L0.1_pcc</th>\n",
       "      <th>HpHp_L0.01_weight</th>\n",
       "      <th>HpHp_L0.01_mean</th>\n",
       "      <th>HpHp_L0.01_std</th>\n",
       "      <th>HpHp_L0.01_magnitude</th>\n",
       "      <th>HpHp_L0.01_radius</th>\n",
       "      <th>HpHp_L0.01_covariance</th>\n",
       "      <th>HpHp_L0.01_pcc</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.319895</td>\n",
       "      <td>344.262695</td>\n",
       "      <td>4.710446</td>\n",
       "      <td>344.262695</td>\n",
       "      <td>2.218830e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.857879</td>\n",
       "      <td>360.458980</td>\n",
       "      <td>3.578934e+01</td>\n",
       "      <td>1.912127</td>\n",
       "      <td>360.275733</td>\n",
       "      <td>3.592397e+01</td>\n",
       "      <td>1.969807</td>\n",
       "      <td>360.091968</td>\n",
       "      <td>35.991542</td>\n",
       "      <td>1.996939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.318264</td>\n",
       "      <td>347.703087</td>\n",
       "      <td>9.034660</td>\n",
       "      <td>347.703087</td>\n",
       "      <td>8.162508e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.680223</td>\n",
       "      <td>172.140917</td>\n",
       "      <td>1.848745e+04</td>\n",
       "      <td>1.793580</td>\n",
       "      <td>182.560279</td>\n",
       "      <td>1.892818e+04</td>\n",
       "      <td>1.925828</td>\n",
       "      <td>193.165753</td>\n",
       "      <td>19153.795810</td>\n",
       "      <td>1.992323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49543</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>1.820000e-12</td>\n",
       "      <td>1.000009</td>\n",
       "      <td>101.999633</td>\n",
       "      <td>0.015405</td>\n",
       "      <td>2.270210</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.570000e-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.218824</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>144.249783</td>\n",
       "      <td>1.820000e-12</td>\n",
       "      <td>5.970000e-23</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49544</th>\n",
       "      <td>1.999976</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.999986</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>1.820000e-12</td>\n",
       "      <td>2.000004</td>\n",
       "      <td>101.999816</td>\n",
       "      <td>0.007702</td>\n",
       "      <td>3.270209</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.580000e-44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.218838</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>144.249783</td>\n",
       "      <td>3.640000e-12</td>\n",
       "      <td>-1.100000e-29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49545</th>\n",
       "      <td>2.999872</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>3.640000e-12</td>\n",
       "      <td>2.999923</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>1.820000e-12</td>\n",
       "      <td>2.999983</td>\n",
       "      <td>101.999878</td>\n",
       "      <td>0.005135</td>\n",
       "      <td>4.270206</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.330000e-45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.179949</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>144.249783</td>\n",
       "      <td>5.140000e-12</td>\n",
       "      <td>8.230000e-29</td>\n",
       "      <td>2.260000e-17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49546</th>\n",
       "      <td>3.999664</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>3.640000e-12</td>\n",
       "      <td>3.999798</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.999942</td>\n",
       "      <td>101.999908</td>\n",
       "      <td>0.003851</td>\n",
       "      <td>5.270200</td>\n",
       "      <td>...</td>\n",
       "      <td>4.980000e-69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.219537</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>144.249783</td>\n",
       "      <td>1.820000e-12</td>\n",
       "      <td>5.960000e-29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49547</th>\n",
       "      <td>4.997694</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>3.640000e-12</td>\n",
       "      <td>4.998617</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>1.820000e-12</td>\n",
       "      <td>4.999548</td>\n",
       "      <td>101.999927</td>\n",
       "      <td>0.003081</td>\n",
       "      <td>6.270148</td>\n",
       "      <td>...</td>\n",
       "      <td>7.450000e-39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.219212</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>144.249783</td>\n",
       "      <td>2.570000e-12</td>\n",
       "      <td>2.920000e-26</td>\n",
       "      <td>1.600000e-14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49548 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MI_dir_L5_weight  MI_dir_L5_mean  MI_dir_L5_variance  MI_dir_L3_weight  \\\n",
       "0              1.000000       60.000000        0.000000e+00          1.000000   \n",
       "1              1.000000      354.000000        0.000000e+00          1.000000   \n",
       "2              1.857879      360.458980        3.578934e+01          1.912127   \n",
       "3              1.000000      337.000000        0.000000e+00          1.000000   \n",
       "4              1.680223      172.140917        1.848745e+04          1.793580   \n",
       "...                 ...             ...                 ...               ...   \n",
       "49543          1.000000      102.000000        0.000000e+00          1.000000   \n",
       "49544          1.999976      102.000000        0.000000e+00          1.999986   \n",
       "49545          2.999872      102.000000        3.640000e-12          2.999923   \n",
       "49546          3.999664      102.000000        3.640000e-12          3.999798   \n",
       "49547          4.997694      102.000000        3.640000e-12          4.998617   \n",
       "\n",
       "       MI_dir_L3_mean  MI_dir_L3_variance  MI_dir_L1_weight  MI_dir_L1_mean  \\\n",
       "0           60.000000        0.000000e+00          1.000000       60.000000   \n",
       "1          354.000000        0.000000e+00          1.000000      354.000000   \n",
       "2          360.275733        3.592397e+01          1.969807      360.091968   \n",
       "3          337.000000        0.000000e+00          1.000000      337.000000   \n",
       "4          182.560279        1.892818e+04          1.925828      193.165753   \n",
       "...               ...                 ...               ...             ...   \n",
       "49543      102.000000        1.820000e-12          1.000009      101.999633   \n",
       "49544      102.000000        1.820000e-12          2.000004      101.999816   \n",
       "49545      102.000000        1.820000e-12          2.999983      101.999878   \n",
       "49546      102.000000        0.000000e+00          3.999942      101.999908   \n",
       "49547      102.000000        1.820000e-12          4.999548      101.999927   \n",
       "\n",
       "       MI_dir_L1_variance  MI_dir_L0.1_weight  ...  HpHp_L0.1_covariance  \\\n",
       "0                0.000000            1.000000  ...          0.000000e+00   \n",
       "1                0.000000            1.000000  ...          0.000000e+00   \n",
       "2               35.991542            1.996939  ...          0.000000e+00   \n",
       "3                0.000000            1.000000  ...          0.000000e+00   \n",
       "4            19153.795810            1.992323  ...          0.000000e+00   \n",
       "...                   ...                 ...  ...                   ...   \n",
       "49543            0.015405            2.270210  ...         -1.570000e-30   \n",
       "49544            0.007702            3.270209  ...         -1.580000e-44   \n",
       "49545            0.005135            4.270206  ...         -8.330000e-45   \n",
       "49546            0.003851            5.270200  ...          4.980000e-69   \n",
       "49547            0.003081            6.270148  ...          7.450000e-39   \n",
       "\n",
       "       HpHp_L0.1_pcc  HpHp_L0.01_weight  HpHp_L0.01_mean  HpHp_L0.01_std  \\\n",
       "0                0.0           1.000000        60.000000        0.000000   \n",
       "1                0.0           5.319895       344.262695        4.710446   \n",
       "2                0.0           6.318264       347.703087        9.034660   \n",
       "3                0.0           1.000000       337.000000        0.000000   \n",
       "4                0.0           1.000000        60.000000        0.000000   \n",
       "...              ...                ...              ...             ...   \n",
       "49543            0.0           4.218824       102.000000        0.000000   \n",
       "49544            0.0           4.218838       102.000000        0.000000   \n",
       "49545            0.0           4.179949       102.000000        0.000002   \n",
       "49546            0.0           4.219537       102.000000        0.000001   \n",
       "49547            0.0           4.219212       102.000000        0.000001   \n",
       "\n",
       "       HpHp_L0.01_magnitude  HpHp_L0.01_radius  HpHp_L0.01_covariance  \\\n",
       "0                 60.000000       0.000000e+00           0.000000e+00   \n",
       "1                344.262695       2.218830e+01           0.000000e+00   \n",
       "2                347.703087       8.162508e+01           0.000000e+00   \n",
       "3                337.000000       0.000000e+00           0.000000e+00   \n",
       "4                 60.000000       0.000000e+00           0.000000e+00   \n",
       "...                     ...                ...                    ...   \n",
       "49543            144.249783       1.820000e-12           5.970000e-23   \n",
       "49544            144.249783       3.640000e-12          -1.100000e-29   \n",
       "49545            144.249783       5.140000e-12           8.230000e-29   \n",
       "49546            144.249783       1.820000e-12           5.960000e-29   \n",
       "49547            144.249783       2.570000e-12           2.920000e-26   \n",
       "\n",
       "       HpHp_L0.01_pcc  y  \n",
       "0        0.000000e+00  0  \n",
       "1        0.000000e+00  0  \n",
       "2        0.000000e+00  0  \n",
       "3        0.000000e+00  0  \n",
       "4        0.000000e+00  0  \n",
       "...               ... ..  \n",
       "49543    0.000000e+00  0  \n",
       "49544    0.000000e+00  0  \n",
       "49545    2.260000e-17  0  \n",
       "49546    0.000000e+00  0  \n",
       "49547    1.600000e-14  0  \n",
       "\n",
       "[49548 rows x 116 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_benign = pd.read_csv(f'{base_dataset_dir}/{benign_file_name}')\n",
    "\n",
    "# raw data frame\n",
    "df_benign[\"y\"]=0\n",
    "df_benign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MI_dir_L5_weight</th>\n",
       "      <th>MI_dir_L3_weight</th>\n",
       "      <th>MI_dir_L1_weight</th>\n",
       "      <th>MI_dir_L0.1_weight</th>\n",
       "      <th>MI_dir_L0.01_weight</th>\n",
       "      <th>H_L5_weight</th>\n",
       "      <th>H_L3_weight</th>\n",
       "      <th>H_L1_weight</th>\n",
       "      <th>H_L0.1_weight</th>\n",
       "      <th>H_L0.01_weight</th>\n",
       "      <th>...</th>\n",
       "      <th>HH_jit_L5_weight</th>\n",
       "      <th>HH_jit_L3_weight</th>\n",
       "      <th>HH_jit_L1_weight</th>\n",
       "      <th>HH_jit_L0.1_weight</th>\n",
       "      <th>HH_jit_L0.01_weight</th>\n",
       "      <th>HpHp_L5_weight</th>\n",
       "      <th>HpHp_L3_weight</th>\n",
       "      <th>HpHp_L1_weight</th>\n",
       "      <th>HpHp_L0.1_weight</th>\n",
       "      <th>HpHp_L0.01_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000032</td>\n",
       "      <td>1.031757</td>\n",
       "      <td>2.597515</td>\n",
       "      <td>5.319895</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000032</td>\n",
       "      <td>1.031757</td>\n",
       "      <td>2.597515</td>\n",
       "      <td>5.319895</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000032</td>\n",
       "      <td>1.031757</td>\n",
       "      <td>2.597515</td>\n",
       "      <td>5.319895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.857879</td>\n",
       "      <td>1.912127</td>\n",
       "      <td>1.969807</td>\n",
       "      <td>1.996939</td>\n",
       "      <td>1.999693</td>\n",
       "      <td>1.857879</td>\n",
       "      <td>1.912156</td>\n",
       "      <td>2.000605</td>\n",
       "      <td>3.589564</td>\n",
       "      <td>6.318264</td>\n",
       "      <td>...</td>\n",
       "      <td>1.857879</td>\n",
       "      <td>1.912156</td>\n",
       "      <td>2.000605</td>\n",
       "      <td>3.589564</td>\n",
       "      <td>6.318264</td>\n",
       "      <td>1.857879</td>\n",
       "      <td>1.912156</td>\n",
       "      <td>2.000605</td>\n",
       "      <td>3.589564</td>\n",
       "      <td>6.318264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.680223</td>\n",
       "      <td>1.793580</td>\n",
       "      <td>1.925828</td>\n",
       "      <td>1.992323</td>\n",
       "      <td>1.999230</td>\n",
       "      <td>1.680223</td>\n",
       "      <td>1.793580</td>\n",
       "      <td>1.925828</td>\n",
       "      <td>1.992323</td>\n",
       "      <td>1.999230</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49543</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000009</td>\n",
       "      <td>2.270210</td>\n",
       "      <td>29.219393</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000009</td>\n",
       "      <td>2.270210</td>\n",
       "      <td>29.219393</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.071582</td>\n",
       "      <td>4.218824</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.071582</td>\n",
       "      <td>4.218824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49544</th>\n",
       "      <td>1.999976</td>\n",
       "      <td>1.999986</td>\n",
       "      <td>2.000004</td>\n",
       "      <td>3.270209</td>\n",
       "      <td>30.219392</td>\n",
       "      <td>1.999976</td>\n",
       "      <td>1.999986</td>\n",
       "      <td>2.000004</td>\n",
       "      <td>3.270209</td>\n",
       "      <td>30.219392</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.071585</td>\n",
       "      <td>4.218838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.071585</td>\n",
       "      <td>4.218838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49545</th>\n",
       "      <td>2.999872</td>\n",
       "      <td>2.999923</td>\n",
       "      <td>2.999983</td>\n",
       "      <td>4.270206</td>\n",
       "      <td>31.219389</td>\n",
       "      <td>2.999872</td>\n",
       "      <td>2.999923</td>\n",
       "      <td>2.999983</td>\n",
       "      <td>4.270206</td>\n",
       "      <td>31.219389</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.071590</td>\n",
       "      <td>4.179949</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.071590</td>\n",
       "      <td>4.179949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49546</th>\n",
       "      <td>3.999664</td>\n",
       "      <td>3.999798</td>\n",
       "      <td>3.999942</td>\n",
       "      <td>5.270200</td>\n",
       "      <td>32.219384</td>\n",
       "      <td>3.999664</td>\n",
       "      <td>3.999798</td>\n",
       "      <td>3.999942</td>\n",
       "      <td>5.270200</td>\n",
       "      <td>32.219384</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.071658</td>\n",
       "      <td>4.219537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.071658</td>\n",
       "      <td>4.219537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49547</th>\n",
       "      <td>4.997694</td>\n",
       "      <td>4.998617</td>\n",
       "      <td>4.999548</td>\n",
       "      <td>6.270148</td>\n",
       "      <td>33.219353</td>\n",
       "      <td>4.997694</td>\n",
       "      <td>4.998617</td>\n",
       "      <td>4.999548</td>\n",
       "      <td>6.270148</td>\n",
       "      <td>33.219353</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.071641</td>\n",
       "      <td>4.219212</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.071641</td>\n",
       "      <td>4.219212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49548 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MI_dir_L5_weight  MI_dir_L3_weight  MI_dir_L1_weight  \\\n",
       "0              1.000000          1.000000          1.000000   \n",
       "1              1.000000          1.000000          1.000000   \n",
       "2              1.857879          1.912127          1.969807   \n",
       "3              1.000000          1.000000          1.000000   \n",
       "4              1.680223          1.793580          1.925828   \n",
       "...                 ...               ...               ...   \n",
       "49543          1.000000          1.000000          1.000009   \n",
       "49544          1.999976          1.999986          2.000004   \n",
       "49545          2.999872          2.999923          2.999983   \n",
       "49546          3.999664          3.999798          3.999942   \n",
       "49547          4.997694          4.998617          4.999548   \n",
       "\n",
       "       MI_dir_L0.1_weight  MI_dir_L0.01_weight  H_L5_weight  H_L3_weight  \\\n",
       "0                1.000000             1.000000     1.000000     1.000000   \n",
       "1                1.000000             1.000000     1.000000     1.000032   \n",
       "2                1.996939             1.999693     1.857879     1.912156   \n",
       "3                1.000000             1.000000     1.000000     1.000000   \n",
       "4                1.992323             1.999230     1.680223     1.793580   \n",
       "...                   ...                  ...          ...          ...   \n",
       "49543            2.270210            29.219393     1.000000     1.000000   \n",
       "49544            3.270209            30.219392     1.999976     1.999986   \n",
       "49545            4.270206            31.219389     2.999872     2.999923   \n",
       "49546            5.270200            32.219384     3.999664     3.999798   \n",
       "49547            6.270148            33.219353     4.997694     4.998617   \n",
       "\n",
       "       H_L1_weight  H_L0.1_weight  H_L0.01_weight  ...  HH_jit_L5_weight  \\\n",
       "0         1.000000       1.000000        1.000000  ...          1.000000   \n",
       "1         1.031757       2.597515        5.319895  ...          1.000000   \n",
       "2         2.000605       3.589564        6.318264  ...          1.857879   \n",
       "3         1.000000       1.000000        1.000000  ...          1.000000   \n",
       "4         1.925828       1.992323        1.999230  ...          1.000000   \n",
       "...            ...            ...             ...  ...               ...   \n",
       "49543     1.000009       2.270210       29.219393  ...          1.000000   \n",
       "49544     2.000004       3.270209       30.219392  ...          1.000000   \n",
       "49545     2.999983       4.270206       31.219389  ...          1.000000   \n",
       "49546     3.999942       5.270200       32.219384  ...          1.000000   \n",
       "49547     4.999548       6.270148       33.219353  ...          1.000000   \n",
       "\n",
       "       HH_jit_L3_weight  HH_jit_L1_weight  HH_jit_L0.1_weight  \\\n",
       "0              1.000000          1.000000            1.000000   \n",
       "1              1.000032          1.031757            2.597515   \n",
       "2              1.912156          2.000605            3.589564   \n",
       "3              1.000000          1.000000            1.000000   \n",
       "4              1.000000          1.000000            1.000000   \n",
       "...                 ...               ...                 ...   \n",
       "49543          1.000000          1.000000            1.071582   \n",
       "49544          1.000000          1.000000            1.071585   \n",
       "49545          1.000000          1.000000            1.071590   \n",
       "49546          1.000000          1.000000            1.071658   \n",
       "49547          1.000000          1.000000            1.071641   \n",
       "\n",
       "       HH_jit_L0.01_weight  HpHp_L5_weight  HpHp_L3_weight  HpHp_L1_weight  \\\n",
       "0                 1.000000        1.000000        1.000000        1.000000   \n",
       "1                 5.319895        1.000000        1.000032        1.031757   \n",
       "2                 6.318264        1.857879        1.912156        2.000605   \n",
       "3                 1.000000        1.000000        1.000000        1.000000   \n",
       "4                 1.000000        1.000000        1.000000        1.000000   \n",
       "...                    ...             ...             ...             ...   \n",
       "49543             4.218824        1.000000        1.000000        1.000000   \n",
       "49544             4.218838        1.000000        1.000000        1.000000   \n",
       "49545             4.179949        1.000000        1.000000        1.000000   \n",
       "49546             4.219537        1.000000        1.000000        1.000000   \n",
       "49547             4.219212        1.000000        1.000000        1.000000   \n",
       "\n",
       "       HpHp_L0.1_weight  HpHp_L0.01_weight  \n",
       "0              1.000000           1.000000  \n",
       "1              2.597515           5.319895  \n",
       "2              3.589564           6.318264  \n",
       "3              1.000000           1.000000  \n",
       "4              1.000000           1.000000  \n",
       "...                 ...                ...  \n",
       "49543          1.071582           4.218824  \n",
       "49544          1.071585           4.218838  \n",
       "49545          1.071590           4.179949  \n",
       "49546          1.071658           4.219537  \n",
       "49547          1.071641           4.219212  \n",
       "\n",
       "[49548 rows x 25 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only pick \"weight\" columns\n",
    "\n",
    "df_benign_weight = df_benign[df_benign.columns[df_benign.columns.str.contains('weight')].to_list()]\n",
    "df_benign_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_benign_pics_1, list_benign_pics_2 = np.array_split(df_benign_weight, 2)\n",
    "list_benign_pics_1 = np.array_split(list_benign_pics_1.to_numpy()[:-(len(list_benign_pics_1) % chunk_size_1)], len(list_benign_pics_1) // chunk_size_1)\n",
    "list_benign_pics_2 = np.array_split(list_benign_pics_2.to_numpy()[:-(len(list_benign_pics_2) % chunk_size_2)], len(list_benign_pics_2) // chunk_size_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242\n",
      "485\n"
     ]
    }
   ],
   "source": [
    "print(len(list_benign_pics_1))\n",
    "print(len(list_benign_pics_2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### contoh gambar yang dihasilkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39m# SelectKBest\u001b[39;00m\n\u001b[1;32m      6\u001b[0m selector \u001b[39m=\u001b[39m SelectKBest(score_func\u001b[39m=\u001b[39mf_classif, k\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m) \u001b[39m# f_classif for classification, f_regression for regression\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m X_new \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39mfit_transform(X, y)\n\u001b[1;32m      9\u001b[0m \u001b[39m# SelectPercentile\u001b[39;00m\n\u001b[1;32m     10\u001b[0m selector \u001b[39m=\u001b[39m SelectPercentile(score_func\u001b[39m=\u001b[39mmutual_info_classif, percentile\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m) \u001b[39m# mutual_info_classif for classification, mutual_info_regression for regression\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif, SelectPercentile, mutual_info_classif\n",
    "\n",
    "arr = list_benign_pics_1[0]\n",
    "\n",
    "# SelectKBest\n",
    "selector = SelectKBest(score_func=f_classif, k=5) # f_classif for classification, f_regression for regression\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "# SelectPercentile\n",
    "selector = SelectPercentile(score_func=mutual_info_classif, percentile=50) # mutual_info_classif for classification, mutual_info_regression for regression\n",
    "X_new = selector.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABkAAAAiCAIAAAAlNuVaAAADQ0lEQVR4nM3Sa0iTYRQH8OOablNz5jQvI8c0UamJKyNM7TlRaS2STJ0WXaQiSu1CFynDpmWQWll20bKMct4jo5tOq5FhZeWtTO3mHRK7vegCnba3DwaC9cqbGPTp/+V3zvOcwwEAAACKTEz+f43+0FBnnM4HoIjWtiZIChTpSXC4LTpEkUX1ycK7T7iYbtl5KS3ABv/kgC1k4YARup8Mf9Oi+UE4z2rfWWUYiJPUayg4kSYBGY7TY/poIl1pmfbAQJN1d963tWh+EKcN0EbkGQZiiJkr9TMCVH+K89lWYo773n6UfFxsjyOQhQO2kIX7X89iHIVfnraulXfoydHHDoPxN4dIuO2hVs86A2mHyAtwoo0mW46leTUP0cxwlPvHI1LACNqX+Q66vOaiJOqiyS6dMUapor2uL+ShUfHq1IOfeVjf3dluauDhiOOsHYapsmGoFQ/DfjVoK8zFlfpCV13hQHVeqcrOzvn5qdPH/TSq+J0Po/YFcpbZO87hTnn1IfgR16FSX+iqA3+aZN7XHk5PpUnjmbgyj7c0CVOdeDV7iCYcO9GDLJppN78nR7ZZ5tphc6Sg8Gx4R1ZDkNXZ/BrZ9ns+k6uvCZKDtUFXI8uSPaIHhbh7r6zicgMfvdXhpbOCzHBHSU3iF4UFVpULjkW9FOLWqmTwiB4U4sQsfxyFiki55Z0EimSfH8hyj+sj3iUvTt8Uc1EJ33t9lidaYawu6VZYswgZ4Sg3YT9jSOb7cpvR1MsBiuTkHj+ylEORNd387ib7PuIZsf2iJsQKV0+qm1UbZosjDsaGnvm1ZgAUKe/65j8HKFIvP1NfR1HEQ5+Tmzt/ElalJEZa7OL9ciwg61Gz3awXf9tkIHxfU81yE5qsaRQ0aVcZ4bmAdK9axVTM47vnpCjFyMJBTopSzP7lMXMchUkb7wfuduFhmeDclZkHeLh+wZ6eSqUA1eAdu2SbwgG/mjVeVSklyAhHuQn7GUMy31dIuaRnhbMQYwZCeW37hRgGxMm1yBL79aEtEQpHvNEE1qRIiiMOxob/fPmMeTdweld/kgjXf22V+5eKcFpgcXxCgTVK1PaOpi5STJVcyZxX5IwsHGTOK3L+y1GY8iduqu4c2ng35wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=25x34>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mencoba salah satu untuk list beign pic 1\n",
    "\n",
    "arr = list_benign_pics_1[0]\n",
    "\n",
    "\n",
    "\n",
    "a = arr.size/3\n",
    "a = a/25\n",
    "\n",
    "Image.fromarray(arr.reshape(int(a), 25, 3), mode='RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABkAAAARCAIAAACn2JBZAAACJUlEQVR4nGNY1HXtkfl/dgd/+01/2/+zOxQlrTpYy8XhkNbQ/4qTVcjhtsDrZd+/2TsQoY5h2fdv9g4MDAwMDAwf7NHptQIts7+ofrS/99so4OwDAQLqGIhViFDX7GEgs+gZvwMjq2njkQ/8Dv8jmkOPMwk4XGLQSzddzSLm0CnJlVtc7YBbIZo67BYzfLAPO/uW673qR/uSSp3Hp/C4kIA6BpwKn7q+rNn/UdhBO33xv4Lvwg4asTZbyphEHNK3b5JbwCLlYHa3YkbRbwckdQz4FeJy4ZJp3k3vVD/aq3cE6ZyGu5BohWQYOM/yHbcswwd7sbXnH55sYnd4wur8eJU4ZrLBoo4Bq8LUuyfYGRg+2Cv/Cf52qeyrfcg2h0zXRnUC6hhwKzTY4cLAwPDBnvtFmcAr50/2BZ+3pC21FHVY/mcrGwPDB/ub0r8fyDB8sN824eeDTdUf7HUY1okmpEzkcOjSvfTvGas9boUE1MWevcLAsKn6g/28bZMmaSj8tzcryBIJ2KSBVSE2dRjpC+YV2d//ii45fLLvF+Q5ws0nheHl5St3ZnEzfLBf+uLr0yvz/9tPcVrjoLrKBk0d0QoR9KYEs34D1Y/2JSGdDkk7oMmBkeGDPYPAQYhCKL2p4PvdC++T+P2Tvc7w6V+45/HhAIo8LnUM4g6KFy7//2/Pd+BBzdP//+2vfdHxYmRgcIhcGD/55Xl2h75kWwnVVbYORKgDAABY0UwyCTODAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=25x17>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mencoba salah satu untuk list beign pic 2\n",
    "\n",
    "arr = list_benign_pics_2[0]\n",
    "a = arr.size/3\n",
    "a = a/25\n",
    "\n",
    "Image.fromarray(arr.reshape(int(a), 25, 3), mode='RGB')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### menyimpan gambar yang dihasilkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_image_dir = f'{base_generated_image_dir}/{benign_file_name[:-4]}'\n",
    "os.system(f'mkdir {benign_image_dir}')\n",
    "for i  in range(len(list_benign_pics_1)):\n",
    "    a = list_benign_pics_1[i].size // 3\n",
    "    a = a // 25\n",
    "    Image.fromarray(list_benign_pics_1[i].reshape(a, 25, 3), mode='RGB').save(f'{benign_image_dir}/pic1_{i}.png')\n",
    "\n",
    "for i  in range(len(list_benign_pics_2)):\n",
    "    a = list_benign_pics_2[i].size/3\n",
    "    a = a/25\n",
    "    Image.fromarray(list_benign_pics_2[i].reshape(a, 25, 3), mode='RGB').save(f'{benign_image_dir}/pic2_{i}.png')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### untuk dataset mirai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MI_dir_L5_weight</th>\n",
       "      <th>MI_dir_L5_mean</th>\n",
       "      <th>MI_dir_L5_variance</th>\n",
       "      <th>MI_dir_L3_weight</th>\n",
       "      <th>MI_dir_L3_mean</th>\n",
       "      <th>MI_dir_L3_variance</th>\n",
       "      <th>MI_dir_L1_weight</th>\n",
       "      <th>MI_dir_L1_mean</th>\n",
       "      <th>MI_dir_L1_variance</th>\n",
       "      <th>MI_dir_L0.1_weight</th>\n",
       "      <th>...</th>\n",
       "      <th>HpHp_L0.1_covariance</th>\n",
       "      <th>HpHp_L0.1_pcc</th>\n",
       "      <th>HpHp_L0.01_weight</th>\n",
       "      <th>HpHp_L0.01_mean</th>\n",
       "      <th>HpHp_L0.01_std</th>\n",
       "      <th>HpHp_L0.01_magnitude</th>\n",
       "      <th>HpHp_L0.01_radius</th>\n",
       "      <th>HpHp_L0.01_covariance</th>\n",
       "      <th>HpHp_L0.01_pcc</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.996585</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>5.820766e-11</td>\n",
       "      <td>1.997950</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>5.820766e-11</td>\n",
       "      <td>1.999316</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.999932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.958989</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.975291</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>5.820766e-11</td>\n",
       "      <td>2.991729</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>5.820766e-11</td>\n",
       "      <td>2.999171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.958979</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.975285</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.991727</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>1.164153e-10</td>\n",
       "      <td>3.999171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.914189</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>1.164153e-10</td>\n",
       "      <td>4.948239</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>5.820766e-11</td>\n",
       "      <td>4.982654</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>5.820766e-11</td>\n",
       "      <td>4.998261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102190</th>\n",
       "      <td>149.120959</td>\n",
       "      <td>250.662823</td>\n",
       "      <td>6.012308e+04</td>\n",
       "      <td>230.049109</td>\n",
       "      <td>306.976684</td>\n",
       "      <td>6.397272e+04</td>\n",
       "      <td>650.841283</td>\n",
       "      <td>368.905880</td>\n",
       "      <td>6.088352e+04</td>\n",
       "      <td>6295.232865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102191</th>\n",
       "      <td>150.118494</td>\n",
       "      <td>249.392741</td>\n",
       "      <td>5.996312e+04</td>\n",
       "      <td>231.046828</td>\n",
       "      <td>305.907738</td>\n",
       "      <td>6.395870e+04</td>\n",
       "      <td>651.839132</td>\n",
       "      <td>368.431981</td>\n",
       "      <td>6.093628e+04</td>\n",
       "      <td>6296.230784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102192</th>\n",
       "      <td>151.117874</td>\n",
       "      <td>248.139463</td>\n",
       "      <td>5.980211e+04</td>\n",
       "      <td>232.046256</td>\n",
       "      <td>304.848002</td>\n",
       "      <td>6.394254e+04</td>\n",
       "      <td>652.838593</td>\n",
       "      <td>367.959533</td>\n",
       "      <td>6.098844e+04</td>\n",
       "      <td>6297.230264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102193</th>\n",
       "      <td>150.827162</td>\n",
       "      <td>246.892078</td>\n",
       "      <td>5.963874e+04</td>\n",
       "      <td>231.855059</td>\n",
       "      <td>303.791963</td>\n",
       "      <td>6.392421e+04</td>\n",
       "      <td>652.719572</td>\n",
       "      <td>367.487723</td>\n",
       "      <td>6.104007e+04</td>\n",
       "      <td>6297.150032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102194</th>\n",
       "      <td>151.162744</td>\n",
       "      <td>245.655715</td>\n",
       "      <td>5.947375e+04</td>\n",
       "      <td>232.241702</td>\n",
       "      <td>302.742229</td>\n",
       "      <td>6.390378e+04</td>\n",
       "      <td>653.143489</td>\n",
       "      <td>367.016942</td>\n",
       "      <td>6.109116e+04</td>\n",
       "      <td>6297.594031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102195 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MI_dir_L5_weight  MI_dir_L5_mean  MI_dir_L5_variance  \\\n",
       "0               1.000000      566.000000        0.000000e+00   \n",
       "1               1.996585      566.000000        5.820766e-11   \n",
       "2               2.958989      566.000000        0.000000e+00   \n",
       "3               3.958979      566.000000        0.000000e+00   \n",
       "4               4.914189      566.000000        1.164153e-10   \n",
       "...                  ...             ...                 ...   \n",
       "102190        149.120959      250.662823        6.012308e+04   \n",
       "102191        150.118494      249.392741        5.996312e+04   \n",
       "102192        151.117874      248.139463        5.980211e+04   \n",
       "102193        150.827162      246.892078        5.963874e+04   \n",
       "102194        151.162744      245.655715        5.947375e+04   \n",
       "\n",
       "        MI_dir_L3_weight  MI_dir_L3_mean  MI_dir_L3_variance  \\\n",
       "0               1.000000      566.000000        0.000000e+00   \n",
       "1               1.997950      566.000000        5.820766e-11   \n",
       "2               2.975291      566.000000        5.820766e-11   \n",
       "3               3.975285      566.000000        0.000000e+00   \n",
       "4               4.948239      566.000000        5.820766e-11   \n",
       "...                  ...             ...                 ...   \n",
       "102190        230.049109      306.976684        6.397272e+04   \n",
       "102191        231.046828      305.907738        6.395870e+04   \n",
       "102192        232.046256      304.848002        6.394254e+04   \n",
       "102193        231.855059      303.791963        6.392421e+04   \n",
       "102194        232.241702      302.742229        6.390378e+04   \n",
       "\n",
       "        MI_dir_L1_weight  MI_dir_L1_mean  MI_dir_L1_variance  \\\n",
       "0               1.000000      566.000000        0.000000e+00   \n",
       "1               1.999316      566.000000        0.000000e+00   \n",
       "2               2.991729      566.000000        5.820766e-11   \n",
       "3               3.991727      566.000000        1.164153e-10   \n",
       "4               4.982654      566.000000        5.820766e-11   \n",
       "...                  ...             ...                 ...   \n",
       "102190        650.841283      368.905880        6.088352e+04   \n",
       "102191        651.839132      368.431981        6.093628e+04   \n",
       "102192        652.838593      367.959533        6.098844e+04   \n",
       "102193        652.719572      367.487723        6.104007e+04   \n",
       "102194        653.143489      367.016942        6.109116e+04   \n",
       "\n",
       "        MI_dir_L0.1_weight  ...  HpHp_L0.1_covariance  HpHp_L0.1_pcc  \\\n",
       "0                 1.000000  ...                   0.0            0.0   \n",
       "1                 1.999932  ...                   0.0            0.0   \n",
       "2                 2.999171  ...                   0.0            0.0   \n",
       "3                 3.999171  ...                   0.0            0.0   \n",
       "4                 4.998261  ...                   0.0            0.0   \n",
       "...                    ...  ...                   ...            ...   \n",
       "102190         6295.232865  ...                   0.0            0.0   \n",
       "102191         6296.230784  ...                   0.0            0.0   \n",
       "102192         6297.230264  ...                   0.0            0.0   \n",
       "102193         6297.150032  ...                   0.0            0.0   \n",
       "102194         6297.594031  ...                   0.0            0.0   \n",
       "\n",
       "        HpHp_L0.01_weight  HpHp_L0.01_mean  HpHp_L0.01_std  \\\n",
       "0                     1.0            566.0             0.0   \n",
       "1                     1.0            566.0             0.0   \n",
       "2                     1.0            566.0             0.0   \n",
       "3                     1.0            566.0             0.0   \n",
       "4                     1.0            566.0             0.0   \n",
       "...                   ...              ...             ...   \n",
       "102190                1.0             60.0             0.0   \n",
       "102191                1.0             60.0             0.0   \n",
       "102192                1.0             60.0             0.0   \n",
       "102193                1.0             60.0             0.0   \n",
       "102194                1.0             60.0             0.0   \n",
       "\n",
       "        HpHp_L0.01_magnitude  HpHp_L0.01_radius  HpHp_L0.01_covariance  \\\n",
       "0                      566.0                0.0                    0.0   \n",
       "1                      566.0                0.0                    0.0   \n",
       "2                      566.0                0.0                    0.0   \n",
       "3                      566.0                0.0                    0.0   \n",
       "4                      566.0                0.0                    0.0   \n",
       "...                      ...                ...                    ...   \n",
       "102190                  60.0                0.0                    0.0   \n",
       "102191                  60.0                0.0                    0.0   \n",
       "102192                  60.0                0.0                    0.0   \n",
       "102193                  60.0                0.0                    0.0   \n",
       "102194                  60.0                0.0                    0.0   \n",
       "\n",
       "        HpHp_L0.01_pcc  y  \n",
       "0                  0.0  1  \n",
       "1                  0.0  1  \n",
       "2                  0.0  1  \n",
       "3                  0.0  1  \n",
       "4                  0.0  1  \n",
       "...                ... ..  \n",
       "102190             0.0  1  \n",
       "102191             0.0  1  \n",
       "102192             0.0  1  \n",
       "102193             0.0  1  \n",
       "102194             0.0  1  \n",
       "\n",
       "[102195 rows x 116 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mirai = pd.read_csv(f'{base_dataset_dir}/{mirai_file_name}')\n",
    "\n",
    "# raw data frame\n",
    "df_mirai['y']=1\n",
    "df_mirai\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_benign, df_mirai])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MI_dir_L5_weight</th>\n",
       "      <th>MI_dir_L5_mean</th>\n",
       "      <th>MI_dir_L5_variance</th>\n",
       "      <th>MI_dir_L3_weight</th>\n",
       "      <th>MI_dir_L3_mean</th>\n",
       "      <th>MI_dir_L3_variance</th>\n",
       "      <th>MI_dir_L1_weight</th>\n",
       "      <th>MI_dir_L1_mean</th>\n",
       "      <th>MI_dir_L1_variance</th>\n",
       "      <th>MI_dir_L0.1_weight</th>\n",
       "      <th>...</th>\n",
       "      <th>HpHp_L0.1_covariance</th>\n",
       "      <th>HpHp_L0.1_pcc</th>\n",
       "      <th>HpHp_L0.01_weight</th>\n",
       "      <th>HpHp_L0.01_mean</th>\n",
       "      <th>HpHp_L0.01_std</th>\n",
       "      <th>HpHp_L0.01_magnitude</th>\n",
       "      <th>HpHp_L0.01_radius</th>\n",
       "      <th>HpHp_L0.01_covariance</th>\n",
       "      <th>HpHp_L0.01_pcc</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.319895</td>\n",
       "      <td>344.262695</td>\n",
       "      <td>4.710446</td>\n",
       "      <td>344.262695</td>\n",
       "      <td>22.188299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.857879</td>\n",
       "      <td>360.458980</td>\n",
       "      <td>35.789338</td>\n",
       "      <td>1.912127</td>\n",
       "      <td>360.275733</td>\n",
       "      <td>35.923972</td>\n",
       "      <td>1.969807</td>\n",
       "      <td>360.091968</td>\n",
       "      <td>35.991542</td>\n",
       "      <td>1.996939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.318264</td>\n",
       "      <td>347.703087</td>\n",
       "      <td>9.034660</td>\n",
       "      <td>347.703087</td>\n",
       "      <td>81.625077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.680223</td>\n",
       "      <td>172.140917</td>\n",
       "      <td>18487.448750</td>\n",
       "      <td>1.793580</td>\n",
       "      <td>182.560279</td>\n",
       "      <td>18928.175300</td>\n",
       "      <td>1.925828</td>\n",
       "      <td>193.165753</td>\n",
       "      <td>19153.795810</td>\n",
       "      <td>1.992323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102190</th>\n",
       "      <td>149.120959</td>\n",
       "      <td>250.662823</td>\n",
       "      <td>60123.076387</td>\n",
       "      <td>230.049109</td>\n",
       "      <td>306.976684</td>\n",
       "      <td>63972.719668</td>\n",
       "      <td>650.841283</td>\n",
       "      <td>368.905880</td>\n",
       "      <td>60883.517934</td>\n",
       "      <td>6295.232865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102191</th>\n",
       "      <td>150.118494</td>\n",
       "      <td>249.392741</td>\n",
       "      <td>59963.116605</td>\n",
       "      <td>231.046828</td>\n",
       "      <td>305.907738</td>\n",
       "      <td>63958.699818</td>\n",
       "      <td>651.839132</td>\n",
       "      <td>368.431981</td>\n",
       "      <td>60936.280851</td>\n",
       "      <td>6296.230784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102192</th>\n",
       "      <td>151.117874</td>\n",
       "      <td>248.139463</td>\n",
       "      <td>59802.110713</td>\n",
       "      <td>232.046256</td>\n",
       "      <td>304.848002</td>\n",
       "      <td>63942.544929</td>\n",
       "      <td>652.838593</td>\n",
       "      <td>367.959533</td>\n",
       "      <td>60988.435072</td>\n",
       "      <td>6297.230264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102193</th>\n",
       "      <td>150.827162</td>\n",
       "      <td>246.892078</td>\n",
       "      <td>59638.742689</td>\n",
       "      <td>231.855059</td>\n",
       "      <td>303.791963</td>\n",
       "      <td>63924.212054</td>\n",
       "      <td>652.719572</td>\n",
       "      <td>367.487723</td>\n",
       "      <td>61040.073390</td>\n",
       "      <td>6297.150032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102194</th>\n",
       "      <td>151.162744</td>\n",
       "      <td>245.655715</td>\n",
       "      <td>59473.747270</td>\n",
       "      <td>232.241702</td>\n",
       "      <td>302.742229</td>\n",
       "      <td>63903.778137</td>\n",
       "      <td>653.143489</td>\n",
       "      <td>367.016942</td>\n",
       "      <td>61091.155377</td>\n",
       "      <td>6297.594031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151743 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MI_dir_L5_weight  MI_dir_L5_mean  MI_dir_L5_variance  \\\n",
       "0               1.000000       60.000000            0.000000   \n",
       "1               1.000000      354.000000            0.000000   \n",
       "2               1.857879      360.458980           35.789338   \n",
       "3               1.000000      337.000000            0.000000   \n",
       "4               1.680223      172.140917        18487.448750   \n",
       "...                  ...             ...                 ...   \n",
       "102190        149.120959      250.662823        60123.076387   \n",
       "102191        150.118494      249.392741        59963.116605   \n",
       "102192        151.117874      248.139463        59802.110713   \n",
       "102193        150.827162      246.892078        59638.742689   \n",
       "102194        151.162744      245.655715        59473.747270   \n",
       "\n",
       "        MI_dir_L3_weight  MI_dir_L3_mean  MI_dir_L3_variance  \\\n",
       "0               1.000000       60.000000            0.000000   \n",
       "1               1.000000      354.000000            0.000000   \n",
       "2               1.912127      360.275733           35.923972   \n",
       "3               1.000000      337.000000            0.000000   \n",
       "4               1.793580      182.560279        18928.175300   \n",
       "...                  ...             ...                 ...   \n",
       "102190        230.049109      306.976684        63972.719668   \n",
       "102191        231.046828      305.907738        63958.699818   \n",
       "102192        232.046256      304.848002        63942.544929   \n",
       "102193        231.855059      303.791963        63924.212054   \n",
       "102194        232.241702      302.742229        63903.778137   \n",
       "\n",
       "        MI_dir_L1_weight  MI_dir_L1_mean  MI_dir_L1_variance  \\\n",
       "0               1.000000       60.000000            0.000000   \n",
       "1               1.000000      354.000000            0.000000   \n",
       "2               1.969807      360.091968           35.991542   \n",
       "3               1.000000      337.000000            0.000000   \n",
       "4               1.925828      193.165753        19153.795810   \n",
       "...                  ...             ...                 ...   \n",
       "102190        650.841283      368.905880        60883.517934   \n",
       "102191        651.839132      368.431981        60936.280851   \n",
       "102192        652.838593      367.959533        60988.435072   \n",
       "102193        652.719572      367.487723        61040.073390   \n",
       "102194        653.143489      367.016942        61091.155377   \n",
       "\n",
       "        MI_dir_L0.1_weight  ...  HpHp_L0.1_covariance  HpHp_L0.1_pcc  \\\n",
       "0                 1.000000  ...                   0.0            0.0   \n",
       "1                 1.000000  ...                   0.0            0.0   \n",
       "2                 1.996939  ...                   0.0            0.0   \n",
       "3                 1.000000  ...                   0.0            0.0   \n",
       "4                 1.992323  ...                   0.0            0.0   \n",
       "...                    ...  ...                   ...            ...   \n",
       "102190         6295.232865  ...                   0.0            0.0   \n",
       "102191         6296.230784  ...                   0.0            0.0   \n",
       "102192         6297.230264  ...                   0.0            0.0   \n",
       "102193         6297.150032  ...                   0.0            0.0   \n",
       "102194         6297.594031  ...                   0.0            0.0   \n",
       "\n",
       "        HpHp_L0.01_weight  HpHp_L0.01_mean  HpHp_L0.01_std  \\\n",
       "0                1.000000        60.000000        0.000000   \n",
       "1                5.319895       344.262695        4.710446   \n",
       "2                6.318264       347.703087        9.034660   \n",
       "3                1.000000       337.000000        0.000000   \n",
       "4                1.000000        60.000000        0.000000   \n",
       "...                   ...              ...             ...   \n",
       "102190           1.000000        60.000000        0.000000   \n",
       "102191           1.000000        60.000000        0.000000   \n",
       "102192           1.000000        60.000000        0.000000   \n",
       "102193           1.000000        60.000000        0.000000   \n",
       "102194           1.000000        60.000000        0.000000   \n",
       "\n",
       "        HpHp_L0.01_magnitude  HpHp_L0.01_radius  HpHp_L0.01_covariance  \\\n",
       "0                  60.000000           0.000000                    0.0   \n",
       "1                 344.262695          22.188299                    0.0   \n",
       "2                 347.703087          81.625077                    0.0   \n",
       "3                 337.000000           0.000000                    0.0   \n",
       "4                  60.000000           0.000000                    0.0   \n",
       "...                      ...                ...                    ...   \n",
       "102190             60.000000           0.000000                    0.0   \n",
       "102191             60.000000           0.000000                    0.0   \n",
       "102192             60.000000           0.000000                    0.0   \n",
       "102193             60.000000           0.000000                    0.0   \n",
       "102194             60.000000           0.000000                    0.0   \n",
       "\n",
       "        HpHp_L0.01_pcc  y  \n",
       "0                  0.0  0  \n",
       "1                  0.0  0  \n",
       "2                  0.0  0  \n",
       "3                  0.0  0  \n",
       "4                  0.0  0  \n",
       "...                ... ..  \n",
       "102190             0.0  1  \n",
       "102191             0.0  1  \n",
       "102192             0.0  1  \n",
       "102193             0.0  1  \n",
       "102194             0.0  1  \n",
       "\n",
       "[151743 rows x 116 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MI_dir_L5_weight         0.938040\n",
       "MI_dir_L5_mean           0.849536\n",
       "MI_dir_L5_variance       0.869956\n",
       "MI_dir_L3_weight         0.971800\n",
       "MI_dir_L3_mean           0.924745\n",
       "                           ...   \n",
       "HpHp_L0.01_magnitude     0.525163\n",
       "HpHp_L0.01_radius        0.027143\n",
       "HpHp_L0.01_covariance    0.021607\n",
       "HpHp_L0.01_pcc           0.057696\n",
       "y                        1.000000\n",
       "Name: y, Length: 116, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "corr = df_all.corr()\n",
    "\n",
    "\n",
    "corr[\"y\"].describe()\n",
    "abs_corr_y = corr[\"y\"].apply(lambda x: abs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MI_dir_L5_weight        0.938040\n",
       "MI_dir_L5_mean          0.849536\n",
       "MI_dir_L5_variance      0.869956\n",
       "MI_dir_L3_weight        0.971800\n",
       "MI_dir_L3_mean          0.924745\n",
       "                          ...   \n",
       "HpHp_L0.1_magnitude     0.525143\n",
       "HpHp_L0.01_weight       0.930495\n",
       "HpHp_L0.01_mean         0.577620\n",
       "HpHp_L0.01_magnitude    0.525163\n",
       "y                       1.000000\n",
       "Name: y, Length: 62, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thr = 0.5\n",
    "abs_corr_y_thresholded = abs_corr_y[abs_corr_y>thr]\n",
    "abs_corr_y_thresholded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MI_dir_L5_weight',\n",
       " 'MI_dir_L5_mean',\n",
       " 'MI_dir_L5_variance',\n",
       " 'MI_dir_L3_weight',\n",
       " 'MI_dir_L3_mean',\n",
       " 'MI_dir_L3_variance',\n",
       " 'MI_dir_L1_weight',\n",
       " 'MI_dir_L1_mean',\n",
       " 'MI_dir_L1_variance',\n",
       " 'MI_dir_L0.1_weight',\n",
       " 'MI_dir_L0.1_mean',\n",
       " 'MI_dir_L0.1_variance',\n",
       " 'MI_dir_L0.01_weight',\n",
       " 'MI_dir_L0.01_mean',\n",
       " 'MI_dir_L0.01_variance',\n",
       " 'H_L5_weight',\n",
       " 'H_L5_mean',\n",
       " 'H_L5_variance',\n",
       " 'H_L3_weight',\n",
       " 'H_L3_mean',\n",
       " 'H_L3_variance',\n",
       " 'H_L1_weight',\n",
       " 'H_L1_mean',\n",
       " 'H_L1_variance',\n",
       " 'H_L0.1_weight',\n",
       " 'H_L0.1_mean',\n",
       " 'H_L0.1_variance',\n",
       " 'H_L0.01_weight',\n",
       " 'H_L0.01_mean',\n",
       " 'H_L0.01_variance',\n",
       " 'HH_L5_weight',\n",
       " 'HH_L5_mean',\n",
       " 'HH_L5_magnitude',\n",
       " 'HH_L3_weight',\n",
       " 'HH_L3_mean',\n",
       " 'HH_L3_magnitude',\n",
       " 'HH_L1_weight',\n",
       " 'HH_L1_mean',\n",
       " 'HH_L1_magnitude',\n",
       " 'HH_L0.1_weight',\n",
       " 'HH_L0.1_mean',\n",
       " 'HH_L0.1_magnitude',\n",
       " 'HH_L0.01_weight',\n",
       " 'HH_L0.01_mean',\n",
       " 'HH_L0.01_magnitude',\n",
       " 'HH_jit_L5_weight',\n",
       " 'HH_jit_L3_weight',\n",
       " 'HH_jit_L1_weight',\n",
       " 'HH_jit_L0.1_weight',\n",
       " 'HH_jit_L0.01_weight',\n",
       " 'HpHp_L5_mean',\n",
       " 'HpHp_L5_magnitude',\n",
       " 'HpHp_L3_mean',\n",
       " 'HpHp_L3_magnitude',\n",
       " 'HpHp_L1_mean',\n",
       " 'HpHp_L1_magnitude',\n",
       " 'HpHp_L0.1_mean',\n",
       " 'HpHp_L0.1_magnitude',\n",
       " 'HpHp_L0.01_weight',\n",
       " 'HpHp_L0.01_mean',\n",
       " 'HpHp_L0.01_magnitude',\n",
       " 'y']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_selected = abs_corr_y_thresholded.index.to_list()\n",
    "feature_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MI_dir_L5_weight</th>\n",
       "      <th>MI_dir_L3_weight</th>\n",
       "      <th>MI_dir_L1_weight</th>\n",
       "      <th>MI_dir_L0.1_weight</th>\n",
       "      <th>MI_dir_L0.01_weight</th>\n",
       "      <th>H_L5_weight</th>\n",
       "      <th>H_L3_weight</th>\n",
       "      <th>H_L1_weight</th>\n",
       "      <th>H_L0.1_weight</th>\n",
       "      <th>H_L0.01_weight</th>\n",
       "      <th>...</th>\n",
       "      <th>HH_jit_L5_weight</th>\n",
       "      <th>HH_jit_L3_weight</th>\n",
       "      <th>HH_jit_L1_weight</th>\n",
       "      <th>HH_jit_L0.1_weight</th>\n",
       "      <th>HH_jit_L0.01_weight</th>\n",
       "      <th>HpHp_L5_weight</th>\n",
       "      <th>HpHp_L3_weight</th>\n",
       "      <th>HpHp_L1_weight</th>\n",
       "      <th>HpHp_L0.1_weight</th>\n",
       "      <th>HpHp_L0.01_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.996585</td>\n",
       "      <td>1.997950</td>\n",
       "      <td>1.999316</td>\n",
       "      <td>1.999932</td>\n",
       "      <td>1.999993</td>\n",
       "      <td>1.996585</td>\n",
       "      <td>1.997950</td>\n",
       "      <td>1.999316</td>\n",
       "      <td>1.999932</td>\n",
       "      <td>1.999993</td>\n",
       "      <td>...</td>\n",
       "      <td>1.996585</td>\n",
       "      <td>1.997950</td>\n",
       "      <td>1.999316</td>\n",
       "      <td>1.999932</td>\n",
       "      <td>1.999993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.958989</td>\n",
       "      <td>2.975291</td>\n",
       "      <td>2.991729</td>\n",
       "      <td>2.999171</td>\n",
       "      <td>2.999917</td>\n",
       "      <td>2.958989</td>\n",
       "      <td>2.975291</td>\n",
       "      <td>2.991729</td>\n",
       "      <td>2.999171</td>\n",
       "      <td>2.999917</td>\n",
       "      <td>...</td>\n",
       "      <td>2.958989</td>\n",
       "      <td>2.975291</td>\n",
       "      <td>2.991729</td>\n",
       "      <td>2.999171</td>\n",
       "      <td>2.999917</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.958979</td>\n",
       "      <td>3.975285</td>\n",
       "      <td>3.991727</td>\n",
       "      <td>3.999171</td>\n",
       "      <td>3.999917</td>\n",
       "      <td>3.958979</td>\n",
       "      <td>3.975285</td>\n",
       "      <td>3.991727</td>\n",
       "      <td>3.999171</td>\n",
       "      <td>3.999917</td>\n",
       "      <td>...</td>\n",
       "      <td>3.958979</td>\n",
       "      <td>3.975285</td>\n",
       "      <td>3.991727</td>\n",
       "      <td>3.999171</td>\n",
       "      <td>3.999917</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.914189</td>\n",
       "      <td>4.948239</td>\n",
       "      <td>4.982654</td>\n",
       "      <td>4.998261</td>\n",
       "      <td>4.999826</td>\n",
       "      <td>4.914189</td>\n",
       "      <td>4.948239</td>\n",
       "      <td>4.982654</td>\n",
       "      <td>4.998261</td>\n",
       "      <td>4.999826</td>\n",
       "      <td>...</td>\n",
       "      <td>4.914189</td>\n",
       "      <td>4.948239</td>\n",
       "      <td>4.982654</td>\n",
       "      <td>4.998261</td>\n",
       "      <td>4.999826</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102190</th>\n",
       "      <td>149.120959</td>\n",
       "      <td>230.049109</td>\n",
       "      <td>650.841283</td>\n",
       "      <td>6295.232865</td>\n",
       "      <td>52631.999391</td>\n",
       "      <td>149.120959</td>\n",
       "      <td>230.049109</td>\n",
       "      <td>650.841283</td>\n",
       "      <td>6295.232865</td>\n",
       "      <td>52631.999391</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102191</th>\n",
       "      <td>150.118494</td>\n",
       "      <td>231.046828</td>\n",
       "      <td>651.839132</td>\n",
       "      <td>6296.230784</td>\n",
       "      <td>52632.997652</td>\n",
       "      <td>150.118494</td>\n",
       "      <td>231.046828</td>\n",
       "      <td>651.839132</td>\n",
       "      <td>6296.230784</td>\n",
       "      <td>52632.997652</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102192</th>\n",
       "      <td>151.117874</td>\n",
       "      <td>232.046256</td>\n",
       "      <td>652.838593</td>\n",
       "      <td>6297.230264</td>\n",
       "      <td>52633.997217</td>\n",
       "      <td>151.117874</td>\n",
       "      <td>232.046256</td>\n",
       "      <td>652.838593</td>\n",
       "      <td>6297.230264</td>\n",
       "      <td>52633.997217</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102193</th>\n",
       "      <td>150.827162</td>\n",
       "      <td>231.855059</td>\n",
       "      <td>652.719572</td>\n",
       "      <td>6297.150032</td>\n",
       "      <td>52634.094259</td>\n",
       "      <td>150.827162</td>\n",
       "      <td>231.855059</td>\n",
       "      <td>652.719572</td>\n",
       "      <td>6297.150032</td>\n",
       "      <td>52634.094259</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102194</th>\n",
       "      <td>151.162744</td>\n",
       "      <td>232.241702</td>\n",
       "      <td>653.143489</td>\n",
       "      <td>6297.594031</td>\n",
       "      <td>52634.629513</td>\n",
       "      <td>151.162744</td>\n",
       "      <td>232.241702</td>\n",
       "      <td>653.143489</td>\n",
       "      <td>6297.594031</td>\n",
       "      <td>52634.629513</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102195 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MI_dir_L5_weight  MI_dir_L3_weight  MI_dir_L1_weight  \\\n",
       "0               1.000000          1.000000          1.000000   \n",
       "1               1.996585          1.997950          1.999316   \n",
       "2               2.958989          2.975291          2.991729   \n",
       "3               3.958979          3.975285          3.991727   \n",
       "4               4.914189          4.948239          4.982654   \n",
       "...                  ...               ...               ...   \n",
       "102190        149.120959        230.049109        650.841283   \n",
       "102191        150.118494        231.046828        651.839132   \n",
       "102192        151.117874        232.046256        652.838593   \n",
       "102193        150.827162        231.855059        652.719572   \n",
       "102194        151.162744        232.241702        653.143489   \n",
       "\n",
       "        MI_dir_L0.1_weight  MI_dir_L0.01_weight  H_L5_weight  H_L3_weight  \\\n",
       "0                 1.000000             1.000000     1.000000     1.000000   \n",
       "1                 1.999932             1.999993     1.996585     1.997950   \n",
       "2                 2.999171             2.999917     2.958989     2.975291   \n",
       "3                 3.999171             3.999917     3.958979     3.975285   \n",
       "4                 4.998261             4.999826     4.914189     4.948239   \n",
       "...                    ...                  ...          ...          ...   \n",
       "102190         6295.232865         52631.999391   149.120959   230.049109   \n",
       "102191         6296.230784         52632.997652   150.118494   231.046828   \n",
       "102192         6297.230264         52633.997217   151.117874   232.046256   \n",
       "102193         6297.150032         52634.094259   150.827162   231.855059   \n",
       "102194         6297.594031         52634.629513   151.162744   232.241702   \n",
       "\n",
       "        H_L1_weight  H_L0.1_weight  H_L0.01_weight  ...  HH_jit_L5_weight  \\\n",
       "0          1.000000       1.000000        1.000000  ...          1.000000   \n",
       "1          1.999316       1.999932        1.999993  ...          1.996585   \n",
       "2          2.991729       2.999171        2.999917  ...          2.958989   \n",
       "3          3.991727       3.999171        3.999917  ...          3.958979   \n",
       "4          4.982654       4.998261        4.999826  ...          4.914189   \n",
       "...             ...            ...             ...  ...               ...   \n",
       "102190   650.841283    6295.232865    52631.999391  ...          1.000000   \n",
       "102191   651.839132    6296.230784    52632.997652  ...          1.000000   \n",
       "102192   652.838593    6297.230264    52633.997217  ...          1.000000   \n",
       "102193   652.719572    6297.150032    52634.094259  ...          1.000000   \n",
       "102194   653.143489    6297.594031    52634.629513  ...          1.000000   \n",
       "\n",
       "        HH_jit_L3_weight  HH_jit_L1_weight  HH_jit_L0.1_weight  \\\n",
       "0               1.000000          1.000000            1.000000   \n",
       "1               1.997950          1.999316            1.999932   \n",
       "2               2.975291          2.991729            2.999171   \n",
       "3               3.975285          3.991727            3.999171   \n",
       "4               4.948239          4.982654            4.998261   \n",
       "...                  ...               ...                 ...   \n",
       "102190          1.000000          1.000000            1.000000   \n",
       "102191          1.000000          1.000000            1.000000   \n",
       "102192          1.000000          1.000000            1.000000   \n",
       "102193          1.000000          1.000000            1.000000   \n",
       "102194          1.000000          1.000000            1.000000   \n",
       "\n",
       "        HH_jit_L0.01_weight  HpHp_L5_weight  HpHp_L3_weight  HpHp_L1_weight  \\\n",
       "0                  1.000000             1.0             1.0             1.0   \n",
       "1                  1.999993             1.0             1.0             1.0   \n",
       "2                  2.999917             1.0             1.0             1.0   \n",
       "3                  3.999917             1.0             1.0             1.0   \n",
       "4                  4.999826             1.0             1.0             1.0   \n",
       "...                     ...             ...             ...             ...   \n",
       "102190             1.000000             1.0             1.0             1.0   \n",
       "102191             1.000000             1.0             1.0             1.0   \n",
       "102192             1.000000             1.0             1.0             1.0   \n",
       "102193             1.000000             1.0             1.0             1.0   \n",
       "102194             1.000000             1.0             1.0             1.0   \n",
       "\n",
       "        HpHp_L0.1_weight  HpHp_L0.01_weight  \n",
       "0                    1.0                1.0  \n",
       "1                    1.0                1.0  \n",
       "2                    1.0                1.0  \n",
       "3                    1.0                1.0  \n",
       "4                    1.0                1.0  \n",
       "...                  ...                ...  \n",
       "102190               1.0                1.0  \n",
       "102191               1.0                1.0  \n",
       "102192               1.0                1.0  \n",
       "102193               1.0                1.0  \n",
       "102194               1.0                1.0  \n",
       "\n",
       "[102195 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only pick \"weight\" columns\n",
    "\n",
    "df_mirai_weight = df_mirai[df_mirai.columns[df_mirai.columns.str.contains('weight')].to_list()]\n",
    "df_mirai_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_mirai_pics_1, list_mirai_pics_2 = np.array_split(df_mirai_weight, 2)\n",
    "\n",
    "list_mirai_pics_1 = np.array_split(list_mirai_pics_1.to_numpy()[:-(len(list_mirai_pics_1) % chunk_size_1)], len(list_mirai_pics_1) // chunk_size_1)\n",
    "list_mirai_pics_2 = np.array_split(list_mirai_pics_2.to_numpy()[:-(len(list_mirai_pics_2) % chunk_size_2)], len(list_mirai_pics_2) // chunk_size_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "1001\n"
     ]
    }
   ],
   "source": [
    "print(len(list_mirai_pics_1))\n",
    "print(len(list_mirai_pics_2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### contoh gambar yang dihasilkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABkAAAAiCAIAAAAlNuVaAAAED0lEQVR4nMXSf1ATZBgH8NcNWHnApNkNGrK2ITENPCEckGwPEGkMZ5ckEGXH5IfJgrglArMQOBUJCDa6ADHhSBwIAp40lEFykMfx40TERclNfpl6R9Blk4Gwtz923e5sO98/uuuv55/Pvc/7veeLEEIIoT9E/838Px/KmlEwqX9i0f6tgatVS1iUZSzU+a1hUTDyROGdGItcijJuGzG2DQkcIoXW3DM/RjajjPA2xVGaaZDJSQlKGqHB0GTaD/RFGvz4W17pHhMN3Kv4xeOYBhaHSCGBQwSQ+DiGtKOBaxfpIKzI5khH6FBahZudF+lwTn9fvsdEB23Q8dPjmA4EDpFCAocskDTKgLKGyVEzIFXm6YgHGSDc4D+2c4EBJiSZ3hZoYsC36xMOjWEG2IQEDpFCa464Xzk3WupPHWZCsbMqvu08E0rKdwlap5mQe12aaVhlwlHFq+zLmAkWZxcd35asLXtYR2tqnZ4q/26Uu2TorhMrvpo6L3jPeHWk9VNmb7e2jLu07yb7pamy5hxa52LulLigkYsDtEZxVuKUev4fhwg2E/dr/PP0mezNLPD6UCe4rmBBwEykuvA2C+IEaMfppyz48q53SwlmAYFDpJDAIQskjdLnO1M98LMHSEqDY+VRbHhh7MhoYR8bOtDGuYfzy2x4SxOWmojZYBMSOEQKrTnifh1TplCd3Diw2/VBqVLOASdDmM/XoxxY7/cJL/gpB/Tq+O4TmAMWR1GboT3VDMO2mGGne+jjSg//gxmvdRn8VJfuLF3IO7v9r/aQcQrvoxSTA92FH6GsTey6d4plcYhgM+lRKG9K+xtqPb651DORqurf/KR96DN4I/ogcrjr5Wzkn0vuep+fHKXAPIhW/bTQac+D7S/Kaq+m8OBMXajw5DAPdDF03a0VHkR/kILMsMDODJcvmmH5cTPcJTHDyAYChyyQNIqPQlNXXRMLCXm7L5g6kkBX4h01GZQPctTQPXss9AokOJY9WcF9YBM+41x7HsiKhDEwONcSLrwlBcBfGJBalwNrGcKzKxNNkPZ98l51xDWr0Joj7pf4lV8Fv3Nj4cBAfQdHngTthVwNzSsf7E+uPJaKroCvxrPkddQPFreuvoMz2sYW8mYccu2Ggu7ZXVuYjOjVL1LnPj4yKdiY4UEtEhfHM4qGf3GR5Rsv87eFG92De1SPwnwbuYfipd4Lee82npDhrd7UIjG6uR/iuG6HS89Iob+8QNvSnQMN2rS9el0TmCp7JaFv/yuKzbnO/0CEUr5JlT6eq5ncWbPP536mn4e3dj7E6WVd+NCWHfq6MVGtV154hX+1/fMcRSLpwulumsE7Ia4RPjeWa0QN7wyHzGZHyjZoVvWVE4/GYuL4FeKCAMdZiuE57m/qQN+aasw0jwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=25x34>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = list_mirai_pics_1[0]\n",
    "a = arr.size/3\n",
    "a = a/25\n",
    "\n",
    "Image.fromarray(arr.reshape(int(a), 25, 3), mode='RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABkAAAARCAIAAACn2JBZAAADf0lEQVR4nGOYZWUx6yFLlEOOiYrwtQNpDqxmbTHL9jc5sDnNz3pWtMOhWLkoekngYwci1DEdzJL0jP9+/El1pZ1rlrvHqozT/9lnCXzUfPjvtGDUtMLTTHo7QueILHjM3iZjT0AdwwaH1GblhQdCbjowMDAwMDB8sCdEH9r8pLfjXqTDvxQ2kR+r0hxa+uT+nNvR5HCb4Ziv27fCHQ4MJy+qzg187IBTIZq65d07Hx50inAo2hbrfros2UF77jcvht6UagdPv5uZnFobHNbv2m9+NuQmVoXY1KG5mAGnVybKHJ8XzxLlUPLvUYrJ3jSHxKslcix7mxyOyW0uKy/a4cBor6GwOfCxA0Id46MUk9tMPEvyTfbqe6bYcM4p3hC53+lkf/sL+RLNw71v/PxlOG7/Z5fi/yc9yeeIO1NitLXNlS0OATccLiStUuyekRYR+GrvMYcXEf4yHAxZEQ4t6Xbzf3YlO/QcmX2cIb/aYX9wQ/9WrQ0Oh8RmCDOEEh8pLNqWsatiOqTdL4due1x6/ZZD0eNjD8IajLsPXld6eu7W0pjsk6cNjwfGVrosjF319pl0sMX+bY8tr6uxO0Qec5p/wHhh43SltCfGgjF+m04zth0PjK3snFAhbXw1edavozaMCoq3mX1XaUu18pavs/ped/xRrvmbPbsvfDvq+kegdRY+dQwbHJ5nC9w1IMErWX2xzc8Mohwkp5g0519Mcyi+FMj370CTgwzTghsvq5JuC3DFmiddDnzskDVPDqJwyVeIwkdCEIUJNy88LdrhEO9m8cP1S0LULvkDwh7pVy8aulw72hIS6nQ+/GwHQ0pttYMcx4L3q7U3OGyJOloSFnrT4VUlg86d2REOTKvELMKWJjv03+Rdgk0dmosZ7RkYDkIEBFDpKYHhr85H3jbodbo+adO0iM+M51WkuYN2MhgaZKQfPJl1NuihmbTGbdZ657gwqDpGcT5fPAr75jvoxjz0SarUnnJZc9u2KSeWuSc9fnU8hLepUVAgS9G47t/pe8u9gl53rXTQjWFIjHC41Xxl7ZquZIcgzvYtbwqrHer+Huzn1d7gsHIdd3soKelr6xUmy8tv94vm97nECfDUhaTtOf/v3Nvpxjm2qr/zDQxfc20OnbVd0LPzqA1Ti/bB/aIW313eF4fUnY0yOv/Pc9307y//qvLGGIo84ZoTCgBwBA6gBwK/HQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=25x17>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = list_mirai_pics_2[0]\n",
    "a = arr.size/3\n",
    "a = a/25\n",
    "\n",
    "Image.fromarray(arr.reshape(int(a), 25, 3), mode='RGB')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### menyimpan gambar yang dihasilkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘generated_image/1.mirai.ack’: File exists\n"
     ]
    }
   ],
   "source": [
    "mirai_image_dir = f'{base_generated_image_dir}/{mirai_file_name[:-4]}'\n",
    "os.system(f'mkdir {mirai_image_dir}')\n",
    "for i in range(len(list_mirai_pics_1)):\n",
    "    a = list_mirai_pics_1[i].size // 3\n",
    "    a = a // 25\n",
    "    Image.fromarray(list_mirai_pics_1[i].reshape(a, 25, 3), mode='RGB').save(f'{mirai_image_dir}/pic1_{i}.png')\n",
    "\n",
    "for i in range(len(list_mirai_pics_2)):\n",
    "    a = list_mirai_pics_2[i].size // 3\n",
    "    a = a // 25\n",
    "    Image.fromarray(list_mirai_pics_2[i].reshape(a, 25, 3), mode='RGB').save(f'{mirai_image_dir}/pic2_{i}.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### untuk semua file dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.mirai.syn.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘generated_image/8.mirai.syn’: File exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.mirai.udp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘generated_image/8.mirai.udp’: File exists\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "tile cannot extend outside image",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m a \u001b[39m=\u001b[39m list_pics_2[j]\u001b[39m.\u001b[39msize \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m n_image_channel\n\u001b[1;32m     23\u001b[0m a \u001b[39m=\u001b[39m a \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m n_features\n\u001b[0;32m---> 24\u001b[0m Image\u001b[39m.\u001b[39;49mfromarray(list_pics_2[j]\u001b[39m.\u001b[39;49mreshape(a, n_features, n_image_channel), mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mRGB\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39msave(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mimage_dir\u001b[39m}\u001b[39;00m\u001b[39m/pic2_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m.png\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/botnet-image-processing/lib/python3.10/site-packages/PIL/Image.py:3103\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3100\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3101\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mtostring()\n\u001b[0;32m-> 3103\u001b[0m \u001b[39mreturn\u001b[39;00m frombuffer(mode, size, obj, \u001b[39m\"\u001b[39;49m\u001b[39mraw\u001b[39;49m\u001b[39m\"\u001b[39;49m, rawmode, \u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/botnet-image-processing/lib/python3.10/site-packages/PIL/Image.py:3027\u001b[0m, in \u001b[0;36mfrombuffer\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   3024\u001b[0m         im\u001b[39m.\u001b[39mreadonly \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   3025\u001b[0m         \u001b[39mreturn\u001b[39;00m im\n\u001b[0;32m-> 3027\u001b[0m \u001b[39mreturn\u001b[39;00m frombytes(mode, size, data, decoder_name, args)\n",
      "File \u001b[0;32m~/anaconda3/envs/botnet-image-processing/lib/python3.10/site-packages/PIL/Image.py:2969\u001b[0m, in \u001b[0;36mfrombytes\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   2966\u001b[0m     args \u001b[39m=\u001b[39m mode\n\u001b[1;32m   2968\u001b[0m im \u001b[39m=\u001b[39m new(mode, size)\n\u001b[0;32m-> 2969\u001b[0m im\u001b[39m.\u001b[39;49mfrombytes(data, decoder_name, args)\n\u001b[1;32m   2970\u001b[0m \u001b[39mreturn\u001b[39;00m im\n",
      "File \u001b[0;32m~/anaconda3/envs/botnet-image-processing/lib/python3.10/site-packages/PIL/Image.py:825\u001b[0m, in \u001b[0;36mImage.frombytes\u001b[0;34m(self, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[39m# unpack data\u001b[39;00m\n\u001b[1;32m    824\u001b[0m d \u001b[39m=\u001b[39m _getdecoder(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode, decoder_name, args)\n\u001b[0;32m--> 825\u001b[0m d\u001b[39m.\u001b[39;49msetimage(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mim)\n\u001b[1;32m    826\u001b[0m s \u001b[39m=\u001b[39m d\u001b[39m.\u001b[39mdecode(data)\n\u001b[1;32m    828\u001b[0m \u001b[39mif\u001b[39;00m s[\u001b[39m0\u001b[39m] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: tile cannot extend outside image"
     ]
    }
   ],
   "source": [
    "list_dir = os.listdir(base_dataset_dir)\n",
    "list_dir.sort()\n",
    "for dataset_file in list_dir[77:-4]:\n",
    "    print(dataset_file)\n",
    "\n",
    "    df = pd.read_csv(f'{base_dataset_dir}/{dataset_file}')\n",
    "    df_weight = df[df.columns[df.columns.str.contains('weight')].to_list()]\n",
    "    n_features = df_weight.shape[1]\n",
    "    list_pics_1, list_pics_2 = np.array_split(df_weight.to_numpy(), 2)\n",
    "    list_pics_1 = np.array_split(list_pics_1[:-(len(list_pics_1) % chunk_size_1)], len(list_pics_1) // chunk_size_1)\n",
    "    list_pics_2 = np.array_split(list_pics_2[:-(len(list_pics_2) % chunk_size_2)], len(list_pics_2) // chunk_size_2)\n",
    "    \n",
    "    image_dir = f'{base_generated_image_dir}/{dataset_file[:-4]}'\n",
    "    os.system(f'mkdir {image_dir}')\n",
    "\n",
    "    for i in range(len(list_pics_1)):\n",
    "        a = list_pics_1[i].size // n_image_channel\n",
    "        a = a // n_features\n",
    "        Image.fromarray(list_pics_1[i].reshape(a, n_features, n_image_channel), mode='RGB').save(f'{image_dir}/pic1_{i}.png')\n",
    "\n",
    "    for j in range(len(list_pics_2)):\n",
    "        a = list_pics_2[j].size // n_image_channel\n",
    "        a = a // n_features\n",
    "        Image.fromarray(list_pics_2[j].reshape(a, n_features, n_image_channel), mode='RGB').save(f'{image_dir}/pic2_{i}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.benign.csv',\n",
       " '1.gafgyt.combo.csv',\n",
       " '1.gafgyt.junk.csv',\n",
       " '1.gafgyt.scan.csv',\n",
       " '1.gafgyt.tcp.csv',\n",
       " '1.gafgyt.udp.csv',\n",
       " '1.mirai.ack.csv',\n",
       " '1.mirai.scan.csv',\n",
       " '1.mirai.syn.csv',\n",
       " '1.mirai.udp.csv',\n",
       " '1.mirai.udpplain.csv',\n",
       " '2.benign.csv',\n",
       " '2.gafgyt.combo.csv',\n",
       " '2.gafgyt.junk.csv',\n",
       " '2.gafgyt.scan.csv',\n",
       " '2.gafgyt.tcp.csv',\n",
       " '2.gafgyt.udp.csv',\n",
       " '2.mirai.ack.csv',\n",
       " '2.mirai.scan.csv',\n",
       " '2.mirai.syn.csv',\n",
       " '2.mirai.udp.csv',\n",
       " '2.mirai.udpplain.csv',\n",
       " '3.benign.csv',\n",
       " '3.gafgyt.combo.csv',\n",
       " '3.gafgyt.junk.csv',\n",
       " '3.gafgyt.scan.csv',\n",
       " '3.gafgyt.tcp.csv',\n",
       " '3.gafgyt.udp.csv',\n",
       " '4.benign.csv',\n",
       " '4.gafgyt.combo.csv',\n",
       " '4.gafgyt.junk.csv',\n",
       " '4.gafgyt.scan.csv',\n",
       " '4.gafgyt.tcp.csv',\n",
       " '4.gafgyt.udp.csv',\n",
       " '4.mirai.ack.csv',\n",
       " '4.mirai.scan.csv',\n",
       " '4.mirai.syn.csv',\n",
       " '4.mirai.udp.csv',\n",
       " '4.mirai.udpplain.csv',\n",
       " '5.benign.csv',\n",
       " '5.gafgyt.combo.csv',\n",
       " '5.gafgyt.junk.csv',\n",
       " '5.gafgyt.scan.csv',\n",
       " '5.gafgyt.tcp.csv',\n",
       " '5.gafgyt.udp.csv',\n",
       " '5.mirai.ack.csv',\n",
       " '5.mirai.scan.csv',\n",
       " '5.mirai.syn.csv',\n",
       " '5.mirai.udp.csv',\n",
       " '5.mirai.udpplain.csv',\n",
       " '6.benign.csv',\n",
       " '6.gafgyt.combo.csv',\n",
       " '6.gafgyt.junk.csv',\n",
       " '6.gafgyt.scan.csv',\n",
       " '6.gafgyt.tcp.csv',\n",
       " '6.gafgyt.udp.csv',\n",
       " '6.mirai.ack.csv',\n",
       " '6.mirai.scan.csv',\n",
       " '6.mirai.syn.csv',\n",
       " '6.mirai.udp.csv',\n",
       " '6.mirai.udpplain.csv',\n",
       " '7.benign.csv',\n",
       " '7.gafgyt.combo.csv',\n",
       " '7.gafgyt.junk.csv',\n",
       " '7.gafgyt.scan.csv',\n",
       " '7.gafgyt.tcp.csv',\n",
       " '7.gafgyt.udp.csv',\n",
       " '8.benign.csv',\n",
       " '8.gafgyt.combo.csv',\n",
       " '8.gafgyt.junk.csv',\n",
       " '8.gafgyt.scan.csv',\n",
       " '8.gafgyt.tcp.csv',\n",
       " '8.gafgyt.udp.csv',\n",
       " '8.mirai.ack.csv',\n",
       " '8.mirai.scan.csv',\n",
       " '8.mirai.syn.csv',\n",
       " '8.mirai.udp.csv',\n",
       " '8.mirai.udpplain.csv',\n",
       " '9.benign.csv',\n",
       " '9.gafgyt.combo.csv',\n",
       " '9.gafgyt.junk.csv',\n",
       " '9.gafgyt.scan.csv',\n",
       " '9.gafgyt.tcp.csv',\n",
       " '9.gafgyt.udp.csv',\n",
       " '9.mirai.ack.csv',\n",
       " '9.mirai.scan.csv',\n",
       " '9.mirai.syn.csv',\n",
       " '9.mirai.udp.csv',\n",
       " '9.mirai.udpplain.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_dir[:-4]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset gambar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 14:32:34.312801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-05 14:32:35.096669: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/odhi/anaconda3/envs/botnet-image-processing/lib/\n",
      "2023-04-05 14:32:35.096746: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/odhi/anaconda3/envs/botnet-image-processing/lib/\n",
      "2023-04-05 14:32:35.096761: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2228 files belonging to 2 classes.\n",
      "Using 1783 files for training.\n",
      "Found 2228 files belonging to 2 classes.\n",
      "Using 445 files for validation.\n",
      "['1.benign', '1.mirai.ack']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 14:32:35.964685: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-05 14:32:35.968702: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-05 14:32:35.968844: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-05 14:32:35.969166: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-05 14:32:35.969556: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-05 14:32:35.969677: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-05 14:32:35.969780: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-05 14:32:36.377249: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-05 14:32:36.377416: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-05 14:32:36.377536: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-05 14:32:36.377634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6111 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 2\n",
    "label_mode = 'binary'\n",
    "dataset_directory = './generated_image/train_data'\n",
    "img_height = 1\n",
    "img_width = 1\n",
    "validation_split = 0.2\n",
    "seed = 111\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=dataset_directory,\n",
    "    validation_split=validation_split,\n",
    "    subset='training',\n",
    "    seed=seed,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    label_mode=label_mode\n",
    ")\n",
    "\n",
    "validation_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=dataset_directory,\n",
    "    validation_split=validation_split,\n",
    "    subset='validation',\n",
    "    seed=seed,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    label_mode=label_mode\n",
    ")\n",
    "\n",
    "print(train_ds.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=892>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_ds."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pembuatan model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  1/892 [..............................] - ETA: 20:25 - loss: 72.5941 - accuracy: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - true_negatives: 1.0000 - true_positives: 0.0000e+00 - false_negatives: 1.0000 - false_positives: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 14:32:51.319781: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x1d193b90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-04-05 14:32:51.319828: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3070 Laptop GPU, Compute Capability 8.6\n",
      "2023-04-05 14:32:51.326675: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-04-05 14:32:51.421381: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "892/892 [==============================] - 3s 2ms/step - loss: 47.4972 - accuracy: 0.2810 - precision: 0.4444 - recall: 0.2521 - true_negatives: 197.0000 - true_positives: 304.0000 - false_negatives: 902.0000 - false_positives: 380.0000 - val_loss: 21.7786 - val_accuracy: 0.4247 - val_precision: 0.5666 - val_recall: 0.5627 - val_true_negatives: 23.0000 - val_true_positives: 166.0000 - val_false_negatives: 129.0000 - val_false_positives: 127.0000\n",
      "Epoch 2/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 13.0296 - accuracy: 0.4941 - precision: 0.6169 - recall: 0.6650 - true_negatives: 79.0000 - true_positives: 802.0000 - false_negatives: 404.0000 - false_positives: 498.0000 - val_loss: 4.3555 - val_accuracy: 0.5528 - val_precision: 0.6412 - val_recall: 0.7390 - val_true_negatives: 28.0000 - val_true_positives: 218.0000 - val_false_negatives: 77.0000 - val_false_positives: 122.0000\n",
      "Epoch 3/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 1.0232 - accuracy: 0.7914 - precision: 0.8150 - recall: 0.8947 - true_negatives: 332.0000 - true_positives: 1079.0000 - false_negatives: 127.0000 - false_positives: 245.0000 - val_loss: 0.2829 - val_accuracy: 0.8809 - val_precision: 0.8712 - val_recall: 0.9627 - val_true_negatives: 108.0000 - val_true_positives: 284.0000 - val_false_negatives: 11.0000 - val_false_positives: 42.0000\n",
      "Epoch 4/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.2222 - accuracy: 0.9052 - precision: 0.8992 - recall: 0.9685 - true_negatives: 446.0000 - true_positives: 1168.0000 - false_negatives: 38.0000 - false_positives: 131.0000 - val_loss: 0.2738 - val_accuracy: 0.8764 - val_precision: 0.8750 - val_recall: 0.9492 - val_true_negatives: 110.0000 - val_true_positives: 280.0000 - val_false_negatives: 15.0000 - val_false_positives: 40.0000\n",
      "Epoch 5/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.2186 - accuracy: 0.9063 - precision: 0.8999 - recall: 0.9693 - true_negatives: 447.0000 - true_positives: 1169.0000 - false_negatives: 37.0000 - false_positives: 130.0000 - val_loss: 0.2688 - val_accuracy: 0.8831 - val_precision: 0.8693 - val_recall: 0.9695 - val_true_negatives: 107.0000 - val_true_positives: 286.0000 - val_false_negatives: 9.0000 - val_false_positives: 43.0000\n",
      "Epoch 6/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.2202 - accuracy: 0.9047 - precision: 0.8997 - recall: 0.9668 - true_negatives: 447.0000 - true_positives: 1166.0000 - false_negatives: 40.0000 - false_positives: 130.0000 - val_loss: 0.2636 - val_accuracy: 0.8787 - val_precision: 0.8777 - val_recall: 0.9492 - val_true_negatives: 111.0000 - val_true_positives: 280.0000 - val_false_negatives: 15.0000 - val_false_positives: 39.0000\n",
      "Epoch 7/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.2150 - accuracy: 0.9080 - precision: 0.9051 - recall: 0.9652 - true_negatives: 455.0000 - true_positives: 1164.0000 - false_negatives: 42.0000 - false_positives: 122.0000 - val_loss: 0.2570 - val_accuracy: 0.8876 - val_precision: 0.8746 - val_recall: 0.9695 - val_true_negatives: 109.0000 - val_true_positives: 286.0000 - val_false_negatives: 9.0000 - val_false_positives: 41.0000\n",
      "Epoch 8/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.2101 - accuracy: 0.9069 - precision: 0.9050 - recall: 0.9635 - true_negatives: 455.0000 - true_positives: 1162.0000 - false_negatives: 44.0000 - false_positives: 122.0000 - val_loss: 0.2508 - val_accuracy: 0.8854 - val_precision: 0.8836 - val_recall: 0.9525 - val_true_negatives: 113.0000 - val_true_positives: 281.0000 - val_false_negatives: 14.0000 - val_false_positives: 37.0000\n",
      "Epoch 9/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.2104 - accuracy: 0.9108 - precision: 0.9061 - recall: 0.9685 - true_negatives: 456.0000 - true_positives: 1168.0000 - false_negatives: 38.0000 - false_positives: 121.0000 - val_loss: 0.2440 - val_accuracy: 0.8921 - val_precision: 0.8824 - val_recall: 0.9661 - val_true_negatives: 112.0000 - val_true_positives: 285.0000 - val_false_negatives: 10.0000 - val_false_positives: 38.0000\n",
      "Epoch 10/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.2019 - accuracy: 0.9142 - precision: 0.9110 - recall: 0.9677 - true_negatives: 463.0000 - true_positives: 1167.0000 - false_negatives: 39.0000 - false_positives: 114.0000 - val_loss: 0.2482 - val_accuracy: 0.8899 - val_precision: 0.8727 - val_recall: 0.9763 - val_true_negatives: 108.0000 - val_true_positives: 288.0000 - val_false_negatives: 7.0000 - val_false_positives: 42.0000\n",
      "Epoch 11/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.2007 - accuracy: 0.9164 - precision: 0.9158 - recall: 0.9652 - true_negatives: 470.0000 - true_positives: 1164.0000 - false_negatives: 42.0000 - false_positives: 107.0000 - val_loss: 0.2330 - val_accuracy: 0.8966 - val_precision: 0.8879 - val_recall: 0.9661 - val_true_negatives: 114.0000 - val_true_positives: 285.0000 - val_false_negatives: 10.0000 - val_false_positives: 36.0000\n",
      "Epoch 12/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1997 - accuracy: 0.9176 - precision: 0.9133 - recall: 0.9701 - true_negatives: 466.0000 - true_positives: 1170.0000 - false_negatives: 36.0000 - false_positives: 111.0000 - val_loss: 0.2291 - val_accuracy: 0.9011 - val_precision: 0.8934 - val_recall: 0.9661 - val_true_negatives: 116.0000 - val_true_positives: 285.0000 - val_false_negatives: 10.0000 - val_false_positives: 34.0000\n",
      "Epoch 13/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1911 - accuracy: 0.9215 - precision: 0.9197 - recall: 0.9685 - true_negatives: 475.0000 - true_positives: 1168.0000 - false_negatives: 38.0000 - false_positives: 102.0000 - val_loss: 0.2249 - val_accuracy: 0.9011 - val_precision: 0.8984 - val_recall: 0.9593 - val_true_negatives: 118.0000 - val_true_positives: 283.0000 - val_false_negatives: 12.0000 - val_false_positives: 32.0000\n",
      "Epoch 14/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1883 - accuracy: 0.9232 - precision: 0.9239 - recall: 0.9660 - true_negatives: 481.0000 - true_positives: 1165.0000 - false_negatives: 41.0000 - false_positives: 96.0000 - val_loss: 0.2225 - val_accuracy: 0.8989 - val_precision: 0.8906 - val_recall: 0.9661 - val_true_negatives: 115.0000 - val_true_positives: 285.0000 - val_false_negatives: 10.0000 - val_false_positives: 35.0000\n",
      "Epoch 15/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1883 - accuracy: 0.9226 - precision: 0.9205 - recall: 0.9693 - true_negatives: 476.0000 - true_positives: 1169.0000 - false_negatives: 37.0000 - false_positives: 101.0000 - val_loss: 0.2177 - val_accuracy: 0.9034 - val_precision: 0.8962 - val_recall: 0.9661 - val_true_negatives: 117.0000 - val_true_positives: 285.0000 - val_false_negatives: 10.0000 - val_false_positives: 33.0000\n",
      "Epoch 16/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1822 - accuracy: 0.9209 - precision: 0.9230 - recall: 0.9635 - true_negatives: 480.0000 - true_positives: 1162.0000 - false_negatives: 44.0000 - false_positives: 97.0000 - val_loss: 0.2141 - val_accuracy: 0.9034 - val_precision: 0.8962 - val_recall: 0.9661 - val_true_negatives: 117.0000 - val_true_positives: 285.0000 - val_false_negatives: 10.0000 - val_false_positives: 33.0000\n",
      "Epoch 17/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1819 - accuracy: 0.9243 - precision: 0.9274 - recall: 0.9635 - true_negatives: 486.0000 - true_positives: 1162.0000 - false_negatives: 44.0000 - false_positives: 91.0000 - val_loss: 0.2104 - val_accuracy: 0.9146 - val_precision: 0.9159 - val_recall: 0.9593 - val_true_negatives: 124.0000 - val_true_positives: 283.0000 - val_false_negatives: 12.0000 - val_false_positives: 26.0000\n",
      "Epoch 18/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1784 - accuracy: 0.9299 - precision: 0.9314 - recall: 0.9677 - true_negatives: 491.0000 - true_positives: 1167.0000 - false_negatives: 39.0000 - false_positives: 86.0000 - val_loss: 0.2088 - val_accuracy: 0.9191 - val_precision: 0.9191 - val_recall: 0.9627 - val_true_negatives: 125.0000 - val_true_positives: 284.0000 - val_false_negatives: 11.0000 - val_false_positives: 25.0000\n",
      "Epoch 19/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1750 - accuracy: 0.9321 - precision: 0.9316 - recall: 0.9710 - true_negatives: 491.0000 - true_positives: 1171.0000 - false_negatives: 35.0000 - false_positives: 86.0000 - val_loss: 0.2085 - val_accuracy: 0.9169 - val_precision: 0.9272 - val_recall: 0.9492 - val_true_negatives: 128.0000 - val_true_positives: 280.0000 - val_false_negatives: 15.0000 - val_false_positives: 22.0000\n",
      "Epoch 20/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1746 - accuracy: 0.9288 - precision: 0.9326 - recall: 0.9643 - true_negatives: 493.0000 - true_positives: 1163.0000 - false_negatives: 43.0000 - false_positives: 84.0000 - val_loss: 0.2025 - val_accuracy: 0.9146 - val_precision: 0.9132 - val_recall: 0.9627 - val_true_negatives: 123.0000 - val_true_positives: 284.0000 - val_false_negatives: 11.0000 - val_false_positives: 27.0000\n",
      "Epoch 21/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1715 - accuracy: 0.9327 - precision: 0.9351 - recall: 0.9677 - true_negatives: 496.0000 - true_positives: 1167.0000 - false_negatives: 39.0000 - false_positives: 81.0000 - val_loss: 0.2010 - val_accuracy: 0.9213 - val_precision: 0.9221 - val_recall: 0.9627 - val_true_negatives: 126.0000 - val_true_positives: 284.0000 - val_false_negatives: 11.0000 - val_false_positives: 24.0000\n",
      "Epoch 22/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1694 - accuracy: 0.9305 - precision: 0.9328 - recall: 0.9668 - true_negatives: 493.0000 - true_positives: 1166.0000 - false_negatives: 40.0000 - false_positives: 84.0000 - val_loss: 0.2023 - val_accuracy: 0.9191 - val_precision: 0.9274 - val_recall: 0.9525 - val_true_negatives: 128.0000 - val_true_positives: 281.0000 - val_false_negatives: 14.0000 - val_false_positives: 22.0000\n",
      "Epoch 23/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1699 - accuracy: 0.9282 - precision: 0.9305 - recall: 0.9660 - true_negatives: 490.0000 - true_positives: 1165.0000 - false_negatives: 41.0000 - false_positives: 87.0000 - val_loss: 0.2040 - val_accuracy: 0.9169 - val_precision: 0.9329 - val_recall: 0.9424 - val_true_negatives: 130.0000 - val_true_positives: 278.0000 - val_false_negatives: 17.0000 - val_false_positives: 20.0000\n",
      "Epoch 24/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1711 - accuracy: 0.9316 - precision: 0.9364 - recall: 0.9643 - true_negatives: 498.0000 - true_positives: 1163.0000 - false_negatives: 43.0000 - false_positives: 79.0000 - val_loss: 0.1964 - val_accuracy: 0.9236 - val_precision: 0.9336 - val_recall: 0.9525 - val_true_negatives: 130.0000 - val_true_positives: 281.0000 - val_false_negatives: 14.0000 - val_false_positives: 20.0000\n",
      "Epoch 25/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1634 - accuracy: 0.9366 - precision: 0.9397 - recall: 0.9685 - true_negatives: 502.0000 - true_positives: 1168.0000 - false_negatives: 38.0000 - false_positives: 75.0000 - val_loss: 0.1936 - val_accuracy: 0.9258 - val_precision: 0.9281 - val_recall: 0.9627 - val_true_negatives: 128.0000 - val_true_positives: 284.0000 - val_false_negatives: 11.0000 - val_false_positives: 22.0000\n",
      "Epoch 26/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1659 - accuracy: 0.9366 - precision: 0.9376 - recall: 0.9710 - true_negatives: 499.0000 - true_positives: 1171.0000 - false_negatives: 35.0000 - false_positives: 78.0000 - val_loss: 0.1964 - val_accuracy: 0.9191 - val_precision: 0.9390 - val_recall: 0.9390 - val_true_negatives: 132.0000 - val_true_positives: 277.0000 - val_false_negatives: 18.0000 - val_false_positives: 18.0000\n",
      "Epoch 27/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1614 - accuracy: 0.9366 - precision: 0.9404 - recall: 0.9677 - true_negatives: 503.0000 - true_positives: 1167.0000 - false_negatives: 39.0000 - false_positives: 74.0000 - val_loss: 0.1978 - val_accuracy: 0.9169 - val_precision: 0.9388 - val_recall: 0.9356 - val_true_negatives: 132.0000 - val_true_positives: 276.0000 - val_false_negatives: 19.0000 - val_false_positives: 18.0000\n",
      "Epoch 28/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1644 - accuracy: 0.9366 - precision: 0.9383 - recall: 0.9701 - true_negatives: 500.0000 - true_positives: 1170.0000 - false_negatives: 36.0000 - false_positives: 77.0000 - val_loss: 0.1918 - val_accuracy: 0.9236 - val_precision: 0.9394 - val_recall: 0.9458 - val_true_negatives: 132.0000 - val_true_positives: 279.0000 - val_false_negatives: 16.0000 - val_false_positives: 18.0000\n",
      "Epoch 29/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1597 - accuracy: 0.9377 - precision: 0.9405 - recall: 0.9693 - true_negatives: 503.0000 - true_positives: 1169.0000 - false_negatives: 37.0000 - false_positives: 74.0000 - val_loss: 0.1911 - val_accuracy: 0.9191 - val_precision: 0.9390 - val_recall: 0.9390 - val_true_negatives: 132.0000 - val_true_positives: 277.0000 - val_false_negatives: 18.0000 - val_false_positives: 18.0000\n",
      "Epoch 30/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1603 - accuracy: 0.9405 - precision: 0.9428 - recall: 0.9710 - true_negatives: 506.0000 - true_positives: 1171.0000 - false_negatives: 35.0000 - false_positives: 71.0000 - val_loss: 0.1901 - val_accuracy: 0.9213 - val_precision: 0.9392 - val_recall: 0.9424 - val_true_negatives: 132.0000 - val_true_positives: 278.0000 - val_false_negatives: 17.0000 - val_false_positives: 18.0000\n",
      "Epoch 31/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1584 - accuracy: 0.9366 - precision: 0.9411 - recall: 0.9668 - true_negatives: 504.0000 - true_positives: 1166.0000 - false_negatives: 40.0000 - false_positives: 73.0000 - val_loss: 0.1872 - val_accuracy: 0.9303 - val_precision: 0.9342 - val_recall: 0.9627 - val_true_negatives: 130.0000 - val_true_positives: 284.0000 - val_false_negatives: 11.0000 - val_false_positives: 20.0000\n",
      "Epoch 32/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1580 - accuracy: 0.9389 - precision: 0.9406 - recall: 0.9710 - true_negatives: 503.0000 - true_positives: 1171.0000 - false_negatives: 35.0000 - false_positives: 74.0000 - val_loss: 0.1871 - val_accuracy: 0.9303 - val_precision: 0.9314 - val_recall: 0.9661 - val_true_negatives: 129.0000 - val_true_positives: 285.0000 - val_false_negatives: 10.0000 - val_false_positives: 21.0000\n",
      "Epoch 33/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1592 - accuracy: 0.9405 - precision: 0.9435 - recall: 0.9701 - true_negatives: 507.0000 - true_positives: 1170.0000 - false_negatives: 36.0000 - false_positives: 70.0000 - val_loss: 0.1858 - val_accuracy: 0.9281 - val_precision: 0.9369 - val_recall: 0.9559 - val_true_negatives: 131.0000 - val_true_positives: 282.0000 - val_false_negatives: 13.0000 - val_false_positives: 19.0000\n",
      "Epoch 34/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1564 - accuracy: 0.9338 - precision: 0.9401 - recall: 0.9635 - true_negatives: 503.0000 - true_positives: 1162.0000 - false_negatives: 44.0000 - false_positives: 74.0000 - val_loss: 0.1991 - val_accuracy: 0.9124 - val_precision: 0.9507 - val_recall: 0.9153 - val_true_negatives: 136.0000 - val_true_positives: 270.0000 - val_false_negatives: 25.0000 - val_false_positives: 14.0000\n",
      "Epoch 35/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1551 - accuracy: 0.9411 - precision: 0.9436 - recall: 0.9710 - true_negatives: 507.0000 - true_positives: 1171.0000 - false_negatives: 35.0000 - false_positives: 70.0000 - val_loss: 0.1847 - val_accuracy: 0.9258 - val_precision: 0.9396 - val_recall: 0.9492 - val_true_negatives: 132.0000 - val_true_positives: 280.0000 - val_false_negatives: 15.0000 - val_false_positives: 18.0000\n",
      "Epoch 36/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1600 - accuracy: 0.9383 - precision: 0.9412 - recall: 0.9693 - true_negatives: 504.0000 - true_positives: 1169.0000 - false_negatives: 37.0000 - false_positives: 73.0000 - val_loss: 0.1837 - val_accuracy: 0.9281 - val_precision: 0.9428 - val_recall: 0.9492 - val_true_negatives: 133.0000 - val_true_positives: 280.0000 - val_false_negatives: 15.0000 - val_false_positives: 17.0000\n",
      "Epoch 37/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1581 - accuracy: 0.9383 - precision: 0.9448 - recall: 0.9652 - true_negatives: 509.0000 - true_positives: 1164.0000 - false_negatives: 42.0000 - false_positives: 68.0000 - val_loss: 0.1835 - val_accuracy: 0.9281 - val_precision: 0.9428 - val_recall: 0.9492 - val_true_negatives: 133.0000 - val_true_positives: 280.0000 - val_false_negatives: 15.0000 - val_false_positives: 17.0000\n",
      "Epoch 38/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1504 - accuracy: 0.9405 - precision: 0.9472 - recall: 0.9660 - true_negatives: 512.0000 - true_positives: 1165.0000 - false_negatives: 41.0000 - false_positives: 65.0000 - val_loss: 0.1903 - val_accuracy: 0.9191 - val_precision: 0.9481 - val_recall: 0.9288 - val_true_negatives: 135.0000 - val_true_positives: 274.0000 - val_false_negatives: 21.0000 - val_false_positives: 15.0000\n",
      "Epoch 39/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1557 - accuracy: 0.9400 - precision: 0.9464 - recall: 0.9660 - true_negatives: 511.0000 - true_positives: 1165.0000 - false_negatives: 41.0000 - false_positives: 66.0000 - val_loss: 0.1825 - val_accuracy: 0.9281 - val_precision: 0.9428 - val_recall: 0.9492 - val_true_negatives: 133.0000 - val_true_positives: 280.0000 - val_false_negatives: 15.0000 - val_false_positives: 17.0000\n",
      "Epoch 40/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1522 - accuracy: 0.9394 - precision: 0.9449 - recall: 0.9668 - true_negatives: 509.0000 - true_positives: 1166.0000 - false_negatives: 40.0000 - false_positives: 68.0000 - val_loss: 0.1823 - val_accuracy: 0.9236 - val_precision: 0.9454 - val_recall: 0.9390 - val_true_negatives: 134.0000 - val_true_positives: 277.0000 - val_false_negatives: 18.0000 - val_false_positives: 16.0000\n",
      "Epoch 41/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1530 - accuracy: 0.9428 - precision: 0.9502 - recall: 0.9660 - true_negatives: 516.0000 - true_positives: 1165.0000 - false_negatives: 41.0000 - false_positives: 61.0000 - val_loss: 0.1824 - val_accuracy: 0.9326 - val_precision: 0.9402 - val_recall: 0.9593 - val_true_negatives: 132.0000 - val_true_positives: 283.0000 - val_false_negatives: 12.0000 - val_false_positives: 18.0000\n",
      "Epoch 42/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1527 - accuracy: 0.9411 - precision: 0.9487 - recall: 0.9652 - true_negatives: 514.0000 - true_positives: 1164.0000 - false_negatives: 42.0000 - false_positives: 63.0000 - val_loss: 0.1888 - val_accuracy: 0.9124 - val_precision: 0.9476 - val_recall: 0.9186 - val_true_negatives: 135.0000 - val_true_positives: 271.0000 - val_false_negatives: 24.0000 - val_false_positives: 15.0000\n",
      "Epoch 43/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1504 - accuracy: 0.9422 - precision: 0.9517 - recall: 0.9635 - true_negatives: 518.0000 - true_positives: 1162.0000 - false_negatives: 44.0000 - false_positives: 59.0000 - val_loss: 0.1998 - val_accuracy: 0.9101 - val_precision: 0.9505 - val_recall: 0.9119 - val_true_negatives: 136.0000 - val_true_positives: 269.0000 - val_false_negatives: 26.0000 - val_false_positives: 14.0000\n",
      "Epoch 44/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1513 - accuracy: 0.9417 - precision: 0.9494 - recall: 0.9652 - true_negatives: 515.0000 - true_positives: 1164.0000 - false_negatives: 42.0000 - false_positives: 62.0000 - val_loss: 0.1799 - val_accuracy: 0.9213 - val_precision: 0.9422 - val_recall: 0.9390 - val_true_negatives: 133.0000 - val_true_positives: 277.0000 - val_false_negatives: 18.0000 - val_false_positives: 17.0000\n",
      "Epoch 45/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1507 - accuracy: 0.9361 - precision: 0.9446 - recall: 0.9619 - true_negatives: 509.0000 - true_positives: 1160.0000 - false_negatives: 46.0000 - false_positives: 68.0000 - val_loss: 0.1868 - val_accuracy: 0.9124 - val_precision: 0.9476 - val_recall: 0.9186 - val_true_negatives: 135.0000 - val_true_positives: 271.0000 - val_false_negatives: 24.0000 - val_false_positives: 15.0000\n",
      "Epoch 46/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1504 - accuracy: 0.9405 - precision: 0.9472 - recall: 0.9660 - true_negatives: 512.0000 - true_positives: 1165.0000 - false_negatives: 41.0000 - false_positives: 65.0000 - val_loss: 0.1795 - val_accuracy: 0.9281 - val_precision: 0.9428 - val_recall: 0.9492 - val_true_negatives: 133.0000 - val_true_positives: 280.0000 - val_false_negatives: 15.0000 - val_false_positives: 17.0000\n",
      "Epoch 47/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1526 - accuracy: 0.9411 - precision: 0.9465 - recall: 0.9677 - true_negatives: 511.0000 - true_positives: 1167.0000 - false_negatives: 39.0000 - false_positives: 66.0000 - val_loss: 0.1821 - val_accuracy: 0.9191 - val_precision: 0.9481 - val_recall: 0.9288 - val_true_negatives: 135.0000 - val_true_positives: 274.0000 - val_false_negatives: 21.0000 - val_false_positives: 15.0000\n",
      "Epoch 48/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1543 - accuracy: 0.9428 - precision: 0.9466 - recall: 0.9701 - true_negatives: 511.0000 - true_positives: 1170.0000 - false_negatives: 36.0000 - false_positives: 66.0000 - val_loss: 0.1961 - val_accuracy: 0.9124 - val_precision: 0.9507 - val_recall: 0.9153 - val_true_negatives: 136.0000 - val_true_positives: 270.0000 - val_false_negatives: 25.0000 - val_false_positives: 14.0000\n",
      "Epoch 49/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1512 - accuracy: 0.9422 - precision: 0.9517 - recall: 0.9635 - true_negatives: 518.0000 - true_positives: 1162.0000 - false_negatives: 44.0000 - false_positives: 59.0000 - val_loss: 0.1793 - val_accuracy: 0.9258 - val_precision: 0.9426 - val_recall: 0.9458 - val_true_negatives: 133.0000 - val_true_positives: 279.0000 - val_false_negatives: 16.0000 - val_false_positives: 17.0000\n",
      "Epoch 50/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1557 - accuracy: 0.9394 - precision: 0.9456 - recall: 0.9660 - true_negatives: 510.0000 - true_positives: 1165.0000 - false_negatives: 41.0000 - false_positives: 67.0000 - val_loss: 0.1795 - val_accuracy: 0.9191 - val_precision: 0.9420 - val_recall: 0.9356 - val_true_negatives: 133.0000 - val_true_positives: 276.0000 - val_false_negatives: 19.0000 - val_false_positives: 17.0000\n",
      "Epoch 51/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1482 - accuracy: 0.9422 - precision: 0.9473 - recall: 0.9685 - true_negatives: 512.0000 - true_positives: 1168.0000 - false_negatives: 38.0000 - false_positives: 65.0000 - val_loss: 0.1787 - val_accuracy: 0.9258 - val_precision: 0.9426 - val_recall: 0.9458 - val_true_negatives: 133.0000 - val_true_positives: 279.0000 - val_false_negatives: 16.0000 - val_false_positives: 17.0000\n",
      "Epoch 52/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1503 - accuracy: 0.9417 - precision: 0.9480 - recall: 0.9668 - true_negatives: 513.0000 - true_positives: 1166.0000 - false_negatives: 40.0000 - false_positives: 64.0000 - val_loss: 0.1783 - val_accuracy: 0.9236 - val_precision: 0.9454 - val_recall: 0.9390 - val_true_negatives: 134.0000 - val_true_positives: 277.0000 - val_false_negatives: 18.0000 - val_false_positives: 16.0000\n",
      "Epoch 53/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1518 - accuracy: 0.9405 - precision: 0.9472 - recall: 0.9660 - true_negatives: 512.0000 - true_positives: 1165.0000 - false_negatives: 41.0000 - false_positives: 65.0000 - val_loss: 0.1818 - val_accuracy: 0.9191 - val_precision: 0.9481 - val_recall: 0.9288 - val_true_negatives: 135.0000 - val_true_positives: 274.0000 - val_false_negatives: 21.0000 - val_false_positives: 15.0000\n",
      "Epoch 54/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1499 - accuracy: 0.9377 - precision: 0.9455 - recall: 0.9635 - true_negatives: 510.0000 - true_positives: 1162.0000 - false_negatives: 44.0000 - false_positives: 67.0000 - val_loss: 0.1839 - val_accuracy: 0.9124 - val_precision: 0.9476 - val_recall: 0.9186 - val_true_negatives: 135.0000 - val_true_positives: 271.0000 - val_false_negatives: 24.0000 - val_false_positives: 15.0000\n",
      "Epoch 55/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1507 - accuracy: 0.9389 - precision: 0.9470 - recall: 0.9635 - true_negatives: 512.0000 - true_positives: 1162.0000 - false_negatives: 44.0000 - false_positives: 65.0000 - val_loss: 0.1774 - val_accuracy: 0.9303 - val_precision: 0.9430 - val_recall: 0.9525 - val_true_negatives: 133.0000 - val_true_positives: 281.0000 - val_false_negatives: 14.0000 - val_false_positives: 17.0000\n",
      "Epoch 56/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1506 - accuracy: 0.9428 - precision: 0.9488 - recall: 0.9677 - true_negatives: 514.0000 - true_positives: 1167.0000 - false_negatives: 39.0000 - false_positives: 63.0000 - val_loss: 0.1788 - val_accuracy: 0.9213 - val_precision: 0.9483 - val_recall: 0.9322 - val_true_negatives: 135.0000 - val_true_positives: 275.0000 - val_false_negatives: 20.0000 - val_false_positives: 15.0000\n",
      "Epoch 57/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1506 - accuracy: 0.9445 - precision: 0.9511 - recall: 0.9677 - true_negatives: 517.0000 - true_positives: 1167.0000 - false_negatives: 39.0000 - false_positives: 60.0000 - val_loss: 0.1772 - val_accuracy: 0.9303 - val_precision: 0.9430 - val_recall: 0.9525 - val_true_negatives: 133.0000 - val_true_positives: 281.0000 - val_false_negatives: 14.0000 - val_false_positives: 17.0000\n",
      "Epoch 58/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1513 - accuracy: 0.9383 - precision: 0.9470 - recall: 0.9627 - true_negatives: 512.0000 - true_positives: 1161.0000 - false_negatives: 45.0000 - false_positives: 65.0000 - val_loss: 0.1776 - val_accuracy: 0.9191 - val_precision: 0.9420 - val_recall: 0.9356 - val_true_negatives: 133.0000 - val_true_positives: 276.0000 - val_false_negatives: 19.0000 - val_false_positives: 17.0000\n",
      "Epoch 59/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1507 - accuracy: 0.9405 - precision: 0.9493 - recall: 0.9635 - true_negatives: 515.0000 - true_positives: 1162.0000 - false_negatives: 44.0000 - false_positives: 62.0000 - val_loss: 0.1829 - val_accuracy: 0.9124 - val_precision: 0.9476 - val_recall: 0.9186 - val_true_negatives: 135.0000 - val_true_positives: 271.0000 - val_false_negatives: 24.0000 - val_false_positives: 15.0000\n",
      "Epoch 60/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1492 - accuracy: 0.9456 - precision: 0.9519 - recall: 0.9685 - true_negatives: 518.0000 - true_positives: 1168.0000 - false_negatives: 38.0000 - false_positives: 59.0000 - val_loss: 0.1854 - val_accuracy: 0.9101 - val_precision: 0.9474 - val_recall: 0.9153 - val_true_negatives: 135.0000 - val_true_positives: 270.0000 - val_false_negatives: 25.0000 - val_false_positives: 15.0000\n",
      "Epoch 61/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1468 - accuracy: 0.9394 - precision: 0.9478 - recall: 0.9635 - true_negatives: 513.0000 - true_positives: 1162.0000 - false_negatives: 44.0000 - false_positives: 64.0000 - val_loss: 0.1769 - val_accuracy: 0.9303 - val_precision: 0.9430 - val_recall: 0.9525 - val_true_negatives: 133.0000 - val_true_positives: 281.0000 - val_false_negatives: 14.0000 - val_false_positives: 17.0000\n",
      "Epoch 62/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1481 - accuracy: 0.9394 - precision: 0.9485 - recall: 0.9627 - true_negatives: 514.0000 - true_positives: 1161.0000 - false_negatives: 45.0000 - false_positives: 63.0000 - val_loss: 0.1764 - val_accuracy: 0.9213 - val_precision: 0.9422 - val_recall: 0.9390 - val_true_negatives: 133.0000 - val_true_positives: 277.0000 - val_false_negatives: 18.0000 - val_false_positives: 17.0000\n",
      "Epoch 63/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1497 - accuracy: 0.9405 - precision: 0.9486 - recall: 0.9643 - true_negatives: 514.0000 - true_positives: 1163.0000 - false_negatives: 43.0000 - false_positives: 63.0000 - val_loss: 0.1766 - val_accuracy: 0.9213 - val_precision: 0.9422 - val_recall: 0.9390 - val_true_negatives: 133.0000 - val_true_positives: 277.0000 - val_false_negatives: 18.0000 - val_false_positives: 17.0000\n",
      "Epoch 64/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1477 - accuracy: 0.9400 - precision: 0.9478 - recall: 0.9643 - true_negatives: 513.0000 - true_positives: 1163.0000 - false_negatives: 43.0000 - false_positives: 64.0000 - val_loss: 0.1770 - val_accuracy: 0.9213 - val_precision: 0.9422 - val_recall: 0.9390 - val_true_negatives: 133.0000 - val_true_positives: 277.0000 - val_false_negatives: 18.0000 - val_false_positives: 17.0000\n",
      "Epoch 65/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1542 - accuracy: 0.9389 - precision: 0.9470 - recall: 0.9635 - true_negatives: 512.0000 - true_positives: 1162.0000 - false_negatives: 44.0000 - false_positives: 65.0000 - val_loss: 0.2109 - val_accuracy: 0.8944 - val_precision: 0.9559 - val_recall: 0.8814 - val_true_negatives: 138.0000 - val_true_positives: 260.0000 - val_false_negatives: 35.0000 - val_false_positives: 12.0000\n",
      "Epoch 66/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1472 - accuracy: 0.9411 - precision: 0.9509 - recall: 0.9627 - true_negatives: 517.0000 - true_positives: 1161.0000 - false_negatives: 45.0000 - false_positives: 60.0000 - val_loss: 0.1759 - val_accuracy: 0.9281 - val_precision: 0.9428 - val_recall: 0.9492 - val_true_negatives: 133.0000 - val_true_positives: 280.0000 - val_false_negatives: 15.0000 - val_false_positives: 17.0000\n",
      "Epoch 67/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1475 - accuracy: 0.9411 - precision: 0.9479 - recall: 0.9660 - true_negatives: 513.0000 - true_positives: 1165.0000 - false_negatives: 41.0000 - false_positives: 64.0000 - val_loss: 0.1761 - val_accuracy: 0.9258 - val_precision: 0.9396 - val_recall: 0.9492 - val_true_negatives: 132.0000 - val_true_positives: 280.0000 - val_false_negatives: 15.0000 - val_false_positives: 18.0000\n",
      "Epoch 68/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1488 - accuracy: 0.9366 - precision: 0.9461 - recall: 0.9610 - true_negatives: 511.0000 - true_positives: 1159.0000 - false_negatives: 47.0000 - false_positives: 66.0000 - val_loss: 0.1774 - val_accuracy: 0.9191 - val_precision: 0.9450 - val_recall: 0.9322 - val_true_negatives: 134.0000 - val_true_positives: 275.0000 - val_false_negatives: 20.0000 - val_false_positives: 16.0000\n",
      "Epoch 69/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1465 - accuracy: 0.9439 - precision: 0.9503 - recall: 0.9677 - true_negatives: 516.0000 - true_positives: 1167.0000 - false_negatives: 39.0000 - false_positives: 61.0000 - val_loss: 0.1832 - val_accuracy: 0.9101 - val_precision: 0.9474 - val_recall: 0.9153 - val_true_negatives: 135.0000 - val_true_positives: 270.0000 - val_false_negatives: 25.0000 - val_false_positives: 15.0000\n",
      "Epoch 70/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1471 - accuracy: 0.9383 - precision: 0.9470 - recall: 0.9627 - true_negatives: 512.0000 - true_positives: 1161.0000 - false_negatives: 45.0000 - false_positives: 65.0000 - val_loss: 0.1870 - val_accuracy: 0.9124 - val_precision: 0.9507 - val_recall: 0.9153 - val_true_negatives: 136.0000 - val_true_positives: 270.0000 - val_false_negatives: 25.0000 - val_false_positives: 14.0000\n",
      "Epoch 71/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1475 - accuracy: 0.9389 - precision: 0.9478 - recall: 0.9627 - true_negatives: 513.0000 - true_positives: 1161.0000 - false_negatives: 45.0000 - false_positives: 64.0000 - val_loss: 0.1761 - val_accuracy: 0.9236 - val_precision: 0.9424 - val_recall: 0.9424 - val_true_negatives: 133.0000 - val_true_positives: 278.0000 - val_false_negatives: 17.0000 - val_false_positives: 17.0000\n",
      "Epoch 72/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1475 - accuracy: 0.9422 - precision: 0.9502 - recall: 0.9652 - true_negatives: 516.0000 - true_positives: 1164.0000 - false_negatives: 42.0000 - false_positives: 61.0000 - val_loss: 0.1761 - val_accuracy: 0.9236 - val_precision: 0.9424 - val_recall: 0.9424 - val_true_negatives: 133.0000 - val_true_positives: 278.0000 - val_false_negatives: 17.0000 - val_false_positives: 17.0000\n",
      "Epoch 73/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1489 - accuracy: 0.9411 - precision: 0.9509 - recall: 0.9627 - true_negatives: 517.0000 - true_positives: 1161.0000 - false_negatives: 45.0000 - false_positives: 60.0000 - val_loss: 0.1774 - val_accuracy: 0.9169 - val_precision: 0.9418 - val_recall: 0.9322 - val_true_negatives: 133.0000 - val_true_positives: 275.0000 - val_false_negatives: 20.0000 - val_false_positives: 17.0000\n",
      "Epoch 74/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1466 - accuracy: 0.9405 - precision: 0.9479 - recall: 0.9652 - true_negatives: 513.0000 - true_positives: 1164.0000 - false_negatives: 42.0000 - false_positives: 64.0000 - val_loss: 0.1810 - val_accuracy: 0.9146 - val_precision: 0.9477 - val_recall: 0.9220 - val_true_negatives: 135.0000 - val_true_positives: 272.0000 - val_false_negatives: 23.0000 - val_false_positives: 15.0000\n",
      "Epoch 75/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1444 - accuracy: 0.9405 - precision: 0.9479 - recall: 0.9652 - true_negatives: 513.0000 - true_positives: 1164.0000 - false_negatives: 42.0000 - false_positives: 64.0000 - val_loss: 0.1766 - val_accuracy: 0.9236 - val_precision: 0.9485 - val_recall: 0.9356 - val_true_negatives: 135.0000 - val_true_positives: 276.0000 - val_false_negatives: 19.0000 - val_false_positives: 15.0000\n",
      "Epoch 76/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1458 - accuracy: 0.9422 - precision: 0.9487 - recall: 0.9668 - true_negatives: 514.0000 - true_positives: 1166.0000 - false_negatives: 40.0000 - false_positives: 63.0000 - val_loss: 0.1775 - val_accuracy: 0.9236 - val_precision: 0.9485 - val_recall: 0.9356 - val_true_negatives: 135.0000 - val_true_positives: 276.0000 - val_false_negatives: 19.0000 - val_false_positives: 15.0000\n",
      "Epoch 77/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1459 - accuracy: 0.9417 - precision: 0.9487 - recall: 0.9660 - true_negatives: 514.0000 - true_positives: 1165.0000 - false_negatives: 41.0000 - false_positives: 63.0000 - val_loss: 0.1759 - val_accuracy: 0.9258 - val_precision: 0.9426 - val_recall: 0.9458 - val_true_negatives: 133.0000 - val_true_positives: 279.0000 - val_false_negatives: 16.0000 - val_false_positives: 17.0000\n",
      "Epoch 78/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1471 - accuracy: 0.9417 - precision: 0.9502 - recall: 0.9643 - true_negatives: 516.0000 - true_positives: 1163.0000 - false_negatives: 43.0000 - false_positives: 61.0000 - val_loss: 0.1764 - val_accuracy: 0.9281 - val_precision: 0.9428 - val_recall: 0.9492 - val_true_negatives: 133.0000 - val_true_positives: 280.0000 - val_false_negatives: 15.0000 - val_false_positives: 17.0000\n",
      "Epoch 79/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1455 - accuracy: 0.9417 - precision: 0.9494 - recall: 0.9652 - true_negatives: 515.0000 - true_positives: 1164.0000 - false_negatives: 42.0000 - false_positives: 62.0000 - val_loss: 0.1775 - val_accuracy: 0.9191 - val_precision: 0.9481 - val_recall: 0.9288 - val_true_negatives: 135.0000 - val_true_positives: 274.0000 - val_false_negatives: 21.0000 - val_false_positives: 15.0000\n",
      "Epoch 80/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1469 - accuracy: 0.9400 - precision: 0.9486 - recall: 0.9635 - true_negatives: 514.0000 - true_positives: 1162.0000 - false_negatives: 44.0000 - false_positives: 63.0000 - val_loss: 0.1765 - val_accuracy: 0.9281 - val_precision: 0.9398 - val_recall: 0.9525 - val_true_negatives: 132.0000 - val_true_positives: 281.0000 - val_false_negatives: 14.0000 - val_false_positives: 18.0000\n",
      "Epoch 81/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1494 - accuracy: 0.9361 - precision: 0.9475 - recall: 0.9585 - true_negatives: 513.0000 - true_positives: 1156.0000 - false_negatives: 50.0000 - false_positives: 64.0000 - val_loss: 0.1765 - val_accuracy: 0.9281 - val_precision: 0.9398 - val_recall: 0.9525 - val_true_negatives: 132.0000 - val_true_positives: 281.0000 - val_false_negatives: 14.0000 - val_false_positives: 18.0000\n",
      "Epoch 82/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1458 - accuracy: 0.9383 - precision: 0.9477 - recall: 0.9619 - true_negatives: 513.0000 - true_positives: 1160.0000 - false_negatives: 46.0000 - false_positives: 64.0000 - val_loss: 0.1794 - val_accuracy: 0.9169 - val_precision: 0.9479 - val_recall: 0.9254 - val_true_negatives: 135.0000 - val_true_positives: 273.0000 - val_false_negatives: 22.0000 - val_false_positives: 15.0000\n",
      "Epoch 83/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1442 - accuracy: 0.9405 - precision: 0.9501 - recall: 0.9627 - true_negatives: 516.0000 - true_positives: 1161.0000 - false_negatives: 45.0000 - false_positives: 61.0000 - val_loss: 0.1894 - val_accuracy: 0.9079 - val_precision: 0.9504 - val_recall: 0.9085 - val_true_negatives: 136.0000 - val_true_positives: 268.0000 - val_false_negatives: 27.0000 - val_false_positives: 14.0000\n",
      "Epoch 84/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1494 - accuracy: 0.9417 - precision: 0.9531 - recall: 0.9610 - true_negatives: 520.0000 - true_positives: 1159.0000 - false_negatives: 47.0000 - false_positives: 57.0000 - val_loss: 0.1758 - val_accuracy: 0.9213 - val_precision: 0.9422 - val_recall: 0.9390 - val_true_negatives: 133.0000 - val_true_positives: 277.0000 - val_false_negatives: 18.0000 - val_false_positives: 17.0000\n",
      "Epoch 85/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1486 - accuracy: 0.9439 - precision: 0.9525 - recall: 0.9652 - true_negatives: 519.0000 - true_positives: 1164.0000 - false_negatives: 42.0000 - false_positives: 58.0000 - val_loss: 0.1754 - val_accuracy: 0.9258 - val_precision: 0.9396 - val_recall: 0.9492 - val_true_negatives: 132.0000 - val_true_positives: 280.0000 - val_false_negatives: 15.0000 - val_false_positives: 18.0000\n",
      "Epoch 86/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1502 - accuracy: 0.9405 - precision: 0.9457 - recall: 0.9677 - true_negatives: 510.0000 - true_positives: 1167.0000 - false_negatives: 39.0000 - false_positives: 67.0000 - val_loss: 0.1781 - val_accuracy: 0.9281 - val_precision: 0.9340 - val_recall: 0.9593 - val_true_negatives: 130.0000 - val_true_positives: 283.0000 - val_false_negatives: 12.0000 - val_false_positives: 20.0000\n",
      "Epoch 87/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1492 - accuracy: 0.9422 - precision: 0.9509 - recall: 0.9643 - true_negatives: 517.0000 - true_positives: 1163.0000 - false_negatives: 43.0000 - false_positives: 60.0000 - val_loss: 0.1759 - val_accuracy: 0.9213 - val_precision: 0.9452 - val_recall: 0.9356 - val_true_negatives: 134.0000 - val_true_positives: 276.0000 - val_false_negatives: 19.0000 - val_false_positives: 16.0000\n",
      "Epoch 88/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1466 - accuracy: 0.9394 - precision: 0.9463 - recall: 0.9652 - true_negatives: 511.0000 - true_positives: 1164.0000 - false_negatives: 42.0000 - false_positives: 66.0000 - val_loss: 0.1785 - val_accuracy: 0.9169 - val_precision: 0.9479 - val_recall: 0.9254 - val_true_negatives: 135.0000 - val_true_positives: 273.0000 - val_false_negatives: 22.0000 - val_false_positives: 15.0000\n",
      "Epoch 89/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1459 - accuracy: 0.9400 - precision: 0.9478 - recall: 0.9643 - true_negatives: 513.0000 - true_positives: 1163.0000 - false_negatives: 43.0000 - false_positives: 64.0000 - val_loss: 0.1759 - val_accuracy: 0.9258 - val_precision: 0.9396 - val_recall: 0.9492 - val_true_negatives: 132.0000 - val_true_positives: 280.0000 - val_false_negatives: 15.0000 - val_false_positives: 18.0000\n",
      "Epoch 90/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1457 - accuracy: 0.9473 - precision: 0.9542 - recall: 0.9685 - true_negatives: 521.0000 - true_positives: 1168.0000 - false_negatives: 38.0000 - false_positives: 56.0000 - val_loss: 0.1752 - val_accuracy: 0.9258 - val_precision: 0.9426 - val_recall: 0.9458 - val_true_negatives: 133.0000 - val_true_positives: 279.0000 - val_false_negatives: 16.0000 - val_false_positives: 17.0000\n",
      "Epoch 91/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1461 - accuracy: 0.9428 - precision: 0.9502 - recall: 0.9660 - true_negatives: 516.0000 - true_positives: 1165.0000 - false_negatives: 41.0000 - false_positives: 61.0000 - val_loss: 0.1774 - val_accuracy: 0.9191 - val_precision: 0.9481 - val_recall: 0.9288 - val_true_negatives: 135.0000 - val_true_positives: 274.0000 - val_false_negatives: 21.0000 - val_false_positives: 15.0000\n",
      "Epoch 92/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1472 - accuracy: 0.9377 - precision: 0.9477 - recall: 0.9610 - true_negatives: 513.0000 - true_positives: 1159.0000 - false_negatives: 47.0000 - false_positives: 64.0000 - val_loss: 0.1787 - val_accuracy: 0.9236 - val_precision: 0.9279 - val_recall: 0.9593 - val_true_negatives: 128.0000 - val_true_positives: 283.0000 - val_false_negatives: 12.0000 - val_false_positives: 22.0000\n",
      "Epoch 93/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1463 - accuracy: 0.9439 - precision: 0.9511 - recall: 0.9668 - true_negatives: 517.0000 - true_positives: 1166.0000 - false_negatives: 40.0000 - false_positives: 60.0000 - val_loss: 0.1787 - val_accuracy: 0.9169 - val_precision: 0.9479 - val_recall: 0.9254 - val_true_negatives: 135.0000 - val_true_positives: 273.0000 - val_false_negatives: 22.0000 - val_false_positives: 15.0000\n",
      "Epoch 94/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1500 - accuracy: 0.9405 - precision: 0.9508 - recall: 0.9619 - true_negatives: 517.0000 - true_positives: 1160.0000 - false_negatives: 46.0000 - false_positives: 60.0000 - val_loss: 0.1757 - val_accuracy: 0.9281 - val_precision: 0.9428 - val_recall: 0.9492 - val_true_negatives: 133.0000 - val_true_positives: 280.0000 - val_false_negatives: 15.0000 - val_false_positives: 17.0000\n",
      "Epoch 95/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1486 - accuracy: 0.9389 - precision: 0.9492 - recall: 0.9610 - true_negatives: 515.0000 - true_positives: 1159.0000 - false_negatives: 47.0000 - false_positives: 62.0000 - val_loss: 0.1755 - val_accuracy: 0.9258 - val_precision: 0.9426 - val_recall: 0.9458 - val_true_negatives: 133.0000 - val_true_positives: 279.0000 - val_false_negatives: 16.0000 - val_false_positives: 17.0000\n",
      "Epoch 96/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1452 - accuracy: 0.9439 - precision: 0.9518 - recall: 0.9660 - true_negatives: 518.0000 - true_positives: 1165.0000 - false_negatives: 41.0000 - false_positives: 59.0000 - val_loss: 0.1832 - val_accuracy: 0.9101 - val_precision: 0.9474 - val_recall: 0.9153 - val_true_negatives: 135.0000 - val_true_positives: 270.0000 - val_false_negatives: 25.0000 - val_false_positives: 15.0000\n",
      "Epoch 97/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1457 - accuracy: 0.9450 - precision: 0.9534 - recall: 0.9660 - true_negatives: 520.0000 - true_positives: 1165.0000 - false_negatives: 41.0000 - false_positives: 57.0000 - val_loss: 0.1917 - val_accuracy: 0.9079 - val_precision: 0.9504 - val_recall: 0.9085 - val_true_negatives: 136.0000 - val_true_positives: 268.0000 - val_false_negatives: 27.0000 - val_false_positives: 14.0000\n",
      "Epoch 98/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1476 - accuracy: 0.9450 - precision: 0.9534 - recall: 0.9660 - true_negatives: 520.0000 - true_positives: 1165.0000 - false_negatives: 41.0000 - false_positives: 57.0000 - val_loss: 0.1764 - val_accuracy: 0.9213 - val_precision: 0.9483 - val_recall: 0.9322 - val_true_negatives: 135.0000 - val_true_positives: 275.0000 - val_false_negatives: 20.0000 - val_false_positives: 15.0000\n",
      "Epoch 99/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1487 - accuracy: 0.9389 - precision: 0.9463 - recall: 0.9643 - true_negatives: 511.0000 - true_positives: 1163.0000 - false_negatives: 43.0000 - false_positives: 66.0000 - val_loss: 0.1752 - val_accuracy: 0.9258 - val_precision: 0.9396 - val_recall: 0.9492 - val_true_negatives: 132.0000 - val_true_positives: 280.0000 - val_false_negatives: 15.0000 - val_false_positives: 18.0000\n",
      "Epoch 100/100\n",
      "892/892 [==============================] - 2s 2ms/step - loss: 0.1507 - accuracy: 0.9338 - precision: 0.9481 - recall: 0.9544 - true_negatives: 514.0000 - true_positives: 1151.0000 - false_negatives: 55.0000 - false_positives: 63.0000 - val_loss: 0.1777 - val_accuracy: 0.9281 - val_precision: 0.9340 - val_recall: 0.9593 - val_true_negatives: 130.0000 - val_true_positives: 283.0000 - val_false_negatives: 12.0000 - val_false_positives: 20.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd2a828c940>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sequential Neural Network\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# create a sequential model\n",
    "model1 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(img_height, img_width, 3)),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "metrics = [\n",
    "    'accuracy',\n",
    "    tf.keras.metrics.Precision(),\n",
    "    tf.keras.metrics.Recall(),\n",
    "    tf.keras.metrics.TrueNegatives(),\n",
    "    tf.keras.metrics.TruePositives(),\n",
    "    tf.keras.metrics.FalseNegatives(),\n",
    "    tf.keras.metrics.FalsePositives()\n",
    "]\n",
    "\n",
    "# compile the model\n",
    "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=metrics)\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "# fit the model to the training data\n",
    "# model.fit(train_generator, epochs=10, validation_data=validation_generator)\n",
    "model1.fit(\n",
    "    train_ds,\n",
    "    epochs=100,\n",
    "    validation_data=validation_ds,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto Encoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Input Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the shape of the input layer\n",
    "input_shape = (None, 10) # Batch size is None, 10 features\n",
    "\n",
    "# Create the input layer\n",
    "input_layer = tf.keras.layers.Input(shape=input_shape)\n",
    "\n",
    "# Print information about the input layer\n",
    "print(\"Input layer shape:\", input_layer.shape)\n",
    "print(\"Input layer dtype:\", input_layer.dtype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 16 2D Convolutional Layers with a (2,2) kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# from tensorflow.keras.layers import Conv2D\n",
    "# from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "for i in range(16):\n",
    "    model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(2,2), activation='relu', padding='same'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Max Pooling 2D layer with a (2,2) kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "maxpool_layer = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 16 Convolutional 2D Transpose layers with a (3,3) kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# add 16 Convolutional 2D Transpose layers with a (3,3) kernel\n",
    "for i in range(16):\n",
    "    model.add(tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=(3,3), strides=(2,2), padding='same', activation='relu'))\n",
    "\n",
    "\n",
    "# build the model\n",
    "model.build(input_shape=(None, 64, 64, 3))\n",
    "\n",
    "# # compile the model\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# print the summary of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3 Convolutional 2D layers using a (2,2) kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=(2,2), activation='relu', input_shape=(None, None, 3)))\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(2,2), activation='relu'))\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(2,2), activation='relu'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gabungannya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 13:43:00.833283: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-04-05 13:43:04.461702: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x1c760a70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-04-05 13:43:04.461743: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3070 Laptop GPU, Compute Capability 8.6\n",
      "2023-04-05 13:43:04.465408: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-04-05 13:43:04.548987: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 54s 453ms/step - loss: 1.8323 - accuracy: 0.0000e+00 - val_loss: 1.0935 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "90/90 [==============================] - 37s 415ms/step - loss: 0.9104 - accuracy: 0.0000e+00 - val_loss: 0.6677 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "90/90 [==============================] - 37s 415ms/step - loss: 0.6573 - accuracy: 0.0000e+00 - val_loss: 0.6423 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "90/90 [==============================] - 37s 414ms/step - loss: 0.6386 - accuracy: 0.0000e+00 - val_loss: 0.6404 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "90/90 [==============================] - 37s 414ms/step - loss: 0.6465 - accuracy: 0.0000e+00 - val_loss: 0.6614 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "90/90 [==============================] - 37s 415ms/step - loss: 0.6600 - accuracy: 0.0000e+00 - val_loss: 0.8927 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "90/90 [==============================] - 37s 415ms/step - loss: 0.6761 - accuracy: 0.0000e+00 - val_loss: 0.6472 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "90/90 [==============================] - 37s 415ms/step - loss: 0.8306 - accuracy: 0.0000e+00 - val_loss: 0.6698 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "90/90 [==============================] - 37s 414ms/step - loss: 0.6507 - accuracy: 0.0000e+00 - val_loss: 0.6452 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "90/90 [==============================] - 37s 415ms/step - loss: 0.6467 - accuracy: 0.0000e+00 - val_loss: 0.6446 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7eff8c7a2530>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "filters = 25\n",
    "activation  = 'relu'\n",
    "input_shape = (None, None, 3)\n",
    "model2 = tf.keras.models.Sequential()\n",
    "model2.add(tf.keras.layers.Input(shape=input_shape)) # add input layer\n",
    "\n",
    "# 16 2D Convolutinal layers with a (2,2) kernel\n",
    "for i in range(16):\n",
    "    model2.add(tf.keras.layers.Conv2D(kernel_size=(2,2), filters=filters, activation=activation))\n",
    "\n",
    "model2.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2))) # Max Pooling 2D layer with a (2,2) kernel\n",
    "\n",
    "# 16 Convolutional 2D Transpose layers with a (3,3) kernel\n",
    "for i in range(16):\n",
    "    model2.add(tf.keras.layers.Conv2DTranspose(kernel_size=(3,3), filters=filters, activation=activation))\n",
    "\n",
    "# 3 Convolutional 2D layers using a (2,2) kernel\n",
    "for i in range(3):\n",
    "    model2.add(tf.keras.layers.Conv2D(kernel_size=(2,2), filters=filters, activation=activation))\n",
    "\n",
    "model2.add(tf.keras.layers.Flatten())\n",
    "\n",
    "\n",
    "# compile the model\n",
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# fut the model to the training data\n",
    "model2.fit(\n",
    "    train_ds,\n",
    "    epochs=10,\n",
    "    validation_data=validation_ds\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "botnet-image",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
