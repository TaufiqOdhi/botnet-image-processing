{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mengubah dataset menjadi gambar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "base_dataset_dir = '/mnt/Windows/Users/taufi/MyFile/Projects/datasets/N-BaIoT'\n",
    "# base_dataset_dir = '/home/maoik/Projects/datasets/N-BaIoT'\n",
    "base_generated_image_dir = 'generated_image'\n",
    "\n",
    "n_image_channel = 3\n",
    "\n",
    "# for height of image\n",
    "chunk_size_1 = 102\n",
    "chunk_size_2 = 51\n",
    "\n",
    "benign_file_name = '1.benign.csv'\n",
    "mirai_file_name = '1.mirai.ack.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### untuk dataset benign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MI_dir_L5_weight</th>\n",
       "      <th>MI_dir_L5_mean</th>\n",
       "      <th>MI_dir_L5_variance</th>\n",
       "      <th>MI_dir_L3_weight</th>\n",
       "      <th>MI_dir_L3_mean</th>\n",
       "      <th>MI_dir_L3_variance</th>\n",
       "      <th>MI_dir_L1_weight</th>\n",
       "      <th>MI_dir_L1_mean</th>\n",
       "      <th>MI_dir_L1_variance</th>\n",
       "      <th>MI_dir_L0.1_weight</th>\n",
       "      <th>...</th>\n",
       "      <th>HpHp_L0.1_covariance</th>\n",
       "      <th>HpHp_L0.1_pcc</th>\n",
       "      <th>HpHp_L0.01_weight</th>\n",
       "      <th>HpHp_L0.01_mean</th>\n",
       "      <th>HpHp_L0.01_std</th>\n",
       "      <th>HpHp_L0.01_magnitude</th>\n",
       "      <th>HpHp_L0.01_radius</th>\n",
       "      <th>HpHp_L0.01_covariance</th>\n",
       "      <th>HpHp_L0.01_pcc</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.319895</td>\n",
       "      <td>344.262695</td>\n",
       "      <td>4.710446</td>\n",
       "      <td>344.262695</td>\n",
       "      <td>2.218830e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.857879</td>\n",
       "      <td>360.458980</td>\n",
       "      <td>3.578934e+01</td>\n",
       "      <td>1.912127</td>\n",
       "      <td>360.275733</td>\n",
       "      <td>3.592397e+01</td>\n",
       "      <td>1.969807</td>\n",
       "      <td>360.091968</td>\n",
       "      <td>35.991542</td>\n",
       "      <td>1.996939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.318264</td>\n",
       "      <td>347.703087</td>\n",
       "      <td>9.034660</td>\n",
       "      <td>347.703087</td>\n",
       "      <td>8.162508e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.680223</td>\n",
       "      <td>172.140917</td>\n",
       "      <td>1.848745e+04</td>\n",
       "      <td>1.793580</td>\n",
       "      <td>182.560279</td>\n",
       "      <td>1.892818e+04</td>\n",
       "      <td>1.925828</td>\n",
       "      <td>193.165753</td>\n",
       "      <td>19153.795810</td>\n",
       "      <td>1.992323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49543</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>1.820000e-12</td>\n",
       "      <td>1.000009</td>\n",
       "      <td>101.999633</td>\n",
       "      <td>0.015405</td>\n",
       "      <td>2.270210</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.570000e-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.218824</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>144.249783</td>\n",
       "      <td>1.820000e-12</td>\n",
       "      <td>5.970000e-23</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49544</th>\n",
       "      <td>1.999976</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.999986</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>1.820000e-12</td>\n",
       "      <td>2.000004</td>\n",
       "      <td>101.999816</td>\n",
       "      <td>0.007702</td>\n",
       "      <td>3.270209</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.580000e-44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.218838</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>144.249783</td>\n",
       "      <td>3.640000e-12</td>\n",
       "      <td>-1.100000e-29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49545</th>\n",
       "      <td>2.999872</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>3.640000e-12</td>\n",
       "      <td>2.999923</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>1.820000e-12</td>\n",
       "      <td>2.999983</td>\n",
       "      <td>101.999878</td>\n",
       "      <td>0.005135</td>\n",
       "      <td>4.270206</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.330000e-45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.179949</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>144.249783</td>\n",
       "      <td>5.140000e-12</td>\n",
       "      <td>8.230000e-29</td>\n",
       "      <td>2.260000e-17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49546</th>\n",
       "      <td>3.999664</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>3.640000e-12</td>\n",
       "      <td>3.999798</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.999942</td>\n",
       "      <td>101.999908</td>\n",
       "      <td>0.003851</td>\n",
       "      <td>5.270200</td>\n",
       "      <td>...</td>\n",
       "      <td>4.980000e-69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.219537</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>144.249783</td>\n",
       "      <td>1.820000e-12</td>\n",
       "      <td>5.960000e-29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49547</th>\n",
       "      <td>4.997694</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>3.640000e-12</td>\n",
       "      <td>4.998617</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>1.820000e-12</td>\n",
       "      <td>4.999548</td>\n",
       "      <td>101.999927</td>\n",
       "      <td>0.003081</td>\n",
       "      <td>6.270148</td>\n",
       "      <td>...</td>\n",
       "      <td>7.450000e-39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.219212</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>144.249783</td>\n",
       "      <td>2.570000e-12</td>\n",
       "      <td>2.920000e-26</td>\n",
       "      <td>1.600000e-14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49548 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MI_dir_L5_weight  MI_dir_L5_mean  MI_dir_L5_variance  MI_dir_L3_weight  \\\n",
       "0              1.000000       60.000000        0.000000e+00          1.000000   \n",
       "1              1.000000      354.000000        0.000000e+00          1.000000   \n",
       "2              1.857879      360.458980        3.578934e+01          1.912127   \n",
       "3              1.000000      337.000000        0.000000e+00          1.000000   \n",
       "4              1.680223      172.140917        1.848745e+04          1.793580   \n",
       "...                 ...             ...                 ...               ...   \n",
       "49543          1.000000      102.000000        0.000000e+00          1.000000   \n",
       "49544          1.999976      102.000000        0.000000e+00          1.999986   \n",
       "49545          2.999872      102.000000        3.640000e-12          2.999923   \n",
       "49546          3.999664      102.000000        3.640000e-12          3.999798   \n",
       "49547          4.997694      102.000000        3.640000e-12          4.998617   \n",
       "\n",
       "       MI_dir_L3_mean  MI_dir_L3_variance  MI_dir_L1_weight  MI_dir_L1_mean  \\\n",
       "0           60.000000        0.000000e+00          1.000000       60.000000   \n",
       "1          354.000000        0.000000e+00          1.000000      354.000000   \n",
       "2          360.275733        3.592397e+01          1.969807      360.091968   \n",
       "3          337.000000        0.000000e+00          1.000000      337.000000   \n",
       "4          182.560279        1.892818e+04          1.925828      193.165753   \n",
       "...               ...                 ...               ...             ...   \n",
       "49543      102.000000        1.820000e-12          1.000009      101.999633   \n",
       "49544      102.000000        1.820000e-12          2.000004      101.999816   \n",
       "49545      102.000000        1.820000e-12          2.999983      101.999878   \n",
       "49546      102.000000        0.000000e+00          3.999942      101.999908   \n",
       "49547      102.000000        1.820000e-12          4.999548      101.999927   \n",
       "\n",
       "       MI_dir_L1_variance  MI_dir_L0.1_weight  ...  HpHp_L0.1_covariance  \\\n",
       "0                0.000000            1.000000  ...          0.000000e+00   \n",
       "1                0.000000            1.000000  ...          0.000000e+00   \n",
       "2               35.991542            1.996939  ...          0.000000e+00   \n",
       "3                0.000000            1.000000  ...          0.000000e+00   \n",
       "4            19153.795810            1.992323  ...          0.000000e+00   \n",
       "...                   ...                 ...  ...                   ...   \n",
       "49543            0.015405            2.270210  ...         -1.570000e-30   \n",
       "49544            0.007702            3.270209  ...         -1.580000e-44   \n",
       "49545            0.005135            4.270206  ...         -8.330000e-45   \n",
       "49546            0.003851            5.270200  ...          4.980000e-69   \n",
       "49547            0.003081            6.270148  ...          7.450000e-39   \n",
       "\n",
       "       HpHp_L0.1_pcc  HpHp_L0.01_weight  HpHp_L0.01_mean  HpHp_L0.01_std  \\\n",
       "0                0.0           1.000000        60.000000        0.000000   \n",
       "1                0.0           5.319895       344.262695        4.710446   \n",
       "2                0.0           6.318264       347.703087        9.034660   \n",
       "3                0.0           1.000000       337.000000        0.000000   \n",
       "4                0.0           1.000000        60.000000        0.000000   \n",
       "...              ...                ...              ...             ...   \n",
       "49543            0.0           4.218824       102.000000        0.000000   \n",
       "49544            0.0           4.218838       102.000000        0.000000   \n",
       "49545            0.0           4.179949       102.000000        0.000002   \n",
       "49546            0.0           4.219537       102.000000        0.000001   \n",
       "49547            0.0           4.219212       102.000000        0.000001   \n",
       "\n",
       "       HpHp_L0.01_magnitude  HpHp_L0.01_radius  HpHp_L0.01_covariance  \\\n",
       "0                 60.000000       0.000000e+00           0.000000e+00   \n",
       "1                344.262695       2.218830e+01           0.000000e+00   \n",
       "2                347.703087       8.162508e+01           0.000000e+00   \n",
       "3                337.000000       0.000000e+00           0.000000e+00   \n",
       "4                 60.000000       0.000000e+00           0.000000e+00   \n",
       "...                     ...                ...                    ...   \n",
       "49543            144.249783       1.820000e-12           5.970000e-23   \n",
       "49544            144.249783       3.640000e-12          -1.100000e-29   \n",
       "49545            144.249783       5.140000e-12           8.230000e-29   \n",
       "49546            144.249783       1.820000e-12           5.960000e-29   \n",
       "49547            144.249783       2.570000e-12           2.920000e-26   \n",
       "\n",
       "       HpHp_L0.01_pcc  y  \n",
       "0        0.000000e+00  0  \n",
       "1        0.000000e+00  0  \n",
       "2        0.000000e+00  0  \n",
       "3        0.000000e+00  0  \n",
       "4        0.000000e+00  0  \n",
       "...               ... ..  \n",
       "49543    0.000000e+00  0  \n",
       "49544    0.000000e+00  0  \n",
       "49545    2.260000e-17  0  \n",
       "49546    0.000000e+00  0  \n",
       "49547    1.600000e-14  0  \n",
       "\n",
       "[49548 rows x 116 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_benign = pd.read_csv(f'{base_dataset_dir}/{benign_file_name}')\n",
    "\n",
    "# raw data frame\n",
    "df_benign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MI_dir_L5_weight</th>\n",
       "      <th>MI_dir_L3_weight</th>\n",
       "      <th>MI_dir_L1_weight</th>\n",
       "      <th>MI_dir_L0.1_weight</th>\n",
       "      <th>MI_dir_L0.01_weight</th>\n",
       "      <th>H_L5_weight</th>\n",
       "      <th>H_L3_weight</th>\n",
       "      <th>H_L1_weight</th>\n",
       "      <th>H_L0.1_weight</th>\n",
       "      <th>H_L0.01_weight</th>\n",
       "      <th>...</th>\n",
       "      <th>HH_jit_L5_weight</th>\n",
       "      <th>HH_jit_L3_weight</th>\n",
       "      <th>HH_jit_L1_weight</th>\n",
       "      <th>HH_jit_L0.1_weight</th>\n",
       "      <th>HH_jit_L0.01_weight</th>\n",
       "      <th>HpHp_L5_weight</th>\n",
       "      <th>HpHp_L3_weight</th>\n",
       "      <th>HpHp_L1_weight</th>\n",
       "      <th>HpHp_L0.1_weight</th>\n",
       "      <th>HpHp_L0.01_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000032</td>\n",
       "      <td>1.031757</td>\n",
       "      <td>2.597515</td>\n",
       "      <td>5.319895</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000032</td>\n",
       "      <td>1.031757</td>\n",
       "      <td>2.597515</td>\n",
       "      <td>5.319895</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000032</td>\n",
       "      <td>1.031757</td>\n",
       "      <td>2.597515</td>\n",
       "      <td>5.319895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.857879</td>\n",
       "      <td>1.912127</td>\n",
       "      <td>1.969807</td>\n",
       "      <td>1.996939</td>\n",
       "      <td>1.999693</td>\n",
       "      <td>1.857879</td>\n",
       "      <td>1.912156</td>\n",
       "      <td>2.000605</td>\n",
       "      <td>3.589564</td>\n",
       "      <td>6.318264</td>\n",
       "      <td>...</td>\n",
       "      <td>1.857879</td>\n",
       "      <td>1.912156</td>\n",
       "      <td>2.000605</td>\n",
       "      <td>3.589564</td>\n",
       "      <td>6.318264</td>\n",
       "      <td>1.857879</td>\n",
       "      <td>1.912156</td>\n",
       "      <td>2.000605</td>\n",
       "      <td>3.589564</td>\n",
       "      <td>6.318264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.680223</td>\n",
       "      <td>1.793580</td>\n",
       "      <td>1.925828</td>\n",
       "      <td>1.992323</td>\n",
       "      <td>1.999230</td>\n",
       "      <td>1.680223</td>\n",
       "      <td>1.793580</td>\n",
       "      <td>1.925828</td>\n",
       "      <td>1.992323</td>\n",
       "      <td>1.999230</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49543</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000009</td>\n",
       "      <td>2.270210</td>\n",
       "      <td>29.219393</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000009</td>\n",
       "      <td>2.270210</td>\n",
       "      <td>29.219393</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.071582</td>\n",
       "      <td>4.218824</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.071582</td>\n",
       "      <td>4.218824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49544</th>\n",
       "      <td>1.999976</td>\n",
       "      <td>1.999986</td>\n",
       "      <td>2.000004</td>\n",
       "      <td>3.270209</td>\n",
       "      <td>30.219392</td>\n",
       "      <td>1.999976</td>\n",
       "      <td>1.999986</td>\n",
       "      <td>2.000004</td>\n",
       "      <td>3.270209</td>\n",
       "      <td>30.219392</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.071585</td>\n",
       "      <td>4.218838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.071585</td>\n",
       "      <td>4.218838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49545</th>\n",
       "      <td>2.999872</td>\n",
       "      <td>2.999923</td>\n",
       "      <td>2.999983</td>\n",
       "      <td>4.270206</td>\n",
       "      <td>31.219389</td>\n",
       "      <td>2.999872</td>\n",
       "      <td>2.999923</td>\n",
       "      <td>2.999983</td>\n",
       "      <td>4.270206</td>\n",
       "      <td>31.219389</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.071590</td>\n",
       "      <td>4.179949</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.071590</td>\n",
       "      <td>4.179949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49546</th>\n",
       "      <td>3.999664</td>\n",
       "      <td>3.999798</td>\n",
       "      <td>3.999942</td>\n",
       "      <td>5.270200</td>\n",
       "      <td>32.219384</td>\n",
       "      <td>3.999664</td>\n",
       "      <td>3.999798</td>\n",
       "      <td>3.999942</td>\n",
       "      <td>5.270200</td>\n",
       "      <td>32.219384</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.071658</td>\n",
       "      <td>4.219537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.071658</td>\n",
       "      <td>4.219537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49547</th>\n",
       "      <td>4.997694</td>\n",
       "      <td>4.998617</td>\n",
       "      <td>4.999548</td>\n",
       "      <td>6.270148</td>\n",
       "      <td>33.219353</td>\n",
       "      <td>4.997694</td>\n",
       "      <td>4.998617</td>\n",
       "      <td>4.999548</td>\n",
       "      <td>6.270148</td>\n",
       "      <td>33.219353</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.071641</td>\n",
       "      <td>4.219212</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.071641</td>\n",
       "      <td>4.219212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49548 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MI_dir_L5_weight  MI_dir_L3_weight  MI_dir_L1_weight  \\\n",
       "0              1.000000          1.000000          1.000000   \n",
       "1              1.000000          1.000000          1.000000   \n",
       "2              1.857879          1.912127          1.969807   \n",
       "3              1.000000          1.000000          1.000000   \n",
       "4              1.680223          1.793580          1.925828   \n",
       "...                 ...               ...               ...   \n",
       "49543          1.000000          1.000000          1.000009   \n",
       "49544          1.999976          1.999986          2.000004   \n",
       "49545          2.999872          2.999923          2.999983   \n",
       "49546          3.999664          3.999798          3.999942   \n",
       "49547          4.997694          4.998617          4.999548   \n",
       "\n",
       "       MI_dir_L0.1_weight  MI_dir_L0.01_weight  H_L5_weight  H_L3_weight  \\\n",
       "0                1.000000             1.000000     1.000000     1.000000   \n",
       "1                1.000000             1.000000     1.000000     1.000032   \n",
       "2                1.996939             1.999693     1.857879     1.912156   \n",
       "3                1.000000             1.000000     1.000000     1.000000   \n",
       "4                1.992323             1.999230     1.680223     1.793580   \n",
       "...                   ...                  ...          ...          ...   \n",
       "49543            2.270210            29.219393     1.000000     1.000000   \n",
       "49544            3.270209            30.219392     1.999976     1.999986   \n",
       "49545            4.270206            31.219389     2.999872     2.999923   \n",
       "49546            5.270200            32.219384     3.999664     3.999798   \n",
       "49547            6.270148            33.219353     4.997694     4.998617   \n",
       "\n",
       "       H_L1_weight  H_L0.1_weight  H_L0.01_weight  ...  HH_jit_L5_weight  \\\n",
       "0         1.000000       1.000000        1.000000  ...          1.000000   \n",
       "1         1.031757       2.597515        5.319895  ...          1.000000   \n",
       "2         2.000605       3.589564        6.318264  ...          1.857879   \n",
       "3         1.000000       1.000000        1.000000  ...          1.000000   \n",
       "4         1.925828       1.992323        1.999230  ...          1.000000   \n",
       "...            ...            ...             ...  ...               ...   \n",
       "49543     1.000009       2.270210       29.219393  ...          1.000000   \n",
       "49544     2.000004       3.270209       30.219392  ...          1.000000   \n",
       "49545     2.999983       4.270206       31.219389  ...          1.000000   \n",
       "49546     3.999942       5.270200       32.219384  ...          1.000000   \n",
       "49547     4.999548       6.270148       33.219353  ...          1.000000   \n",
       "\n",
       "       HH_jit_L3_weight  HH_jit_L1_weight  HH_jit_L0.1_weight  \\\n",
       "0              1.000000          1.000000            1.000000   \n",
       "1              1.000032          1.031757            2.597515   \n",
       "2              1.912156          2.000605            3.589564   \n",
       "3              1.000000          1.000000            1.000000   \n",
       "4              1.000000          1.000000            1.000000   \n",
       "...                 ...               ...                 ...   \n",
       "49543          1.000000          1.000000            1.071582   \n",
       "49544          1.000000          1.000000            1.071585   \n",
       "49545          1.000000          1.000000            1.071590   \n",
       "49546          1.000000          1.000000            1.071658   \n",
       "49547          1.000000          1.000000            1.071641   \n",
       "\n",
       "       HH_jit_L0.01_weight  HpHp_L5_weight  HpHp_L3_weight  HpHp_L1_weight  \\\n",
       "0                 1.000000        1.000000        1.000000        1.000000   \n",
       "1                 5.319895        1.000000        1.000032        1.031757   \n",
       "2                 6.318264        1.857879        1.912156        2.000605   \n",
       "3                 1.000000        1.000000        1.000000        1.000000   \n",
       "4                 1.000000        1.000000        1.000000        1.000000   \n",
       "...                    ...             ...             ...             ...   \n",
       "49543             4.218824        1.000000        1.000000        1.000000   \n",
       "49544             4.218838        1.000000        1.000000        1.000000   \n",
       "49545             4.179949        1.000000        1.000000        1.000000   \n",
       "49546             4.219537        1.000000        1.000000        1.000000   \n",
       "49547             4.219212        1.000000        1.000000        1.000000   \n",
       "\n",
       "       HpHp_L0.1_weight  HpHp_L0.01_weight  \n",
       "0              1.000000           1.000000  \n",
       "1              2.597515           5.319895  \n",
       "2              3.589564           6.318264  \n",
       "3              1.000000           1.000000  \n",
       "4              1.000000           1.000000  \n",
       "...                 ...                ...  \n",
       "49543          1.071582           4.218824  \n",
       "49544          1.071585           4.218838  \n",
       "49545          1.071590           4.179949  \n",
       "49546          1.071658           4.219537  \n",
       "49547          1.071641           4.219212  \n",
       "\n",
       "[49548 rows x 25 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only pick \"weight\" columns\n",
    "\n",
    "df_benign_weight = df_benign[df_benign.columns[df_benign.columns.str.contains('weight')].to_list()]\n",
    "df_benign_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_benign_pics_1, list_benign_pics_2 = np.array_split(df_benign_weight, 2)\n",
    "list_benign_pics_1 = np.array_split(list_benign_pics_1.to_numpy()[:-(len(list_benign_pics_1) % chunk_size_1)], len(list_benign_pics_1) // chunk_size_1)\n",
    "list_benign_pics_2 = np.array_split(list_benign_pics_2.to_numpy()[:-(len(list_benign_pics_2) % chunk_size_2)], len(list_benign_pics_2) // chunk_size_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242\n",
      "485\n"
     ]
    }
   ],
   "source": [
    "print(len(list_benign_pics_1))\n",
    "print(len(list_benign_pics_2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### contoh gambar yang dihasilkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABkAAAAiCAIAAAAlNuVaAAADQ0lEQVR4nM3Sa0iTYRQH8OOablNz5jQvI8c0UamJKyNM7TlRaS2STJ0WXaQiSu1CFynDpmWQWll20bKMct4jo5tOq5FhZeWtTO3mHRK7vegCnba3DwaC9cqbGPTp/+V3zvOcwwEAAACKTEz+f43+0FBnnM4HoIjWtiZIChTpSXC4LTpEkUX1ycK7T7iYbtl5KS3ABv/kgC1k4YARup8Mf9Oi+UE4z2rfWWUYiJPUayg4kSYBGY7TY/poIl1pmfbAQJN1d963tWh+EKcN0EbkGQZiiJkr9TMCVH+K89lWYo773n6UfFxsjyOQhQO2kIX7X89iHIVfnraulXfoydHHDoPxN4dIuO2hVs86A2mHyAtwoo0mW46leTUP0cxwlPvHI1LACNqX+Q66vOaiJOqiyS6dMUapor2uL+ShUfHq1IOfeVjf3dluauDhiOOsHYapsmGoFQ/DfjVoK8zFlfpCV13hQHVeqcrOzvn5qdPH/TSq+J0Po/YFcpbZO87hTnn1IfgR16FSX+iqA3+aZN7XHk5PpUnjmbgyj7c0CVOdeDV7iCYcO9GDLJppN78nR7ZZ5tphc6Sg8Gx4R1ZDkNXZ/BrZ9ns+k6uvCZKDtUFXI8uSPaIHhbh7r6zicgMfvdXhpbOCzHBHSU3iF4UFVpULjkW9FOLWqmTwiB4U4sQsfxyFiki55Z0EimSfH8hyj+sj3iUvTt8Uc1EJ33t9lidaYawu6VZYswgZ4Sg3YT9jSOb7cpvR1MsBiuTkHj+ylEORNd387ib7PuIZsf2iJsQKV0+qm1UbZosjDsaGnvm1ZgAUKe/65j8HKFIvP1NfR1HEQ5+Tmzt/ElalJEZa7OL9ciwg61Gz3awXf9tkIHxfU81yE5qsaRQ0aVcZ4bmAdK9axVTM47vnpCjFyMJBTopSzP7lMXMchUkb7wfuduFhmeDclZkHeLh+wZ6eSqUA1eAdu2SbwgG/mjVeVSklyAhHuQn7GUMy31dIuaRnhbMQYwZCeW37hRgGxMm1yBL79aEtEQpHvNEE1qRIiiMOxob/fPmMeTdweld/kgjXf22V+5eKcFpgcXxCgTVK1PaOpi5STJVcyZxX5IwsHGTOK3L+y1GY8iduqu4c2ng35wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=25x34>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mencoba salah satu untuk list beign pic 1\n",
    "\n",
    "arr = list_benign_pics_1[0]\n",
    "\n",
    "\n",
    "\n",
    "a = arr.size/3\n",
    "a = a/25\n",
    "\n",
    "Image.fromarray(arr.reshape(int(a), 25, 3), mode='RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABkAAAARCAIAAACn2JBZAAACJUlEQVR4nGNY1HXtkfl/dgd/+01/2/+zOxQlrTpYy8XhkNbQ/4qTVcjhtsDrZd+/2TsQoY5h2fdv9g4MDAwMDAwf7NHptQIts7+ofrS/99so4OwDAQLqGIhViFDX7GEgs+gZvwMjq2njkQ/8Dv8jmkOPMwk4XGLQSzddzSLm0CnJlVtc7YBbIZo67BYzfLAPO/uW673qR/uSSp3Hp/C4kIA6BpwKn7q+rNn/UdhBO33xv4Lvwg4asTZbyphEHNK3b5JbwCLlYHa3YkbRbwckdQz4FeJy4ZJp3k3vVD/aq3cE6ZyGu5BohWQYOM/yHbcswwd7sbXnH55sYnd4wur8eJU4ZrLBoo4Bq8LUuyfYGRg+2Cv/Cf52qeyrfcg2h0zXRnUC6hhwKzTY4cLAwPDBnvtFmcAr50/2BZ+3pC21FHVY/mcrGwPDB/ub0r8fyDB8sN824eeDTdUf7HUY1okmpEzkcOjSvfTvGas9boUE1MWevcLAsKn6g/28bZMmaSj8tzcryBIJ2KSBVSE2dRjpC+YV2d//ii45fLLvF+Q5ws0nheHl5St3ZnEzfLBf+uLr0yvz/9tPcVrjoLrKBk0d0QoR9KYEs34D1Y/2JSGdDkk7oMmBkeGDPYPAQYhCKL2p4PvdC++T+P2Tvc7w6V+45/HhAIo8LnUM4g6KFy7//2/Pd+BBzdP//+2vfdHxYmRgcIhcGD/55Xl2h75kWwnVVbYORKgDAABY0UwyCTODAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=25x17>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mencoba salah satu untuk list beign pic 2\n",
    "\n",
    "arr = list_benign_pics_2[0]\n",
    "a = arr.size/3\n",
    "a = a/25\n",
    "\n",
    "Image.fromarray(arr.reshape(int(a), 25, 3), mode='RGB')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### menyimpan gambar yang dihasilkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_image_dir = f'{base_generated_image_dir}/{benign_file_name[:-4]}'\n",
    "os.system(f'mkdir {benign_image_dir}')\n",
    "for i  in range(len(list_benign_pics_1)):\n",
    "    a = list_benign_pics_1[i].size // 3\n",
    "    a = a // 25\n",
    "    Image.fromarray(list_benign_pics_1[i].reshape(a, 25, 3), mode='RGB').save(f'{benign_image_dir}/pic1_{i}.png')\n",
    "\n",
    "for i  in range(len(list_benign_pics_2)):\n",
    "    a = list_benign_pics_2[i].size/3\n",
    "    a = a/25\n",
    "    Image.fromarray(list_benign_pics_2[i].reshape(a, 25, 3), mode='RGB').save(f'{benign_image_dir}/pic2_{i}.png')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### untuk dataset mirai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MI_dir_L5_weight</th>\n",
       "      <th>MI_dir_L5_mean</th>\n",
       "      <th>MI_dir_L5_variance</th>\n",
       "      <th>MI_dir_L3_weight</th>\n",
       "      <th>MI_dir_L3_mean</th>\n",
       "      <th>MI_dir_L3_variance</th>\n",
       "      <th>MI_dir_L1_weight</th>\n",
       "      <th>MI_dir_L1_mean</th>\n",
       "      <th>MI_dir_L1_variance</th>\n",
       "      <th>MI_dir_L0.1_weight</th>\n",
       "      <th>...</th>\n",
       "      <th>HpHp_L0.1_covariance</th>\n",
       "      <th>HpHp_L0.1_pcc</th>\n",
       "      <th>HpHp_L0.01_weight</th>\n",
       "      <th>HpHp_L0.01_mean</th>\n",
       "      <th>HpHp_L0.01_std</th>\n",
       "      <th>HpHp_L0.01_magnitude</th>\n",
       "      <th>HpHp_L0.01_radius</th>\n",
       "      <th>HpHp_L0.01_covariance</th>\n",
       "      <th>HpHp_L0.01_pcc</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.996585</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>5.820766e-11</td>\n",
       "      <td>1.997950</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>5.820766e-11</td>\n",
       "      <td>1.999316</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.999932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.958989</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.975291</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>5.820766e-11</td>\n",
       "      <td>2.991729</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>5.820766e-11</td>\n",
       "      <td>2.999171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.958979</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.975285</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.991727</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>1.164153e-10</td>\n",
       "      <td>3.999171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.914189</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>1.164153e-10</td>\n",
       "      <td>4.948239</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>5.820766e-11</td>\n",
       "      <td>4.982654</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>5.820766e-11</td>\n",
       "      <td>4.998261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102190</th>\n",
       "      <td>149.120959</td>\n",
       "      <td>250.662823</td>\n",
       "      <td>6.012308e+04</td>\n",
       "      <td>230.049109</td>\n",
       "      <td>306.976684</td>\n",
       "      <td>6.397272e+04</td>\n",
       "      <td>650.841283</td>\n",
       "      <td>368.905880</td>\n",
       "      <td>6.088352e+04</td>\n",
       "      <td>6295.232865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102191</th>\n",
       "      <td>150.118494</td>\n",
       "      <td>249.392741</td>\n",
       "      <td>5.996312e+04</td>\n",
       "      <td>231.046828</td>\n",
       "      <td>305.907738</td>\n",
       "      <td>6.395870e+04</td>\n",
       "      <td>651.839132</td>\n",
       "      <td>368.431981</td>\n",
       "      <td>6.093628e+04</td>\n",
       "      <td>6296.230784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102192</th>\n",
       "      <td>151.117874</td>\n",
       "      <td>248.139463</td>\n",
       "      <td>5.980211e+04</td>\n",
       "      <td>232.046256</td>\n",
       "      <td>304.848002</td>\n",
       "      <td>6.394254e+04</td>\n",
       "      <td>652.838593</td>\n",
       "      <td>367.959533</td>\n",
       "      <td>6.098844e+04</td>\n",
       "      <td>6297.230264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102193</th>\n",
       "      <td>150.827162</td>\n",
       "      <td>246.892078</td>\n",
       "      <td>5.963874e+04</td>\n",
       "      <td>231.855059</td>\n",
       "      <td>303.791963</td>\n",
       "      <td>6.392421e+04</td>\n",
       "      <td>652.719572</td>\n",
       "      <td>367.487723</td>\n",
       "      <td>6.104007e+04</td>\n",
       "      <td>6297.150032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102194</th>\n",
       "      <td>151.162744</td>\n",
       "      <td>245.655715</td>\n",
       "      <td>5.947375e+04</td>\n",
       "      <td>232.241702</td>\n",
       "      <td>302.742229</td>\n",
       "      <td>6.390378e+04</td>\n",
       "      <td>653.143489</td>\n",
       "      <td>367.016942</td>\n",
       "      <td>6.109116e+04</td>\n",
       "      <td>6297.594031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102195 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MI_dir_L5_weight  MI_dir_L5_mean  MI_dir_L5_variance  \\\n",
       "0               1.000000      566.000000        0.000000e+00   \n",
       "1               1.996585      566.000000        5.820766e-11   \n",
       "2               2.958989      566.000000        0.000000e+00   \n",
       "3               3.958979      566.000000        0.000000e+00   \n",
       "4               4.914189      566.000000        1.164153e-10   \n",
       "...                  ...             ...                 ...   \n",
       "102190        149.120959      250.662823        6.012308e+04   \n",
       "102191        150.118494      249.392741        5.996312e+04   \n",
       "102192        151.117874      248.139463        5.980211e+04   \n",
       "102193        150.827162      246.892078        5.963874e+04   \n",
       "102194        151.162744      245.655715        5.947375e+04   \n",
       "\n",
       "        MI_dir_L3_weight  MI_dir_L3_mean  MI_dir_L3_variance  \\\n",
       "0               1.000000      566.000000        0.000000e+00   \n",
       "1               1.997950      566.000000        5.820766e-11   \n",
       "2               2.975291      566.000000        5.820766e-11   \n",
       "3               3.975285      566.000000        0.000000e+00   \n",
       "4               4.948239      566.000000        5.820766e-11   \n",
       "...                  ...             ...                 ...   \n",
       "102190        230.049109      306.976684        6.397272e+04   \n",
       "102191        231.046828      305.907738        6.395870e+04   \n",
       "102192        232.046256      304.848002        6.394254e+04   \n",
       "102193        231.855059      303.791963        6.392421e+04   \n",
       "102194        232.241702      302.742229        6.390378e+04   \n",
       "\n",
       "        MI_dir_L1_weight  MI_dir_L1_mean  MI_dir_L1_variance  \\\n",
       "0               1.000000      566.000000        0.000000e+00   \n",
       "1               1.999316      566.000000        0.000000e+00   \n",
       "2               2.991729      566.000000        5.820766e-11   \n",
       "3               3.991727      566.000000        1.164153e-10   \n",
       "4               4.982654      566.000000        5.820766e-11   \n",
       "...                  ...             ...                 ...   \n",
       "102190        650.841283      368.905880        6.088352e+04   \n",
       "102191        651.839132      368.431981        6.093628e+04   \n",
       "102192        652.838593      367.959533        6.098844e+04   \n",
       "102193        652.719572      367.487723        6.104007e+04   \n",
       "102194        653.143489      367.016942        6.109116e+04   \n",
       "\n",
       "        MI_dir_L0.1_weight  ...  HpHp_L0.1_covariance  HpHp_L0.1_pcc  \\\n",
       "0                 1.000000  ...                   0.0            0.0   \n",
       "1                 1.999932  ...                   0.0            0.0   \n",
       "2                 2.999171  ...                   0.0            0.0   \n",
       "3                 3.999171  ...                   0.0            0.0   \n",
       "4                 4.998261  ...                   0.0            0.0   \n",
       "...                    ...  ...                   ...            ...   \n",
       "102190         6295.232865  ...                   0.0            0.0   \n",
       "102191         6296.230784  ...                   0.0            0.0   \n",
       "102192         6297.230264  ...                   0.0            0.0   \n",
       "102193         6297.150032  ...                   0.0            0.0   \n",
       "102194         6297.594031  ...                   0.0            0.0   \n",
       "\n",
       "        HpHp_L0.01_weight  HpHp_L0.01_mean  HpHp_L0.01_std  \\\n",
       "0                     1.0            566.0             0.0   \n",
       "1                     1.0            566.0             0.0   \n",
       "2                     1.0            566.0             0.0   \n",
       "3                     1.0            566.0             0.0   \n",
       "4                     1.0            566.0             0.0   \n",
       "...                   ...              ...             ...   \n",
       "102190                1.0             60.0             0.0   \n",
       "102191                1.0             60.0             0.0   \n",
       "102192                1.0             60.0             0.0   \n",
       "102193                1.0             60.0             0.0   \n",
       "102194                1.0             60.0             0.0   \n",
       "\n",
       "        HpHp_L0.01_magnitude  HpHp_L0.01_radius  HpHp_L0.01_covariance  \\\n",
       "0                      566.0                0.0                    0.0   \n",
       "1                      566.0                0.0                    0.0   \n",
       "2                      566.0                0.0                    0.0   \n",
       "3                      566.0                0.0                    0.0   \n",
       "4                      566.0                0.0                    0.0   \n",
       "...                      ...                ...                    ...   \n",
       "102190                  60.0                0.0                    0.0   \n",
       "102191                  60.0                0.0                    0.0   \n",
       "102192                  60.0                0.0                    0.0   \n",
       "102193                  60.0                0.0                    0.0   \n",
       "102194                  60.0                0.0                    0.0   \n",
       "\n",
       "        HpHp_L0.01_pcc  y  \n",
       "0                  0.0  1  \n",
       "1                  0.0  1  \n",
       "2                  0.0  1  \n",
       "3                  0.0  1  \n",
       "4                  0.0  1  \n",
       "...                ... ..  \n",
       "102190             0.0  1  \n",
       "102191             0.0  1  \n",
       "102192             0.0  1  \n",
       "102193             0.0  1  \n",
       "102194             0.0  1  \n",
       "\n",
       "[102195 rows x 116 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mirai = pd.read_csv(f'{base_dataset_dir}/{mirai_file_name}')\n",
    "\n",
    "# raw data frame\n",
    "df_mirai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MI_dir_L5_weight</th>\n",
       "      <th>MI_dir_L3_weight</th>\n",
       "      <th>MI_dir_L1_weight</th>\n",
       "      <th>MI_dir_L0.1_weight</th>\n",
       "      <th>MI_dir_L0.01_weight</th>\n",
       "      <th>H_L5_weight</th>\n",
       "      <th>H_L3_weight</th>\n",
       "      <th>H_L1_weight</th>\n",
       "      <th>H_L0.1_weight</th>\n",
       "      <th>H_L0.01_weight</th>\n",
       "      <th>...</th>\n",
       "      <th>HH_jit_L5_weight</th>\n",
       "      <th>HH_jit_L3_weight</th>\n",
       "      <th>HH_jit_L1_weight</th>\n",
       "      <th>HH_jit_L0.1_weight</th>\n",
       "      <th>HH_jit_L0.01_weight</th>\n",
       "      <th>HpHp_L5_weight</th>\n",
       "      <th>HpHp_L3_weight</th>\n",
       "      <th>HpHp_L1_weight</th>\n",
       "      <th>HpHp_L0.1_weight</th>\n",
       "      <th>HpHp_L0.01_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.996585</td>\n",
       "      <td>1.997950</td>\n",
       "      <td>1.999316</td>\n",
       "      <td>1.999932</td>\n",
       "      <td>1.999993</td>\n",
       "      <td>1.996585</td>\n",
       "      <td>1.997950</td>\n",
       "      <td>1.999316</td>\n",
       "      <td>1.999932</td>\n",
       "      <td>1.999993</td>\n",
       "      <td>...</td>\n",
       "      <td>1.996585</td>\n",
       "      <td>1.997950</td>\n",
       "      <td>1.999316</td>\n",
       "      <td>1.999932</td>\n",
       "      <td>1.999993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.958989</td>\n",
       "      <td>2.975291</td>\n",
       "      <td>2.991729</td>\n",
       "      <td>2.999171</td>\n",
       "      <td>2.999917</td>\n",
       "      <td>2.958989</td>\n",
       "      <td>2.975291</td>\n",
       "      <td>2.991729</td>\n",
       "      <td>2.999171</td>\n",
       "      <td>2.999917</td>\n",
       "      <td>...</td>\n",
       "      <td>2.958989</td>\n",
       "      <td>2.975291</td>\n",
       "      <td>2.991729</td>\n",
       "      <td>2.999171</td>\n",
       "      <td>2.999917</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.958979</td>\n",
       "      <td>3.975285</td>\n",
       "      <td>3.991727</td>\n",
       "      <td>3.999171</td>\n",
       "      <td>3.999917</td>\n",
       "      <td>3.958979</td>\n",
       "      <td>3.975285</td>\n",
       "      <td>3.991727</td>\n",
       "      <td>3.999171</td>\n",
       "      <td>3.999917</td>\n",
       "      <td>...</td>\n",
       "      <td>3.958979</td>\n",
       "      <td>3.975285</td>\n",
       "      <td>3.991727</td>\n",
       "      <td>3.999171</td>\n",
       "      <td>3.999917</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.914189</td>\n",
       "      <td>4.948239</td>\n",
       "      <td>4.982654</td>\n",
       "      <td>4.998261</td>\n",
       "      <td>4.999826</td>\n",
       "      <td>4.914189</td>\n",
       "      <td>4.948239</td>\n",
       "      <td>4.982654</td>\n",
       "      <td>4.998261</td>\n",
       "      <td>4.999826</td>\n",
       "      <td>...</td>\n",
       "      <td>4.914189</td>\n",
       "      <td>4.948239</td>\n",
       "      <td>4.982654</td>\n",
       "      <td>4.998261</td>\n",
       "      <td>4.999826</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102190</th>\n",
       "      <td>149.120959</td>\n",
       "      <td>230.049109</td>\n",
       "      <td>650.841283</td>\n",
       "      <td>6295.232865</td>\n",
       "      <td>52631.999391</td>\n",
       "      <td>149.120959</td>\n",
       "      <td>230.049109</td>\n",
       "      <td>650.841283</td>\n",
       "      <td>6295.232865</td>\n",
       "      <td>52631.999391</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102191</th>\n",
       "      <td>150.118494</td>\n",
       "      <td>231.046828</td>\n",
       "      <td>651.839132</td>\n",
       "      <td>6296.230784</td>\n",
       "      <td>52632.997652</td>\n",
       "      <td>150.118494</td>\n",
       "      <td>231.046828</td>\n",
       "      <td>651.839132</td>\n",
       "      <td>6296.230784</td>\n",
       "      <td>52632.997652</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102192</th>\n",
       "      <td>151.117874</td>\n",
       "      <td>232.046256</td>\n",
       "      <td>652.838593</td>\n",
       "      <td>6297.230264</td>\n",
       "      <td>52633.997217</td>\n",
       "      <td>151.117874</td>\n",
       "      <td>232.046256</td>\n",
       "      <td>652.838593</td>\n",
       "      <td>6297.230264</td>\n",
       "      <td>52633.997217</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102193</th>\n",
       "      <td>150.827162</td>\n",
       "      <td>231.855059</td>\n",
       "      <td>652.719572</td>\n",
       "      <td>6297.150032</td>\n",
       "      <td>52634.094259</td>\n",
       "      <td>150.827162</td>\n",
       "      <td>231.855059</td>\n",
       "      <td>652.719572</td>\n",
       "      <td>6297.150032</td>\n",
       "      <td>52634.094259</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102194</th>\n",
       "      <td>151.162744</td>\n",
       "      <td>232.241702</td>\n",
       "      <td>653.143489</td>\n",
       "      <td>6297.594031</td>\n",
       "      <td>52634.629513</td>\n",
       "      <td>151.162744</td>\n",
       "      <td>232.241702</td>\n",
       "      <td>653.143489</td>\n",
       "      <td>6297.594031</td>\n",
       "      <td>52634.629513</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102195 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MI_dir_L5_weight  MI_dir_L3_weight  MI_dir_L1_weight  \\\n",
       "0               1.000000          1.000000          1.000000   \n",
       "1               1.996585          1.997950          1.999316   \n",
       "2               2.958989          2.975291          2.991729   \n",
       "3               3.958979          3.975285          3.991727   \n",
       "4               4.914189          4.948239          4.982654   \n",
       "...                  ...               ...               ...   \n",
       "102190        149.120959        230.049109        650.841283   \n",
       "102191        150.118494        231.046828        651.839132   \n",
       "102192        151.117874        232.046256        652.838593   \n",
       "102193        150.827162        231.855059        652.719572   \n",
       "102194        151.162744        232.241702        653.143489   \n",
       "\n",
       "        MI_dir_L0.1_weight  MI_dir_L0.01_weight  H_L5_weight  H_L3_weight  \\\n",
       "0                 1.000000             1.000000     1.000000     1.000000   \n",
       "1                 1.999932             1.999993     1.996585     1.997950   \n",
       "2                 2.999171             2.999917     2.958989     2.975291   \n",
       "3                 3.999171             3.999917     3.958979     3.975285   \n",
       "4                 4.998261             4.999826     4.914189     4.948239   \n",
       "...                    ...                  ...          ...          ...   \n",
       "102190         6295.232865         52631.999391   149.120959   230.049109   \n",
       "102191         6296.230784         52632.997652   150.118494   231.046828   \n",
       "102192         6297.230264         52633.997217   151.117874   232.046256   \n",
       "102193         6297.150032         52634.094259   150.827162   231.855059   \n",
       "102194         6297.594031         52634.629513   151.162744   232.241702   \n",
       "\n",
       "        H_L1_weight  H_L0.1_weight  H_L0.01_weight  ...  HH_jit_L5_weight  \\\n",
       "0          1.000000       1.000000        1.000000  ...          1.000000   \n",
       "1          1.999316       1.999932        1.999993  ...          1.996585   \n",
       "2          2.991729       2.999171        2.999917  ...          2.958989   \n",
       "3          3.991727       3.999171        3.999917  ...          3.958979   \n",
       "4          4.982654       4.998261        4.999826  ...          4.914189   \n",
       "...             ...            ...             ...  ...               ...   \n",
       "102190   650.841283    6295.232865    52631.999391  ...          1.000000   \n",
       "102191   651.839132    6296.230784    52632.997652  ...          1.000000   \n",
       "102192   652.838593    6297.230264    52633.997217  ...          1.000000   \n",
       "102193   652.719572    6297.150032    52634.094259  ...          1.000000   \n",
       "102194   653.143489    6297.594031    52634.629513  ...          1.000000   \n",
       "\n",
       "        HH_jit_L3_weight  HH_jit_L1_weight  HH_jit_L0.1_weight  \\\n",
       "0               1.000000          1.000000            1.000000   \n",
       "1               1.997950          1.999316            1.999932   \n",
       "2               2.975291          2.991729            2.999171   \n",
       "3               3.975285          3.991727            3.999171   \n",
       "4               4.948239          4.982654            4.998261   \n",
       "...                  ...               ...                 ...   \n",
       "102190          1.000000          1.000000            1.000000   \n",
       "102191          1.000000          1.000000            1.000000   \n",
       "102192          1.000000          1.000000            1.000000   \n",
       "102193          1.000000          1.000000            1.000000   \n",
       "102194          1.000000          1.000000            1.000000   \n",
       "\n",
       "        HH_jit_L0.01_weight  HpHp_L5_weight  HpHp_L3_weight  HpHp_L1_weight  \\\n",
       "0                  1.000000             1.0             1.0             1.0   \n",
       "1                  1.999993             1.0             1.0             1.0   \n",
       "2                  2.999917             1.0             1.0             1.0   \n",
       "3                  3.999917             1.0             1.0             1.0   \n",
       "4                  4.999826             1.0             1.0             1.0   \n",
       "...                     ...             ...             ...             ...   \n",
       "102190             1.000000             1.0             1.0             1.0   \n",
       "102191             1.000000             1.0             1.0             1.0   \n",
       "102192             1.000000             1.0             1.0             1.0   \n",
       "102193             1.000000             1.0             1.0             1.0   \n",
       "102194             1.000000             1.0             1.0             1.0   \n",
       "\n",
       "        HpHp_L0.1_weight  HpHp_L0.01_weight  \n",
       "0                    1.0                1.0  \n",
       "1                    1.0                1.0  \n",
       "2                    1.0                1.0  \n",
       "3                    1.0                1.0  \n",
       "4                    1.0                1.0  \n",
       "...                  ...                ...  \n",
       "102190               1.0                1.0  \n",
       "102191               1.0                1.0  \n",
       "102192               1.0                1.0  \n",
       "102193               1.0                1.0  \n",
       "102194               1.0                1.0  \n",
       "\n",
       "[102195 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only pick \"weight\" columns\n",
    "\n",
    "df_mirai_weight = df_mirai[df_mirai.columns[df_mirai.columns.str.contains('weight')].to_list()]\n",
    "df_mirai_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_mirai_pics_1, list_mirai_pics_2 = np.array_split(df_mirai_weight, 2)\n",
    "\n",
    "list_mirai_pics_1 = np.array_split(list_mirai_pics_1.to_numpy()[:-(len(list_mirai_pics_1) % chunk_size_1)], len(list_mirai_pics_1) // chunk_size_1)\n",
    "list_mirai_pics_2 = np.array_split(list_mirai_pics_2.to_numpy()[:-(len(list_mirai_pics_2) % chunk_size_2)], len(list_mirai_pics_2) // chunk_size_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "1001\n"
     ]
    }
   ],
   "source": [
    "print(len(list_mirai_pics_1))\n",
    "print(len(list_mirai_pics_2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### contoh gambar yang dihasilkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABkAAAAiCAIAAAAlNuVaAAAED0lEQVR4nMXSf1ATZBgH8NcNWHnApNkNGrK2ITENPCEckGwPEGkMZ5ckEGXH5IfJgrglArMQOBUJCDa6ADHhSBwIAp40lEFykMfx40TERclNfpl6R9Blk4Gwtz923e5sO98/uuuv55/Pvc/7veeLEEIIoT9E/838Px/KmlEwqX9i0f6tgatVS1iUZSzU+a1hUTDyROGdGItcijJuGzG2DQkcIoXW3DM/RjajjPA2xVGaaZDJSQlKGqHB0GTaD/RFGvz4W17pHhMN3Kv4xeOYBhaHSCGBQwSQ+DiGtKOBaxfpIKzI5khH6FBahZudF+lwTn9fvsdEB23Q8dPjmA4EDpFCAocskDTKgLKGyVEzIFXm6YgHGSDc4D+2c4EBJiSZ3hZoYsC36xMOjWEG2IQEDpFCa464Xzk3WupPHWZCsbMqvu08E0rKdwlap5mQe12aaVhlwlHFq+zLmAkWZxcd35asLXtYR2tqnZ4q/26Uu2TorhMrvpo6L3jPeHWk9VNmb7e2jLu07yb7pamy5hxa52LulLigkYsDtEZxVuKUev4fhwg2E/dr/PP0mezNLPD6UCe4rmBBwEykuvA2C+IEaMfppyz48q53SwlmAYFDpJDAIQskjdLnO1M98LMHSEqDY+VRbHhh7MhoYR8bOtDGuYfzy2x4SxOWmojZYBMSOEQKrTnifh1TplCd3Diw2/VBqVLOASdDmM/XoxxY7/cJL/gpB/Tq+O4TmAMWR1GboT3VDMO2mGGne+jjSg//gxmvdRn8VJfuLF3IO7v9r/aQcQrvoxSTA92FH6GsTey6d4plcYhgM+lRKG9K+xtqPb651DORqurf/KR96DN4I/ogcrjr5Wzkn0vuep+fHKXAPIhW/bTQac+D7S/Kaq+m8OBMXajw5DAPdDF03a0VHkR/kILMsMDODJcvmmH5cTPcJTHDyAYChyyQNIqPQlNXXRMLCXm7L5g6kkBX4h01GZQPctTQPXss9AokOJY9WcF9YBM+41x7HsiKhDEwONcSLrwlBcBfGJBalwNrGcKzKxNNkPZ98l51xDWr0Joj7pf4lV8Fv3Nj4cBAfQdHngTthVwNzSsf7E+uPJaKroCvxrPkddQPFreuvoMz2sYW8mYccu2Ggu7ZXVuYjOjVL1LnPj4yKdiY4UEtEhfHM4qGf3GR5Rsv87eFG92De1SPwnwbuYfipd4Lee82npDhrd7UIjG6uR/iuG6HS89Iob+8QNvSnQMN2rS9el0TmCp7JaFv/yuKzbnO/0CEUr5JlT6eq5ncWbPP536mn4e3dj7E6WVd+NCWHfq6MVGtV154hX+1/fMcRSLpwulumsE7Ia4RPjeWa0QN7wyHzGZHyjZoVvWVE4/GYuL4FeKCAMdZiuE57m/qQN+aasw0jwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=25x34>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = list_mirai_pics_1[0]\n",
    "a = arr.size/3\n",
    "a = a/25\n",
    "\n",
    "Image.fromarray(arr.reshape(int(a), 25, 3), mode='RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABkAAAARCAIAAACn2JBZAAADf0lEQVR4nGOYZWUx6yFLlEOOiYrwtQNpDqxmbTHL9jc5sDnNz3pWtMOhWLkoekngYwci1DEdzJL0jP9+/El1pZ1rlrvHqozT/9lnCXzUfPjvtGDUtMLTTHo7QueILHjM3iZjT0AdwwaH1GblhQdCbjowMDAwMDB8sCdEH9r8pLfjXqTDvxQ2kR+r0hxa+uT+nNvR5HCb4Ziv27fCHQ4MJy+qzg187IBTIZq65d07Hx50inAo2hbrfros2UF77jcvht6UagdPv5uZnFobHNbv2m9+NuQmVoXY1KG5mAGnVybKHJ8XzxLlUPLvUYrJ3jSHxKslcix7mxyOyW0uKy/a4cBor6GwOfCxA0Id46MUk9tMPEvyTfbqe6bYcM4p3hC53+lkf/sL+RLNw71v/PxlOG7/Z5fi/yc9yeeIO1NitLXNlS0OATccLiStUuyekRYR+GrvMYcXEf4yHAxZEQ4t6Xbzf3YlO/QcmX2cIb/aYX9wQ/9WrQ0Oh8RmCDOEEh8pLNqWsatiOqTdL4due1x6/ZZD0eNjD8IajLsPXld6eu7W0pjsk6cNjwfGVrosjF319pl0sMX+bY8tr6uxO0Qec5p/wHhh43SltCfGgjF+m04zth0PjK3snFAhbXw1edavozaMCoq3mX1XaUu18pavs/ped/xRrvmbPbsvfDvq+kegdRY+dQwbHJ5nC9w1IMErWX2xzc8Mohwkp5g0519Mcyi+FMj370CTgwzTghsvq5JuC3DFmiddDnzskDVPDqJwyVeIwkdCEIUJNy88LdrhEO9m8cP1S0LULvkDwh7pVy8aulw72hIS6nQ+/GwHQ0pttYMcx4L3q7U3OGyJOloSFnrT4VUlg86d2REOTKvELMKWJjv03+Rdgk0dmosZ7RkYDkIEBFDpKYHhr85H3jbodbo+adO0iM+M51WkuYN2MhgaZKQfPJl1NuihmbTGbdZ657gwqDpGcT5fPAr75jvoxjz0SarUnnJZc9u2KSeWuSc9fnU8hLepUVAgS9G47t/pe8u9gl53rXTQjWFIjHC41Xxl7ZquZIcgzvYtbwqrHer+Huzn1d7gsHIdd3soKelr6xUmy8tv94vm97nECfDUhaTtOf/v3Nvpxjm2qr/zDQxfc20OnbVd0LPzqA1Ti/bB/aIW313eF4fUnY0yOv/Pc9307y//qvLGGIo84ZoTCgBwBA6gBwK/HQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=25x17>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = list_mirai_pics_2[0]\n",
    "a = arr.size/3\n",
    "a = a/25\n",
    "\n",
    "Image.fromarray(arr.reshape(int(a), 25, 3), mode='RGB')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### menyimpan gambar yang dihasilkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘generated_image/1.mirai.ack’: File exists\n"
     ]
    }
   ],
   "source": [
    "mirai_image_dir = f'{base_generated_image_dir}/{mirai_file_name[:-4]}'\n",
    "os.system(f'mkdir {mirai_image_dir}')\n",
    "for i in range(len(list_mirai_pics_1)):\n",
    "    a = list_mirai_pics_1[i].size // 3\n",
    "    a = a // 25\n",
    "    Image.fromarray(list_mirai_pics_1[i].reshape(a, 25, 3), mode='RGB').save(f'{mirai_image_dir}/pic1_{i}.png')\n",
    "\n",
    "for i in range(len(list_mirai_pics_2)):\n",
    "    a = list_mirai_pics_2[i].size // 3\n",
    "    a = a // 25\n",
    "    Image.fromarray(list_mirai_pics_2[i].reshape(a, 25, 3), mode='RGB').save(f'{mirai_image_dir}/pic2_{i}.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### untuk semua file dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.mirai.syn.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘generated_image/8.mirai.syn’: File exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.mirai.udp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘generated_image/8.mirai.udp’: File exists\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "tile cannot extend outside image",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m a \u001b[39m=\u001b[39m list_pics_2[j]\u001b[39m.\u001b[39msize \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m n_image_channel\n\u001b[1;32m     23\u001b[0m a \u001b[39m=\u001b[39m a \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m n_features\n\u001b[0;32m---> 24\u001b[0m Image\u001b[39m.\u001b[39;49mfromarray(list_pics_2[j]\u001b[39m.\u001b[39;49mreshape(a, n_features, n_image_channel), mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mRGB\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39msave(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mimage_dir\u001b[39m}\u001b[39;00m\u001b[39m/pic2_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m.png\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/botnet-image-processing/lib/python3.10/site-packages/PIL/Image.py:3103\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3100\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3101\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mtostring()\n\u001b[0;32m-> 3103\u001b[0m \u001b[39mreturn\u001b[39;00m frombuffer(mode, size, obj, \u001b[39m\"\u001b[39;49m\u001b[39mraw\u001b[39;49m\u001b[39m\"\u001b[39;49m, rawmode, \u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/botnet-image-processing/lib/python3.10/site-packages/PIL/Image.py:3027\u001b[0m, in \u001b[0;36mfrombuffer\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   3024\u001b[0m         im\u001b[39m.\u001b[39mreadonly \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   3025\u001b[0m         \u001b[39mreturn\u001b[39;00m im\n\u001b[0;32m-> 3027\u001b[0m \u001b[39mreturn\u001b[39;00m frombytes(mode, size, data, decoder_name, args)\n",
      "File \u001b[0;32m~/anaconda3/envs/botnet-image-processing/lib/python3.10/site-packages/PIL/Image.py:2969\u001b[0m, in \u001b[0;36mfrombytes\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   2966\u001b[0m     args \u001b[39m=\u001b[39m mode\n\u001b[1;32m   2968\u001b[0m im \u001b[39m=\u001b[39m new(mode, size)\n\u001b[0;32m-> 2969\u001b[0m im\u001b[39m.\u001b[39;49mfrombytes(data, decoder_name, args)\n\u001b[1;32m   2970\u001b[0m \u001b[39mreturn\u001b[39;00m im\n",
      "File \u001b[0;32m~/anaconda3/envs/botnet-image-processing/lib/python3.10/site-packages/PIL/Image.py:825\u001b[0m, in \u001b[0;36mImage.frombytes\u001b[0;34m(self, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[39m# unpack data\u001b[39;00m\n\u001b[1;32m    824\u001b[0m d \u001b[39m=\u001b[39m _getdecoder(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode, decoder_name, args)\n\u001b[0;32m--> 825\u001b[0m d\u001b[39m.\u001b[39;49msetimage(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mim)\n\u001b[1;32m    826\u001b[0m s \u001b[39m=\u001b[39m d\u001b[39m.\u001b[39mdecode(data)\n\u001b[1;32m    828\u001b[0m \u001b[39mif\u001b[39;00m s[\u001b[39m0\u001b[39m] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: tile cannot extend outside image"
     ]
    }
   ],
   "source": [
    "list_dir = os.listdir(base_dataset_dir)\n",
    "list_dir.sort()\n",
    "for dataset_file in list_dir[:-4]:\n",
    "    print(dataset_file)\n",
    "\n",
    "    df = pd.read_csv(f'{base_dataset_dir}/{dataset_file}')\n",
    "    df_weight = df[df.columns[df.columns.str.contains('weight')].to_list()]\n",
    "    n_features = df_weight.shape[1]\n",
    "    list_pics_1, list_pics_2 = np.array_split(df_weight.to_numpy(), 2)\n",
    "    list_pics_1 = np.array_split(list_pics_1[:-(len(list_pics_1) % chunk_size_1)], len(list_pics_1) // chunk_size_1)\n",
    "    list_pics_2 = np.array_split(list_pics_2[:-(len(list_pics_2) % chunk_size_2)], len(list_pics_2) // chunk_size_2)\n",
    "    \n",
    "    image_dir = f'{base_generated_image_dir}/{dataset_file[:-4]}'\n",
    "    os.system(f'mkdir {image_dir}')\n",
    "\n",
    "    for i in range(len(list_pics_1)):\n",
    "        a = list_pics_1[i].size // n_image_channel\n",
    "        a = a // n_features\n",
    "        Image.fromarray(list_pics_1[i].reshape(a, n_features, n_image_channel), mode='RGB').save(f'{image_dir}/pic1_{i}.png')\n",
    "\n",
    "    for j in range(len(list_pics_2)):\n",
    "        a = list_pics_2[j].size // n_image_channel\n",
    "        a = a // n_features\n",
    "        Image.fromarray(list_pics_2[j].reshape(a, n_features, n_image_channel), mode='RGB').save(f'{image_dir}/pic2_{j}.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V2 (Feature Selection)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Untuk semua Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MI_dir_L5_weight</th>\n",
       "      <th>MI_dir_L5_mean</th>\n",
       "      <th>MI_dir_L5_variance</th>\n",
       "      <th>MI_dir_L3_weight</th>\n",
       "      <th>MI_dir_L3_mean</th>\n",
       "      <th>MI_dir_L3_variance</th>\n",
       "      <th>MI_dir_L1_weight</th>\n",
       "      <th>MI_dir_L1_mean</th>\n",
       "      <th>MI_dir_L1_variance</th>\n",
       "      <th>MI_dir_L0.1_weight</th>\n",
       "      <th>...</th>\n",
       "      <th>HpHp_L0.1_covariance</th>\n",
       "      <th>HpHp_L0.1_pcc</th>\n",
       "      <th>HpHp_L0.01_weight</th>\n",
       "      <th>HpHp_L0.01_mean</th>\n",
       "      <th>HpHp_L0.01_std</th>\n",
       "      <th>HpHp_L0.01_magnitude</th>\n",
       "      <th>HpHp_L0.01_radius</th>\n",
       "      <th>HpHp_L0.01_covariance</th>\n",
       "      <th>HpHp_L0.01_pcc</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.319895</td>\n",
       "      <td>344.262695</td>\n",
       "      <td>4.710446</td>\n",
       "      <td>344.262695</td>\n",
       "      <td>22.188299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.857879</td>\n",
       "      <td>360.458980</td>\n",
       "      <td>35.789338</td>\n",
       "      <td>1.912127</td>\n",
       "      <td>360.275733</td>\n",
       "      <td>35.923972</td>\n",
       "      <td>1.969807</td>\n",
       "      <td>360.091968</td>\n",
       "      <td>35.991542</td>\n",
       "      <td>1.996939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.318264</td>\n",
       "      <td>347.703087</td>\n",
       "      <td>9.034660</td>\n",
       "      <td>347.703087</td>\n",
       "      <td>81.625077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.680223</td>\n",
       "      <td>172.140917</td>\n",
       "      <td>18487.448750</td>\n",
       "      <td>1.793580</td>\n",
       "      <td>182.560279</td>\n",
       "      <td>18928.175300</td>\n",
       "      <td>1.925828</td>\n",
       "      <td>193.165753</td>\n",
       "      <td>19153.795810</td>\n",
       "      <td>1.992323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102190</th>\n",
       "      <td>149.120959</td>\n",
       "      <td>250.662823</td>\n",
       "      <td>60123.076387</td>\n",
       "      <td>230.049109</td>\n",
       "      <td>306.976684</td>\n",
       "      <td>63972.719668</td>\n",
       "      <td>650.841283</td>\n",
       "      <td>368.905880</td>\n",
       "      <td>60883.517934</td>\n",
       "      <td>6295.232865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102191</th>\n",
       "      <td>150.118494</td>\n",
       "      <td>249.392741</td>\n",
       "      <td>59963.116605</td>\n",
       "      <td>231.046828</td>\n",
       "      <td>305.907738</td>\n",
       "      <td>63958.699818</td>\n",
       "      <td>651.839132</td>\n",
       "      <td>368.431981</td>\n",
       "      <td>60936.280851</td>\n",
       "      <td>6296.230784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102192</th>\n",
       "      <td>151.117874</td>\n",
       "      <td>248.139463</td>\n",
       "      <td>59802.110713</td>\n",
       "      <td>232.046256</td>\n",
       "      <td>304.848002</td>\n",
       "      <td>63942.544929</td>\n",
       "      <td>652.838593</td>\n",
       "      <td>367.959533</td>\n",
       "      <td>60988.435072</td>\n",
       "      <td>6297.230264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102193</th>\n",
       "      <td>150.827162</td>\n",
       "      <td>246.892078</td>\n",
       "      <td>59638.742689</td>\n",
       "      <td>231.855059</td>\n",
       "      <td>303.791963</td>\n",
       "      <td>63924.212054</td>\n",
       "      <td>652.719572</td>\n",
       "      <td>367.487723</td>\n",
       "      <td>61040.073390</td>\n",
       "      <td>6297.150032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102194</th>\n",
       "      <td>151.162744</td>\n",
       "      <td>245.655715</td>\n",
       "      <td>59473.747270</td>\n",
       "      <td>232.241702</td>\n",
       "      <td>302.742229</td>\n",
       "      <td>63903.778137</td>\n",
       "      <td>653.143489</td>\n",
       "      <td>367.016942</td>\n",
       "      <td>61091.155377</td>\n",
       "      <td>6297.594031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151743 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MI_dir_L5_weight  MI_dir_L5_mean  MI_dir_L5_variance  \\\n",
       "0               1.000000       60.000000            0.000000   \n",
       "1               1.000000      354.000000            0.000000   \n",
       "2               1.857879      360.458980           35.789338   \n",
       "3               1.000000      337.000000            0.000000   \n",
       "4               1.680223      172.140917        18487.448750   \n",
       "...                  ...             ...                 ...   \n",
       "102190        149.120959      250.662823        60123.076387   \n",
       "102191        150.118494      249.392741        59963.116605   \n",
       "102192        151.117874      248.139463        59802.110713   \n",
       "102193        150.827162      246.892078        59638.742689   \n",
       "102194        151.162744      245.655715        59473.747270   \n",
       "\n",
       "        MI_dir_L3_weight  MI_dir_L3_mean  MI_dir_L3_variance  \\\n",
       "0               1.000000       60.000000            0.000000   \n",
       "1               1.000000      354.000000            0.000000   \n",
       "2               1.912127      360.275733           35.923972   \n",
       "3               1.000000      337.000000            0.000000   \n",
       "4               1.793580      182.560279        18928.175300   \n",
       "...                  ...             ...                 ...   \n",
       "102190        230.049109      306.976684        63972.719668   \n",
       "102191        231.046828      305.907738        63958.699818   \n",
       "102192        232.046256      304.848002        63942.544929   \n",
       "102193        231.855059      303.791963        63924.212054   \n",
       "102194        232.241702      302.742229        63903.778137   \n",
       "\n",
       "        MI_dir_L1_weight  MI_dir_L1_mean  MI_dir_L1_variance  \\\n",
       "0               1.000000       60.000000            0.000000   \n",
       "1               1.000000      354.000000            0.000000   \n",
       "2               1.969807      360.091968           35.991542   \n",
       "3               1.000000      337.000000            0.000000   \n",
       "4               1.925828      193.165753        19153.795810   \n",
       "...                  ...             ...                 ...   \n",
       "102190        650.841283      368.905880        60883.517934   \n",
       "102191        651.839132      368.431981        60936.280851   \n",
       "102192        652.838593      367.959533        60988.435072   \n",
       "102193        652.719572      367.487723        61040.073390   \n",
       "102194        653.143489      367.016942        61091.155377   \n",
       "\n",
       "        MI_dir_L0.1_weight  ...  HpHp_L0.1_covariance  HpHp_L0.1_pcc  \\\n",
       "0                 1.000000  ...                   0.0            0.0   \n",
       "1                 1.000000  ...                   0.0            0.0   \n",
       "2                 1.996939  ...                   0.0            0.0   \n",
       "3                 1.000000  ...                   0.0            0.0   \n",
       "4                 1.992323  ...                   0.0            0.0   \n",
       "...                    ...  ...                   ...            ...   \n",
       "102190         6295.232865  ...                   0.0            0.0   \n",
       "102191         6296.230784  ...                   0.0            0.0   \n",
       "102192         6297.230264  ...                   0.0            0.0   \n",
       "102193         6297.150032  ...                   0.0            0.0   \n",
       "102194         6297.594031  ...                   0.0            0.0   \n",
       "\n",
       "        HpHp_L0.01_weight  HpHp_L0.01_mean  HpHp_L0.01_std  \\\n",
       "0                1.000000        60.000000        0.000000   \n",
       "1                5.319895       344.262695        4.710446   \n",
       "2                6.318264       347.703087        9.034660   \n",
       "3                1.000000       337.000000        0.000000   \n",
       "4                1.000000        60.000000        0.000000   \n",
       "...                   ...              ...             ...   \n",
       "102190           1.000000        60.000000        0.000000   \n",
       "102191           1.000000        60.000000        0.000000   \n",
       "102192           1.000000        60.000000        0.000000   \n",
       "102193           1.000000        60.000000        0.000000   \n",
       "102194           1.000000        60.000000        0.000000   \n",
       "\n",
       "        HpHp_L0.01_magnitude  HpHp_L0.01_radius  HpHp_L0.01_covariance  \\\n",
       "0                  60.000000           0.000000                    0.0   \n",
       "1                 344.262695          22.188299                    0.0   \n",
       "2                 347.703087          81.625077                    0.0   \n",
       "3                 337.000000           0.000000                    0.0   \n",
       "4                  60.000000           0.000000                    0.0   \n",
       "...                      ...                ...                    ...   \n",
       "102190             60.000000           0.000000                    0.0   \n",
       "102191             60.000000           0.000000                    0.0   \n",
       "102192             60.000000           0.000000                    0.0   \n",
       "102193             60.000000           0.000000                    0.0   \n",
       "102194             60.000000           0.000000                    0.0   \n",
       "\n",
       "        HpHp_L0.01_pcc  y  \n",
       "0                  0.0  0  \n",
       "1                  0.0  0  \n",
       "2                  0.0  0  \n",
       "3                  0.0  0  \n",
       "4                  0.0  0  \n",
       "...                ... ..  \n",
       "102190             0.0  1  \n",
       "102191             0.0  1  \n",
       "102192             0.0  1  \n",
       "102193             0.0  1  \n",
       "102194             0.0  1  \n",
       "\n",
       "[151743 rows x 116 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_benign = pd.read_csv(f'{base_dataset_dir}/{benign_file_name}')\n",
    "df_benign[\"y\"]=0\n",
    "\n",
    "df_mirai = pd.read_csv(f'{base_dataset_dir}/{mirai_file_name}')\n",
    "df_mirai['y']=1\n",
    "\n",
    "df_all = pd.concat([df_benign, df_mirai])\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MI_dir_L5_weight': 0.9380403801481204,\n",
       " 'MI_dir_L5_mean': 0.849536488314004,\n",
       " 'MI_dir_L5_variance': 0.8699556605587774,\n",
       " 'MI_dir_L3_weight': 0.971799506820516,\n",
       " 'MI_dir_L3_mean': 0.9247447904334171,\n",
       " 'MI_dir_L3_variance': 0.9483019059925422,\n",
       " 'MI_dir_L1_weight': 0.9958591974202889,\n",
       " 'MI_dir_L1_mean': 0.9879421329498745,\n",
       " 'MI_dir_L1_variance': 0.9936301260017302,\n",
       " 'MI_dir_L0.1_weight': 0.9985620779203258,\n",
       " 'MI_dir_L0.1_mean': 0.9993450819667038,\n",
       " 'MI_dir_L0.1_variance': 0.9996985370914365,\n",
       " 'MI_dir_L0.01_weight': 0.8692786985707892,\n",
       " 'MI_dir_L0.01_mean': 0.9997337605716834,\n",
       " 'MI_dir_L0.01_variance': 0.9997792389285077,\n",
       " 'H_L5_weight': 0.9380403801481183,\n",
       " 'H_L5_mean': 0.8495364883142117,\n",
       " 'H_L5_variance': 0.8699556605587729,\n",
       " 'H_L3_weight': 0.9717995068194172,\n",
       " 'H_L3_mean': 0.9247447906501514,\n",
       " 'H_L3_variance': 0.9483019059912471,\n",
       " 'H_L1_weight': 0.9958591973717524,\n",
       " 'H_L1_mean': 0.9879423623530634,\n",
       " 'H_L1_variance': 0.993630125862394,\n",
       " 'H_L0.1_weight': 0.998562077821591,\n",
       " 'H_L0.1_mean': 0.9993504938319061,\n",
       " 'H_L0.1_variance': 0.9996985376930704,\n",
       " 'H_L0.01_weight': 0.869278693919672,\n",
       " 'H_L0.01_mean': 0.9997431401958031,\n",
       " 'H_L0.01_variance': 0.9997792397984782,\n",
       " 'HH_L5_weight': 0.6089679648351712,\n",
       " 'HH_L5_mean': 0.5776482992927802,\n",
       " 'HH_L5_std': 0.03703392215979572,\n",
       " 'HH_L5_magnitude': 0.5258503958005957,\n",
       " 'HH_L5_radius': -0.005917163050491855,\n",
       " 'HH_L5_covariance': -0.01097555893080444,\n",
       " 'HH_L5_pcc': -0.0191795523293861,\n",
       " 'HH_L3_weight': 0.6133223889230772,\n",
       " 'HH_L3_mean': 0.5776521829305581,\n",
       " 'HH_L3_std': 0.039059116408952516,\n",
       " 'HH_L3_magnitude': 0.5258686920363325,\n",
       " 'HH_L3_radius': -0.011292488950477289,\n",
       " 'HH_L3_covariance': -0.012232554413563553,\n",
       " 'HH_L3_pcc': -0.029059421475481684,\n",
       " 'HH_L1_weight': 0.6166535433722492,\n",
       " 'HH_L1_mean': 0.5775063925811255,\n",
       " 'HH_L1_std': -0.0574094808019852,\n",
       " 'HH_L1_magnitude': 0.5256599023675846,\n",
       " 'HH_L1_radius': -0.03174315981439441,\n",
       " 'HH_L1_covariance': -0.014931086627341375,\n",
       " 'HH_L1_pcc': -0.12608332737803418,\n",
       " 'HH_L0.1_weight': 0.6170420364006747,\n",
       " 'HH_L0.1_mean': 0.5765844397024085,\n",
       " 'HH_L0.1_std': -0.3182148226233066,\n",
       " 'HH_L0.1_magnitude': 0.5237491860980504,\n",
       " 'HH_L0.1_radius': -0.1044384048489291,\n",
       " 'HH_L0.1_covariance': -0.08538842008030102,\n",
       " 'HH_L0.1_pcc': -0.2425622222923132,\n",
       " 'HH_L0.01_weight': 0.566514762815599,\n",
       " 'HH_L0.01_mean': 0.5777205803775812,\n",
       " 'HH_L0.01_std': -0.3336000895711833,\n",
       " 'HH_L0.01_magnitude': 0.5246533488330215,\n",
       " 'HH_L0.01_radius': -0.12851003047716134,\n",
       " 'HH_L0.01_covariance': -0.14902819182585497,\n",
       " 'HH_L0.01_pcc': -0.4295080154124813,\n",
       " 'HH_jit_L5_weight': 0.6089679648351712,\n",
       " 'HH_jit_L5_mean': 0.3798743456881619,\n",
       " 'HH_jit_L5_variance': -0.023946353545536096,\n",
       " 'HH_jit_L3_weight': 0.6133223889230772,\n",
       " 'HH_jit_L3_mean': 0.3798053512571903,\n",
       " 'HH_jit_L3_variance': -0.02474107518376816,\n",
       " 'HH_jit_L1_weight': 0.6166535433722492,\n",
       " 'HH_jit_L1_mean': 0.37971440141808216,\n",
       " 'HH_jit_L1_variance': -0.026208472659870037,\n",
       " 'HH_jit_L0.1_weight': 0.6170420364006747,\n",
       " 'HH_jit_L0.1_mean': 0.379514888963855,\n",
       " 'HH_jit_L0.1_variance': -0.03502865751694015,\n",
       " 'HH_jit_L0.01_weight': 0.566514762815599,\n",
       " 'HH_jit_L0.01_mean': 0.3784072801041521,\n",
       " 'HH_jit_L0.01_variance': -0.07175212352868258,\n",
       " 'HpHp_L5_weight': -0.11135859133424199,\n",
       " 'HpHp_L5_mean': 0.5775913983105185,\n",
       " 'HpHp_L5_std': -0.03374970668719544,\n",
       " 'HpHp_L5_magnitude': 0.525066140078925,\n",
       " 'HpHp_L5_radius': -0.02182271824382514,\n",
       " 'HpHp_L5_covariance': -0.010654424756715448,\n",
       " 'HpHp_L5_pcc': -0.00933777993603796,\n",
       " 'HpHp_L3_weight': -0.11326035649919028,\n",
       " 'HpHp_L3_mean': 0.577593093058935,\n",
       " 'HpHp_L3_std': -0.035660974024308276,\n",
       " 'HpHp_L3_magnitude': 0.5250800018119689,\n",
       " 'HpHp_L3_radius': -0.023439490431123408,\n",
       " 'HpHp_L3_covariance': -0.011701095619908905,\n",
       " 'HpHp_L3_pcc': -0.01118988884841979,\n",
       " 'HpHp_L1_weight': -0.11563452669528466,\n",
       " 'HpHp_L1_mean': 0.577589896823667,\n",
       " 'HpHp_L1_std': -0.03641745968131912,\n",
       " 'HpHp_L1_magnitude': 0.5251181372729543,\n",
       " 'HpHp_L1_radius': -0.025095459323821526,\n",
       " 'HpHp_L1_covariance': -0.014159947585669576,\n",
       " 'HpHp_L1_pcc': -0.015265705431806475,\n",
       " 'HpHp_L0.1_weight': -0.468065581766942,\n",
       " 'HpHp_L0.1_mean': 0.5775923058863428,\n",
       " 'HpHp_L0.1_std': -0.03965057357701344,\n",
       " 'HpHp_L0.1_magnitude': 0.5251430238617666,\n",
       " 'HpHp_L0.1_radius': -0.025197973711072894,\n",
       " 'HpHp_L0.1_covariance': -0.01934178024021447,\n",
       " 'HpHp_L0.1_pcc': -0.02191401337729918,\n",
       " 'HpHp_L0.01_weight': -0.930494876675786,\n",
       " 'HpHp_L0.01_mean': 0.5776196534503129,\n",
       " 'HpHp_L0.01_std': -0.06291846405646476,\n",
       " 'HpHp_L0.01_magnitude': 0.52516279503787,\n",
       " 'HpHp_L0.01_radius': -0.027143439253683052,\n",
       " 'HpHp_L0.01_covariance': -0.021607338645837016,\n",
       " 'HpHp_L0.01_pcc': -0.05769552271719446,\n",
       " 'y': 1.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = df_all.corr()\n",
    "\n",
    "corr['y'].to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    116.000000\n",
       "mean       0.380886\n",
       "std        0.455440\n",
       "min       -0.930495\n",
       "25%       -0.024830\n",
       "50%        0.525073\n",
       "75%        0.854472\n",
       "max        1.000000\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr[\"y\"].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MI_dir_L5_weight        0.938040\n",
       "MI_dir_L5_mean          0.849536\n",
       "MI_dir_L5_variance      0.869956\n",
       "MI_dir_L3_weight        0.971800\n",
       "MI_dir_L3_mean          0.924745\n",
       "                          ...   \n",
       "HpHp_L0.1_magnitude     0.525143\n",
       "HpHp_L0.01_weight       0.930495\n",
       "HpHp_L0.01_mean         0.577620\n",
       "HpHp_L0.01_magnitude    0.525163\n",
       "y                       1.000000\n",
       "Name: y, Length: 62, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thr = 0.5\n",
    "\n",
    "abs_corr_y = corr[\"y\"].apply(lambda x: abs(x))\n",
    "abs_corr_y_thresholded = abs_corr_y[abs_corr_y>thr]\n",
    "abs_corr_y_thresholded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    62.000000\n",
       "mean      0.769264\n",
       "std       0.200470\n",
       "min       0.523749\n",
       "25%       0.577592\n",
       "50%       0.849536\n",
       "75%       0.987942\n",
       "max       1.000000\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_corr_y_thresholded.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MI_dir_L5_weight',\n",
       " 'MI_dir_L5_mean',\n",
       " 'MI_dir_L5_variance',\n",
       " 'MI_dir_L3_weight',\n",
       " 'MI_dir_L3_mean',\n",
       " 'MI_dir_L3_variance',\n",
       " 'MI_dir_L1_weight',\n",
       " 'MI_dir_L1_mean',\n",
       " 'MI_dir_L1_variance',\n",
       " 'MI_dir_L0.1_weight',\n",
       " 'MI_dir_L0.1_mean',\n",
       " 'MI_dir_L0.1_variance',\n",
       " 'MI_dir_L0.01_weight',\n",
       " 'MI_dir_L0.01_mean',\n",
       " 'MI_dir_L0.01_variance',\n",
       " 'H_L5_weight',\n",
       " 'H_L5_mean',\n",
       " 'H_L5_variance',\n",
       " 'H_L3_weight',\n",
       " 'H_L3_mean',\n",
       " 'H_L3_variance',\n",
       " 'H_L1_weight',\n",
       " 'H_L1_mean',\n",
       " 'H_L1_variance',\n",
       " 'H_L0.1_weight',\n",
       " 'H_L0.1_mean',\n",
       " 'H_L0.1_variance',\n",
       " 'H_L0.01_weight',\n",
       " 'H_L0.01_mean',\n",
       " 'H_L0.01_variance',\n",
       " 'HH_L5_weight',\n",
       " 'HH_L5_mean',\n",
       " 'HH_L5_magnitude',\n",
       " 'HH_L3_weight',\n",
       " 'HH_L3_mean',\n",
       " 'HH_L3_magnitude',\n",
       " 'HH_L1_weight',\n",
       " 'HH_L1_mean',\n",
       " 'HH_L1_magnitude',\n",
       " 'HH_L0.1_weight',\n",
       " 'HH_L0.1_mean',\n",
       " 'HH_L0.1_magnitude',\n",
       " 'HH_L0.01_weight',\n",
       " 'HH_L0.01_mean',\n",
       " 'HH_L0.01_magnitude',\n",
       " 'HH_jit_L5_weight',\n",
       " 'HH_jit_L3_weight',\n",
       " 'HH_jit_L1_weight',\n",
       " 'HH_jit_L0.1_weight',\n",
       " 'HH_jit_L0.01_weight',\n",
       " 'HpHp_L5_mean',\n",
       " 'HpHp_L5_magnitude',\n",
       " 'HpHp_L3_mean',\n",
       " 'HpHp_L3_magnitude',\n",
       " 'HpHp_L1_mean',\n",
       " 'HpHp_L1_magnitude',\n",
       " 'HpHp_L0.1_mean',\n",
       " 'HpHp_L0.1_magnitude',\n",
       " 'HpHp_L0.01_weight',\n",
       " 'HpHp_L0.01_mean',\n",
       " 'HpHp_L0.01_magnitude',\n",
       " 'y']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_selected = abs_corr_y_thresholded.index.to_list()\n",
    "feature_selected"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Untuk Features \"Weight\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = f'{base_generated_image_dir}/feature_selection/weight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33636/2513895711.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_benign_weight['y'] = 0\n",
      "/tmp/ipykernel_33636/2513895711.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_mirai_weight['y'] = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MI_dir_L5_weight</th>\n",
       "      <th>MI_dir_L3_weight</th>\n",
       "      <th>MI_dir_L1_weight</th>\n",
       "      <th>MI_dir_L0.1_weight</th>\n",
       "      <th>MI_dir_L0.01_weight</th>\n",
       "      <th>H_L5_weight</th>\n",
       "      <th>H_L3_weight</th>\n",
       "      <th>H_L1_weight</th>\n",
       "      <th>H_L0.1_weight</th>\n",
       "      <th>H_L0.01_weight</th>\n",
       "      <th>...</th>\n",
       "      <th>HH_jit_L3_weight</th>\n",
       "      <th>HH_jit_L1_weight</th>\n",
       "      <th>HH_jit_L0.1_weight</th>\n",
       "      <th>HH_jit_L0.01_weight</th>\n",
       "      <th>HpHp_L5_weight</th>\n",
       "      <th>HpHp_L3_weight</th>\n",
       "      <th>HpHp_L1_weight</th>\n",
       "      <th>HpHp_L0.1_weight</th>\n",
       "      <th>HpHp_L0.01_weight</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000032</td>\n",
       "      <td>1.031757</td>\n",
       "      <td>2.597515</td>\n",
       "      <td>5.319895</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000032</td>\n",
       "      <td>1.031757</td>\n",
       "      <td>2.597515</td>\n",
       "      <td>5.319895</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000032</td>\n",
       "      <td>1.031757</td>\n",
       "      <td>2.597515</td>\n",
       "      <td>5.319895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.857879</td>\n",
       "      <td>1.912127</td>\n",
       "      <td>1.969807</td>\n",
       "      <td>1.996939</td>\n",
       "      <td>1.999693</td>\n",
       "      <td>1.857879</td>\n",
       "      <td>1.912156</td>\n",
       "      <td>2.000605</td>\n",
       "      <td>3.589564</td>\n",
       "      <td>6.318264</td>\n",
       "      <td>...</td>\n",
       "      <td>1.912156</td>\n",
       "      <td>2.000605</td>\n",
       "      <td>3.589564</td>\n",
       "      <td>6.318264</td>\n",
       "      <td>1.857879</td>\n",
       "      <td>1.912156</td>\n",
       "      <td>2.000605</td>\n",
       "      <td>3.589564</td>\n",
       "      <td>6.318264</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.680223</td>\n",
       "      <td>1.793580</td>\n",
       "      <td>1.925828</td>\n",
       "      <td>1.992323</td>\n",
       "      <td>1.999230</td>\n",
       "      <td>1.680223</td>\n",
       "      <td>1.793580</td>\n",
       "      <td>1.925828</td>\n",
       "      <td>1.992323</td>\n",
       "      <td>1.999230</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102190</th>\n",
       "      <td>149.120959</td>\n",
       "      <td>230.049109</td>\n",
       "      <td>650.841283</td>\n",
       "      <td>6295.232865</td>\n",
       "      <td>52631.999391</td>\n",
       "      <td>149.120959</td>\n",
       "      <td>230.049109</td>\n",
       "      <td>650.841283</td>\n",
       "      <td>6295.232865</td>\n",
       "      <td>52631.999391</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102191</th>\n",
       "      <td>150.118494</td>\n",
       "      <td>231.046828</td>\n",
       "      <td>651.839132</td>\n",
       "      <td>6296.230784</td>\n",
       "      <td>52632.997652</td>\n",
       "      <td>150.118494</td>\n",
       "      <td>231.046828</td>\n",
       "      <td>651.839132</td>\n",
       "      <td>6296.230784</td>\n",
       "      <td>52632.997652</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102192</th>\n",
       "      <td>151.117874</td>\n",
       "      <td>232.046256</td>\n",
       "      <td>652.838593</td>\n",
       "      <td>6297.230264</td>\n",
       "      <td>52633.997217</td>\n",
       "      <td>151.117874</td>\n",
       "      <td>232.046256</td>\n",
       "      <td>652.838593</td>\n",
       "      <td>6297.230264</td>\n",
       "      <td>52633.997217</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102193</th>\n",
       "      <td>150.827162</td>\n",
       "      <td>231.855059</td>\n",
       "      <td>652.719572</td>\n",
       "      <td>6297.150032</td>\n",
       "      <td>52634.094259</td>\n",
       "      <td>150.827162</td>\n",
       "      <td>231.855059</td>\n",
       "      <td>652.719572</td>\n",
       "      <td>6297.150032</td>\n",
       "      <td>52634.094259</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102194</th>\n",
       "      <td>151.162744</td>\n",
       "      <td>232.241702</td>\n",
       "      <td>653.143489</td>\n",
       "      <td>6297.594031</td>\n",
       "      <td>52634.629513</td>\n",
       "      <td>151.162744</td>\n",
       "      <td>232.241702</td>\n",
       "      <td>653.143489</td>\n",
       "      <td>6297.594031</td>\n",
       "      <td>52634.629513</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151743 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MI_dir_L5_weight  MI_dir_L3_weight  MI_dir_L1_weight  \\\n",
       "0               1.000000          1.000000          1.000000   \n",
       "1               1.000000          1.000000          1.000000   \n",
       "2               1.857879          1.912127          1.969807   \n",
       "3               1.000000          1.000000          1.000000   \n",
       "4               1.680223          1.793580          1.925828   \n",
       "...                  ...               ...               ...   \n",
       "102190        149.120959        230.049109        650.841283   \n",
       "102191        150.118494        231.046828        651.839132   \n",
       "102192        151.117874        232.046256        652.838593   \n",
       "102193        150.827162        231.855059        652.719572   \n",
       "102194        151.162744        232.241702        653.143489   \n",
       "\n",
       "        MI_dir_L0.1_weight  MI_dir_L0.01_weight  H_L5_weight  H_L3_weight  \\\n",
       "0                 1.000000             1.000000     1.000000     1.000000   \n",
       "1                 1.000000             1.000000     1.000000     1.000032   \n",
       "2                 1.996939             1.999693     1.857879     1.912156   \n",
       "3                 1.000000             1.000000     1.000000     1.000000   \n",
       "4                 1.992323             1.999230     1.680223     1.793580   \n",
       "...                    ...                  ...          ...          ...   \n",
       "102190         6295.232865         52631.999391   149.120959   230.049109   \n",
       "102191         6296.230784         52632.997652   150.118494   231.046828   \n",
       "102192         6297.230264         52633.997217   151.117874   232.046256   \n",
       "102193         6297.150032         52634.094259   150.827162   231.855059   \n",
       "102194         6297.594031         52634.629513   151.162744   232.241702   \n",
       "\n",
       "        H_L1_weight  H_L0.1_weight  H_L0.01_weight  ...  HH_jit_L3_weight  \\\n",
       "0          1.000000       1.000000        1.000000  ...          1.000000   \n",
       "1          1.031757       2.597515        5.319895  ...          1.000032   \n",
       "2          2.000605       3.589564        6.318264  ...          1.912156   \n",
       "3          1.000000       1.000000        1.000000  ...          1.000000   \n",
       "4          1.925828       1.992323        1.999230  ...          1.000000   \n",
       "...             ...            ...             ...  ...               ...   \n",
       "102190   650.841283    6295.232865    52631.999391  ...          1.000000   \n",
       "102191   651.839132    6296.230784    52632.997652  ...          1.000000   \n",
       "102192   652.838593    6297.230264    52633.997217  ...          1.000000   \n",
       "102193   652.719572    6297.150032    52634.094259  ...          1.000000   \n",
       "102194   653.143489    6297.594031    52634.629513  ...          1.000000   \n",
       "\n",
       "        HH_jit_L1_weight  HH_jit_L0.1_weight  HH_jit_L0.01_weight  \\\n",
       "0               1.000000            1.000000             1.000000   \n",
       "1               1.031757            2.597515             5.319895   \n",
       "2               2.000605            3.589564             6.318264   \n",
       "3               1.000000            1.000000             1.000000   \n",
       "4               1.000000            1.000000             1.000000   \n",
       "...                  ...                 ...                  ...   \n",
       "102190          1.000000            1.000000             1.000000   \n",
       "102191          1.000000            1.000000             1.000000   \n",
       "102192          1.000000            1.000000             1.000000   \n",
       "102193          1.000000            1.000000             1.000000   \n",
       "102194          1.000000            1.000000             1.000000   \n",
       "\n",
       "        HpHp_L5_weight  HpHp_L3_weight  HpHp_L1_weight  HpHp_L0.1_weight  \\\n",
       "0             1.000000        1.000000        1.000000          1.000000   \n",
       "1             1.000000        1.000032        1.031757          2.597515   \n",
       "2             1.857879        1.912156        2.000605          3.589564   \n",
       "3             1.000000        1.000000        1.000000          1.000000   \n",
       "4             1.000000        1.000000        1.000000          1.000000   \n",
       "...                ...             ...             ...               ...   \n",
       "102190        1.000000        1.000000        1.000000          1.000000   \n",
       "102191        1.000000        1.000000        1.000000          1.000000   \n",
       "102192        1.000000        1.000000        1.000000          1.000000   \n",
       "102193        1.000000        1.000000        1.000000          1.000000   \n",
       "102194        1.000000        1.000000        1.000000          1.000000   \n",
       "\n",
       "        HpHp_L0.01_weight  y  \n",
       "0                1.000000  0  \n",
       "1                5.319895  0  \n",
       "2                6.318264  0  \n",
       "3                1.000000  0  \n",
       "4                1.000000  0  \n",
       "...                   ... ..  \n",
       "102190           1.000000  1  \n",
       "102191           1.000000  1  \n",
       "102192           1.000000  1  \n",
       "102193           1.000000  1  \n",
       "102194           1.000000  1  \n",
       "\n",
       "[151743 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_benign = pd.read_csv(f'{base_dataset_dir}/{benign_file_name}')\n",
    "df_benign_weight = df_benign[df_benign.columns[df_benign.columns.str.contains('weight')].to_list()]\n",
    "df_benign_weight['y'] = 0\n",
    "\n",
    "\n",
    "df_mirai = pd.read_csv(f'{base_dataset_dir}/{mirai_file_name}')\n",
    "df_mirai_weight = df_mirai[df_mirai.columns[df_mirai.columns.str.contains('weight')].to_list()]\n",
    "df_mirai_weight['y'] = 1\n",
    "\n",
    "df_all_weight = pd.concat([df_benign_weight, df_mirai_weight])\n",
    "df_all_weight"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mendapatkan Selected Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MI_dir_L5_weight       0.938040\n",
       "MI_dir_L3_weight       0.971800\n",
       "MI_dir_L1_weight       0.995859\n",
       "MI_dir_L0.1_weight     0.998562\n",
       "MI_dir_L0.01_weight    0.869279\n",
       "H_L5_weight            0.938040\n",
       "H_L3_weight            0.971800\n",
       "H_L1_weight            0.995859\n",
       "H_L0.1_weight          0.998562\n",
       "H_L0.01_weight         0.869279\n",
       "HH_L5_weight           0.608968\n",
       "HH_L3_weight           0.613322\n",
       "HH_L1_weight           0.616654\n",
       "HH_L0.1_weight         0.617042\n",
       "HH_L0.01_weight        0.566515\n",
       "HH_jit_L5_weight       0.608968\n",
       "HH_jit_L3_weight       0.613322\n",
       "HH_jit_L1_weight       0.616654\n",
       "HH_jit_L0.1_weight     0.617042\n",
       "HH_jit_L0.01_weight    0.566515\n",
       "HpHp_L5_weight        -0.111359\n",
       "HpHp_L3_weight        -0.113260\n",
       "HpHp_L1_weight        -0.115635\n",
       "HpHp_L0.1_weight      -0.468066\n",
       "HpHp_L0.01_weight     -0.930495\n",
       "y                      1.000000\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_weight = df_all_weight.corr()\n",
    "\n",
    "corr_weight['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    26.000000\n",
       "mean      0.571280\n",
       "std       0.507294\n",
       "min      -0.930495\n",
       "25%       0.577128\n",
       "50%       0.616848\n",
       "75%       0.963360\n",
       "max       1.000000\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_weight['y'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MI_dir_L5_weight       0.938040\n",
       "MI_dir_L3_weight       0.971800\n",
       "MI_dir_L1_weight       0.995859\n",
       "MI_dir_L0.1_weight     0.998562\n",
       "MI_dir_L0.01_weight    0.869279\n",
       "H_L5_weight            0.938040\n",
       "H_L3_weight            0.971800\n",
       "H_L1_weight            0.995859\n",
       "H_L0.1_weight          0.998562\n",
       "H_L0.01_weight         0.869279\n",
       "HH_L5_weight           0.608968\n",
       "HH_L3_weight           0.613322\n",
       "HH_L1_weight           0.616654\n",
       "HH_L0.1_weight         0.617042\n",
       "HH_L0.01_weight        0.566515\n",
       "HH_jit_L5_weight       0.608968\n",
       "HH_jit_L3_weight       0.613322\n",
       "HH_jit_L1_weight       0.616654\n",
       "HH_jit_L0.1_weight     0.617042\n",
       "HH_jit_L0.01_weight    0.566515\n",
       "HpHp_L0.01_weight      0.930495\n",
       "y                      1.000000\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thr  = 0.5\n",
    "\n",
    "abs_corr_weight_y = corr_weight['y'].apply(lambda x: abs(x))\n",
    "abs_corr_weight_y_thresholded = abs_corr_weight_y[abs_corr_weight_y > thr]\n",
    "abs_corr_weight_y_thresholded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    22.000000\n",
       "mean      0.796481\n",
       "std       0.183220\n",
       "min       0.566515\n",
       "25%       0.614155\n",
       "50%       0.869279\n",
       "75%       0.971800\n",
       "max       1.000000\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_corr_weight_y_thresholded.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MI_dir_L5_weight',\n",
       " 'MI_dir_L3_weight',\n",
       " 'MI_dir_L1_weight',\n",
       " 'MI_dir_L0.1_weight',\n",
       " 'MI_dir_L0.01_weight',\n",
       " 'H_L5_weight',\n",
       " 'H_L3_weight',\n",
       " 'H_L1_weight',\n",
       " 'H_L0.1_weight',\n",
       " 'H_L0.01_weight',\n",
       " 'HH_L5_weight',\n",
       " 'HH_L3_weight',\n",
       " 'HH_L1_weight',\n",
       " 'HH_L0.1_weight',\n",
       " 'HH_L0.01_weight',\n",
       " 'HH_jit_L5_weight',\n",
       " 'HH_jit_L3_weight',\n",
       " 'HH_jit_L1_weight',\n",
       " 'HH_jit_L0.1_weight',\n",
       " 'HH_jit_L0.01_weight',\n",
       " 'HpHp_L0.01_weight',\n",
       " 'y']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_selected = abs_corr_weight_y_thresholded.index.to_list()\n",
    "feature_selected"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### mendapatkan potongan data sesuai dengan \"Selected Feature\" dan convert ke bentuk gambar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# untuk dataset Benign\n",
    "\n",
    "df_benign_selected = df_benign[feature_selected[:-1]]\n",
    "\n",
    "n_features = df_benign_selected.shape[1]\n",
    "list_pics_benign_1, list_pics_benign_2 = np.array_split(df_benign_selected.to_numpy(), 2)\n",
    "   \n",
    "list_pics_benign_1 = np.array_split(list_pics_benign_1[:-(len(list_pics_benign_1) % chunk_size_1)], len(list_pics_benign_1) // chunk_size_1)\n",
    "list_pics_benign_2 = np.array_split(list_pics_benign_2[:-(len(list_pics_benign_2) % chunk_size_2)], len(list_pics_benign_2) // chunk_size_2)\n",
    "\n",
    "\n",
    "for i in range(len(list_pics_benign_1)):\n",
    "    a = list_pics_benign_1[i].size // n_image_channel\n",
    "    a = a // n_features\n",
    "    Image.fromarray(list_pics_benign_1[i].reshape(a, n_features, n_image_channel), mode='RGB').save(f'{image_dir}/benign/pic1_{i}.png')\n",
    "\n",
    "\n",
    "for i in range(len(list_pics_benign_1)):\n",
    "    a = list_pics_benign_2[i].size // n_image_channel\n",
    "    a = a // n_features\n",
    "    Image.fromarray(list_pics_benign_2[i].reshape(a, n_features, n_image_channel), mode='RGB').save(f'{image_dir}/benign/pic2_{i}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# untuk dataset Mirai\n",
    "\n",
    "df_mirai_selected = df_mirai[feature_selected[:-1]]\n",
    "\n",
    "n_features = df_mirai_selected.shape[1]\n",
    "list_pics_mirai_1, list_pics_mirai_2 = np.array_split(df_mirai_selected.to_numpy(), 2)\n",
    "\n",
    "list_pics_mirai_1 = np.array_split(list_pics_mirai_1[:-(len(list_pics_mirai_1) % chunk_size_1)], len(list_pics_mirai_1) // chunk_size_1)\n",
    "list_pics_mirai_2 = np.array_split(list_pics_mirai_2[:-(len(list_pics_mirai_2) % chunk_size_2)], len(list_pics_mirai_2) // chunk_size_2)\n",
    "\n",
    "for i in range(len(list_pics_mirai_1)):\n",
    "    a = list_pics_mirai_1[i].size // n_image_channel\n",
    "    a = a // n_features\n",
    "    Image.fromarray(list_pics_mirai_1[i].reshape(a, n_features, n_image_channel), mode='RGB').save(f'{image_dir}/mirai/pic1_{i}.png')\n",
    "\n",
    "\n",
    "for j in range(len(list_pics_mirai_2)):\n",
    "    a = list_pics_mirai_2[j].size // n_image_channel\n",
    "    a = a // n_features\n",
    "    Image.fromarray(list_pics_mirai_2[j].reshape(a, n_features, n_image_channel), mode='RGB').save(f'{image_dir}/mirai/pic2_{j}.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset gambar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 14:28:58.372612: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-13 14:28:58.936567: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/odhi/anaconda3/envs/botnet-image-processing/lib/\n",
      "2023-04-13 14:28:58.936620: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/odhi/anaconda3/envs/botnet-image-processing/lib/\n",
      "2023-04-13 14:28:58.936626: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2228 files belonging to 2 classes.\n",
      "Using 1783 files for training.\n",
      "Found 2228 files belonging to 2 classes.\n",
      "Using 445 files for validation.\n",
      "['1.benign', '1.mirai.ack']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 14:28:59.452169: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2023-04-13 14:28:59.452192: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: odhiRtxLaptop\n",
      "2023-04-13 14:28:59.452197: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: odhiRtxLaptop\n",
      "2023-04-13 14:28:59.452267: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 525.105.17\n",
      "2023-04-13 14:28:59.452280: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 525.105.17\n",
      "2023-04-13 14:28:59.452283: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 525.105.17\n",
      "2023-04-13 14:28:59.452517: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 2\n",
    "label_mode = 'binary'\n",
    "# dataset_directory = './generated_image/train_data'\n",
    "dataset_directory = './generated_image/v1/weight'\n",
    "# dataset_directory = './generated_image/feature_selection/weight'\n",
    "img_height = 1\n",
    "img_width = 1\n",
    "validation_split = 0.2\n",
    "seed = 111\n",
    "class_name = ['1.benign', '1.mirai.ack']\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=dataset_directory,\n",
    "    validation_split=validation_split,\n",
    "    subset='training',\n",
    "    seed=seed,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    label_mode=label_mode,\n",
    "    class_names=class_name,\n",
    ")\n",
    "\n",
    "validation_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=dataset_directory,\n",
    "    validation_split=validation_split,\n",
    "    subset='validation',\n",
    "    seed=seed,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    label_mode=label_mode,\n",
    "    class_names=class_name,\n",
    ")\n",
    "\n",
    "print(train_ds.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=892>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_ds."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pembuatan model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "892/892 [==============================] - 1s 981us/step - loss: 43.4456 - accuracy: 0.4520 - precision: 0.6633 - recall: 0.3856 - true_negatives: 341.0000 - true_positives: 465.0000 - false_negatives: 741.0000 - false_positives: 236.0000 - val_loss: 26.8097 - val_accuracy: 0.5371 - val_precision: 0.6667 - val_recall: 0.6034 - val_true_negatives: 61.0000 - val_true_positives: 178.0000 - val_false_negatives: 117.0000 - val_false_positives: 89.0000\n",
      "Epoch 2/100\n",
      "892/892 [==============================] - 1s 724us/step - loss: 22.3471 - accuracy: 0.5530 - precision: 0.6792 - recall: 0.6426 - true_negatives: 211.0000 - true_positives: 775.0000 - false_negatives: 431.0000 - false_positives: 366.0000 - val_loss: 18.7903 - val_accuracy: 0.5573 - val_precision: 0.6623 - val_recall: 0.6780 - val_true_negatives: 48.0000 - val_true_positives: 200.0000 - val_false_negatives: 95.0000 - val_false_positives: 102.0000\n",
      "Epoch 3/100\n",
      "892/892 [==============================] - 1s 753us/step - loss: 14.4637 - accuracy: 0.5721 - precision: 0.6847 - recall: 0.6808 - true_negatives: 199.0000 - true_positives: 821.0000 - false_negatives: 385.0000 - false_positives: 378.0000 - val_loss: 10.6760 - val_accuracy: 0.5708 - val_precision: 0.6677 - val_recall: 0.7017 - val_true_negatives: 47.0000 - val_true_positives: 207.0000 - val_false_negatives: 88.0000 - val_false_positives: 103.0000\n",
      "Epoch 4/100\n",
      "892/892 [==============================] - 1s 763us/step - loss: 6.3951 - accuracy: 0.5743 - precision: 0.6849 - recall: 0.6866 - true_negatives: 196.0000 - true_positives: 828.0000 - false_negatives: 378.0000 - false_positives: 381.0000 - val_loss: 2.3963 - val_accuracy: 0.5708 - val_precision: 0.6566 - val_recall: 0.7390 - val_true_negatives: 36.0000 - val_true_positives: 218.0000 - val_false_negatives: 77.0000 - val_false_positives: 114.0000\n",
      "Epoch 5/100\n",
      "892/892 [==============================] - 1s 731us/step - loss: 0.8591 - accuracy: 0.6371 - precision: 0.6800 - recall: 0.8756 - true_negatives: 80.0000 - true_positives: 1056.0000 - false_negatives: 150.0000 - false_positives: 497.0000 - val_loss: 0.6451 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 6/100\n",
      "892/892 [==============================] - 1s 724us/step - loss: 0.6566 - accuracy: 0.6584 - precision: 0.6749 - recall: 0.9552 - true_negatives: 22.0000 - true_positives: 1152.0000 - false_negatives: 54.0000 - false_positives: 555.0000 - val_loss: 0.6486 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 7/100\n",
      "892/892 [==============================] - 1s 705us/step - loss: 0.6612 - accuracy: 0.6568 - precision: 0.6725 - recall: 0.9602 - true_negatives: 13.0000 - true_positives: 1158.0000 - false_negatives: 48.0000 - false_positives: 564.0000 - val_loss: 0.7087 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 8/100\n",
      "892/892 [==============================] - 1s 733us/step - loss: 0.6582 - accuracy: 0.6556 - precision: 0.6754 - recall: 0.9453 - true_negatives: 29.0000 - true_positives: 1140.0000 - false_negatives: 66.0000 - false_positives: 548.0000 - val_loss: 0.6580 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 9/100\n",
      "892/892 [==============================] - 1s 768us/step - loss: 0.6569 - accuracy: 0.6534 - precision: 0.6733 - recall: 0.9469 - true_negatives: 23.0000 - true_positives: 1142.0000 - false_negatives: 64.0000 - false_positives: 554.0000 - val_loss: 0.6979 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 10/100\n",
      "892/892 [==============================] - 1s 753us/step - loss: 0.6606 - accuracy: 0.6489 - precision: 0.6706 - recall: 0.9453 - true_negatives: 17.0000 - true_positives: 1140.0000 - false_negatives: 66.0000 - false_positives: 560.0000 - val_loss: 0.6488 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 11/100\n",
      "892/892 [==============================] - 1s 736us/step - loss: 0.6595 - accuracy: 0.6517 - precision: 0.6738 - recall: 0.9403 - true_negatives: 28.0000 - true_positives: 1134.0000 - false_negatives: 72.0000 - false_positives: 549.0000 - val_loss: 0.6654 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 12/100\n",
      "892/892 [==============================] - 1s 777us/step - loss: 0.6541 - accuracy: 0.6528 - precision: 0.6742 - recall: 0.9420 - true_negatives: 28.0000 - true_positives: 1136.0000 - false_negatives: 70.0000 - false_positives: 549.0000 - val_loss: 0.6360 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 13/100\n",
      "892/892 [==============================] - 1s 757us/step - loss: 0.6557 - accuracy: 0.6573 - precision: 0.6737 - recall: 0.9569 - true_negatives: 18.0000 - true_positives: 1154.0000 - false_negatives: 52.0000 - false_positives: 559.0000 - val_loss: 0.6501 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 14/100\n",
      "892/892 [==============================] - 1s 760us/step - loss: 0.6542 - accuracy: 0.6511 - precision: 0.6749 - recall: 0.9345 - true_negatives: 34.0000 - true_positives: 1127.0000 - false_negatives: 79.0000 - false_positives: 543.0000 - val_loss: 0.6929 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 15/100\n",
      "892/892 [==============================] - 1s 740us/step - loss: 0.6584 - accuracy: 0.6590 - precision: 0.6767 - recall: 0.9494 - true_negatives: 30.0000 - true_positives: 1145.0000 - false_negatives: 61.0000 - false_positives: 547.0000 - val_loss: 0.6738 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 16/100\n",
      "892/892 [==============================] - 1s 719us/step - loss: 0.6604 - accuracy: 0.6511 - precision: 0.6753 - recall: 0.9328 - true_negatives: 36.0000 - true_positives: 1125.0000 - false_negatives: 81.0000 - false_positives: 541.0000 - val_loss: 0.6465 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 17/100\n",
      "892/892 [==============================] - 1s 716us/step - loss: 0.6642 - accuracy: 0.6411 - precision: 0.6699 - recall: 0.9254 - true_negatives: 27.0000 - true_positives: 1116.0000 - false_negatives: 90.0000 - false_positives: 550.0000 - val_loss: 0.6843 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 18/100\n",
      "892/892 [==============================] - 1s 738us/step - loss: 0.6548 - accuracy: 0.6562 - precision: 0.6741 - recall: 0.9519 - true_negatives: 22.0000 - true_positives: 1148.0000 - false_negatives: 58.0000 - false_positives: 555.0000 - val_loss: 0.6651 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 19/100\n",
      "892/892 [==============================] - 1s 740us/step - loss: 0.6561 - accuracy: 0.6534 - precision: 0.6729 - recall: 0.9486 - true_negatives: 21.0000 - true_positives: 1144.0000 - false_negatives: 62.0000 - false_positives: 556.0000 - val_loss: 0.6420 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 20/100\n",
      "892/892 [==============================] - 1s 728us/step - loss: 0.6580 - accuracy: 0.6556 - precision: 0.6760 - recall: 0.9428 - true_negatives: 32.0000 - true_positives: 1137.0000 - false_negatives: 69.0000 - false_positives: 545.0000 - val_loss: 0.7015 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 21/100\n",
      "892/892 [==============================] - 1s 710us/step - loss: 0.6542 - accuracy: 0.6629 - precision: 0.6746 - recall: 0.9693 - true_negatives: 13.0000 - true_positives: 1169.0000 - false_negatives: 37.0000 - false_positives: 564.0000 - val_loss: 0.6507 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 22/100\n",
      "892/892 [==============================] - 1s 726us/step - loss: 0.6559 - accuracy: 0.6534 - precision: 0.6733 - recall: 0.9469 - true_negatives: 23.0000 - true_positives: 1142.0000 - false_negatives: 64.0000 - false_positives: 554.0000 - val_loss: 0.6638 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 23/100\n",
      "892/892 [==============================] - 1s 716us/step - loss: 0.6522 - accuracy: 0.6523 - precision: 0.6719 - recall: 0.9494 - true_negatives: 18.0000 - true_positives: 1145.0000 - false_negatives: 61.0000 - false_positives: 559.0000 - val_loss: 0.6664 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 24/100\n",
      "892/892 [==============================] - 1s 723us/step - loss: 0.6601 - accuracy: 0.6517 - precision: 0.6740 - recall: 0.9395 - true_negatives: 29.0000 - true_positives: 1133.0000 - false_negatives: 73.0000 - false_positives: 548.0000 - val_loss: 0.6480 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 25/100\n",
      "892/892 [==============================] - 1s 730us/step - loss: 0.6585 - accuracy: 0.6517 - precision: 0.6742 - recall: 0.9386 - true_negatives: 30.0000 - true_positives: 1132.0000 - false_negatives: 74.0000 - false_positives: 547.0000 - val_loss: 0.6821 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 26/100\n",
      "892/892 [==============================] - 1s 722us/step - loss: 0.6621 - accuracy: 0.6422 - precision: 0.6692 - recall: 0.9312 - true_negatives: 22.0000 - true_positives: 1123.0000 - false_negatives: 83.0000 - false_positives: 555.0000 - val_loss: 0.6625 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 27/100\n",
      "892/892 [==============================] - 1s 724us/step - loss: 0.6642 - accuracy: 0.6444 - precision: 0.6700 - recall: 0.9345 - true_negatives: 22.0000 - true_positives: 1127.0000 - false_negatives: 79.0000 - false_positives: 555.0000 - val_loss: 0.6776 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 28/100\n",
      "892/892 [==============================] - 1s 741us/step - loss: 0.6617 - accuracy: 0.6495 - precision: 0.6760 - recall: 0.9254 - true_negatives: 42.0000 - true_positives: 1116.0000 - false_negatives: 90.0000 - false_positives: 535.0000 - val_loss: 0.6924 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 29/100\n",
      "892/892 [==============================] - 1s 722us/step - loss: 0.6608 - accuracy: 0.6551 - precision: 0.6756 - recall: 0.9428 - true_negatives: 31.0000 - true_positives: 1137.0000 - false_negatives: 69.0000 - false_positives: 546.0000 - val_loss: 0.6787 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 30/100\n",
      "892/892 [==============================] - 1s 716us/step - loss: 0.6582 - accuracy: 0.6534 - precision: 0.6765 - recall: 0.9345 - true_negatives: 38.0000 - true_positives: 1127.0000 - false_negatives: 79.0000 - false_positives: 539.0000 - val_loss: 0.6957 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 31/100\n",
      "892/892 [==============================] - 1s 728us/step - loss: 0.6554 - accuracy: 0.6601 - precision: 0.6763 - recall: 0.9544 - true_negatives: 26.0000 - true_positives: 1151.0000 - false_negatives: 55.0000 - false_positives: 551.0000 - val_loss: 0.6765 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 32/100\n",
      "892/892 [==============================] - 1s 769us/step - loss: 0.6606 - accuracy: 0.6489 - precision: 0.6708 - recall: 0.9444 - true_negatives: 18.0000 - true_positives: 1139.0000 - false_negatives: 67.0000 - false_positives: 559.0000 - val_loss: 0.6806 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 33/100\n",
      "892/892 [==============================] - 1s 794us/step - loss: 0.6650 - accuracy: 0.6377 - precision: 0.6683 - recall: 0.9221 - true_negatives: 25.0000 - true_positives: 1112.0000 - false_negatives: 94.0000 - false_positives: 552.0000 - val_loss: 0.6740 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 34/100\n",
      "892/892 [==============================] - 1s 771us/step - loss: 0.6645 - accuracy: 0.6388 - precision: 0.6716 - recall: 0.9121 - true_negatives: 39.0000 - true_positives: 1100.0000 - false_negatives: 106.0000 - false_positives: 538.0000 - val_loss: 0.6576 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 35/100\n",
      "892/892 [==============================] - 1s 744us/step - loss: 0.6560 - accuracy: 0.6534 - precision: 0.6740 - recall: 0.9444 - true_negatives: 26.0000 - true_positives: 1139.0000 - false_negatives: 67.0000 - false_positives: 551.0000 - val_loss: 0.6379 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 36/100\n",
      "892/892 [==============================] - 1s 730us/step - loss: 0.6612 - accuracy: 0.6461 - precision: 0.6748 - recall: 0.9204 - true_negatives: 42.0000 - true_positives: 1110.0000 - false_negatives: 96.0000 - false_positives: 535.0000 - val_loss: 0.6415 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 37/100\n",
      "892/892 [==============================] - 1s 742us/step - loss: 0.6619 - accuracy: 0.6472 - precision: 0.6720 - recall: 0.9345 - true_negatives: 27.0000 - true_positives: 1127.0000 - false_negatives: 79.0000 - false_positives: 550.0000 - val_loss: 0.6519 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 38/100\n",
      "892/892 [==============================] - 1s 743us/step - loss: 0.6616 - accuracy: 0.6450 - precision: 0.6704 - recall: 0.9345 - true_negatives: 23.0000 - true_positives: 1127.0000 - false_negatives: 79.0000 - false_positives: 554.0000 - val_loss: 0.6384 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 39/100\n",
      "892/892 [==============================] - 1s 753us/step - loss: 0.6657 - accuracy: 0.6427 - precision: 0.6717 - recall: 0.9229 - true_negatives: 33.0000 - true_positives: 1113.0000 - false_negatives: 93.0000 - false_positives: 544.0000 - val_loss: 0.6425 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 40/100\n",
      "892/892 [==============================] - 1s 738us/step - loss: 0.6515 - accuracy: 0.6607 - precision: 0.6767 - recall: 0.9544 - true_negatives: 27.0000 - true_positives: 1151.0000 - false_negatives: 55.0000 - false_positives: 550.0000 - val_loss: 0.7050 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 41/100\n",
      "892/892 [==============================] - 1s 760us/step - loss: 0.6505 - accuracy: 0.6635 - precision: 0.6756 - recall: 0.9668 - true_negatives: 17.0000 - true_positives: 1166.0000 - false_negatives: 40.0000 - false_positives: 560.0000 - val_loss: 0.6888 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 42/100\n",
      "892/892 [==============================] - 1s 764us/step - loss: 0.6512 - accuracy: 0.6601 - precision: 0.6746 - recall: 0.9610 - true_negatives: 18.0000 - true_positives: 1159.0000 - false_negatives: 47.0000 - false_positives: 559.0000 - val_loss: 0.7153 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 43/100\n",
      "892/892 [==============================] - 1s 768us/step - loss: 0.6644 - accuracy: 0.6472 - precision: 0.6750 - recall: 0.9229 - true_negatives: 41.0000 - true_positives: 1113.0000 - false_negatives: 93.0000 - false_positives: 536.0000 - val_loss: 0.6476 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 44/100\n",
      "892/892 [==============================] - 1s 761us/step - loss: 0.6602 - accuracy: 0.6500 - precision: 0.6732 - recall: 0.9378 - true_negatives: 28.0000 - true_positives: 1131.0000 - false_negatives: 75.0000 - false_positives: 549.0000 - val_loss: 0.7037 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 45/100\n",
      "892/892 [==============================] - 1s 788us/step - loss: 0.6614 - accuracy: 0.6534 - precision: 0.6725 - recall: 0.9502 - true_negatives: 19.0000 - true_positives: 1146.0000 - false_negatives: 60.0000 - false_positives: 558.0000 - val_loss: 0.6403 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 46/100\n",
      "892/892 [==============================] - 1s 755us/step - loss: 0.6627 - accuracy: 0.6472 - precision: 0.6735 - recall: 0.9287 - true_negatives: 34.0000 - true_positives: 1120.0000 - false_negatives: 86.0000 - false_positives: 543.0000 - val_loss: 0.7307 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 47/100\n",
      "892/892 [==============================] - 1s 744us/step - loss: 0.6572 - accuracy: 0.6590 - precision: 0.6744 - recall: 0.9585 - true_negatives: 19.0000 - true_positives: 1156.0000 - false_negatives: 50.0000 - false_positives: 558.0000 - val_loss: 0.6431 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 48/100\n",
      "892/892 [==============================] - 1s 766us/step - loss: 0.6514 - accuracy: 0.6467 - precision: 0.6692 - recall: 0.9444 - true_negatives: 14.0000 - true_positives: 1139.0000 - false_negatives: 67.0000 - false_positives: 563.0000 - val_loss: 0.6387 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 49/100\n",
      "892/892 [==============================] - 1s 743us/step - loss: 0.6582 - accuracy: 0.6629 - precision: 0.6787 - recall: 0.9527 - true_negatives: 33.0000 - true_positives: 1149.0000 - false_negatives: 57.0000 - false_positives: 544.0000 - val_loss: 0.7035 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 50/100\n",
      "892/892 [==============================] - 1s 748us/step - loss: 0.6576 - accuracy: 0.6506 - precision: 0.6747 - recall: 0.9337 - true_negatives: 34.0000 - true_positives: 1126.0000 - false_negatives: 80.0000 - false_positives: 543.0000 - val_loss: 0.6664 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 51/100\n",
      "892/892 [==============================] - 1s 752us/step - loss: 0.6564 - accuracy: 0.6534 - precision: 0.6754 - recall: 0.9386 - true_negatives: 33.0000 - true_positives: 1132.0000 - false_negatives: 74.0000 - false_positives: 544.0000 - val_loss: 0.6440 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 52/100\n",
      "892/892 [==============================] - 1s 744us/step - loss: 0.6540 - accuracy: 0.6556 - precision: 0.6745 - recall: 0.9486 - true_negatives: 25.0000 - true_positives: 1144.0000 - false_negatives: 62.0000 - false_positives: 552.0000 - val_loss: 0.6831 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 53/100\n",
      "892/892 [==============================] - 1s 738us/step - loss: 0.6595 - accuracy: 0.6394 - precision: 0.6693 - recall: 0.9229 - true_negatives: 27.0000 - true_positives: 1113.0000 - false_negatives: 93.0000 - false_positives: 550.0000 - val_loss: 0.7031 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 54/100\n",
      "892/892 [==============================] - 1s 732us/step - loss: 0.6539 - accuracy: 0.6590 - precision: 0.6782 - recall: 0.9436 - true_negatives: 37.0000 - true_positives: 1138.0000 - false_negatives: 68.0000 - false_positives: 540.0000 - val_loss: 0.6373 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 55/100\n",
      "892/892 [==============================] - 1s 741us/step - loss: 0.6617 - accuracy: 0.6472 - precision: 0.6733 - recall: 0.9295 - true_negatives: 33.0000 - true_positives: 1121.0000 - false_negatives: 85.0000 - false_positives: 544.0000 - val_loss: 0.6358 - val_accuracy: 0.6607 - val_precision: 0.6629 - val_recall: 0.9932 - val_true_negatives: 1.0000 - val_true_positives: 293.0000 - val_false_negatives: 2.0000 - val_false_positives: 149.0000\n",
      "Epoch 56/100\n",
      "892/892 [==============================] - 1s 739us/step - loss: 0.6565 - accuracy: 0.6495 - precision: 0.6728 - recall: 0.9378 - true_negatives: 27.0000 - true_positives: 1131.0000 - false_negatives: 75.0000 - false_positives: 550.0000 - val_loss: 0.6754 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 57/100\n",
      "892/892 [==============================] - 1s 741us/step - loss: 0.6587 - accuracy: 0.6517 - precision: 0.6722 - recall: 0.9469 - true_negatives: 20.0000 - true_positives: 1142.0000 - false_negatives: 64.0000 - false_positives: 557.0000 - val_loss: 0.7040 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 58/100\n",
      "892/892 [==============================] - 1s 754us/step - loss: 0.6597 - accuracy: 0.6483 - precision: 0.6722 - recall: 0.9370 - true_negatives: 26.0000 - true_positives: 1130.0000 - false_negatives: 76.0000 - false_positives: 551.0000 - val_loss: 0.6682 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 59/100\n",
      "892/892 [==============================] - 1s 736us/step - loss: 0.6534 - accuracy: 0.6478 - precision: 0.6731 - recall: 0.9320 - true_negatives: 31.0000 - true_positives: 1124.0000 - false_negatives: 82.0000 - false_positives: 546.0000 - val_loss: 0.6759 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 60/100\n",
      "892/892 [==============================] - 1s 754us/step - loss: 0.6506 - accuracy: 0.6556 - precision: 0.6731 - recall: 0.9544 - true_negatives: 18.0000 - true_positives: 1151.0000 - false_negatives: 55.0000 - false_positives: 559.0000 - val_loss: 0.6748 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 61/100\n",
      "892/892 [==============================] - 1s 731us/step - loss: 0.6562 - accuracy: 0.6523 - precision: 0.6728 - recall: 0.9461 - true_negatives: 22.0000 - true_positives: 1141.0000 - false_negatives: 65.0000 - false_positives: 555.0000 - val_loss: 0.7063 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 62/100\n",
      "892/892 [==============================] - 1s 735us/step - loss: 0.6629 - accuracy: 0.6500 - precision: 0.6736 - recall: 0.9362 - true_negatives: 30.0000 - true_positives: 1129.0000 - false_negatives: 77.0000 - false_positives: 547.0000 - val_loss: 0.6486 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 63/100\n",
      "892/892 [==============================] - 1s 741us/step - loss: 0.6601 - accuracy: 0.6472 - precision: 0.6754 - recall: 0.9212 - true_negatives: 43.0000 - true_positives: 1111.0000 - false_negatives: 95.0000 - false_positives: 534.0000 - val_loss: 0.6463 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 64/100\n",
      "892/892 [==============================] - 1s 774us/step - loss: 0.6571 - accuracy: 0.6523 - precision: 0.6713 - recall: 0.9519 - true_negatives: 15.0000 - true_positives: 1148.0000 - false_negatives: 58.0000 - false_positives: 562.0000 - val_loss: 0.6372 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 65/100\n",
      "892/892 [==============================] - 1s 737us/step - loss: 0.6539 - accuracy: 0.6500 - precision: 0.6734 - recall: 0.9370 - true_negatives: 29.0000 - true_positives: 1130.0000 - false_negatives: 76.0000 - false_positives: 548.0000 - val_loss: 0.6647 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 66/100\n",
      "892/892 [==============================] - 1s 737us/step - loss: 0.6553 - accuracy: 0.6601 - precision: 0.6754 - recall: 0.9577 - true_negatives: 22.0000 - true_positives: 1155.0000 - false_negatives: 51.0000 - false_positives: 555.0000 - val_loss: 0.6915 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 67/100\n",
      "892/892 [==============================] - 1s 740us/step - loss: 0.6531 - accuracy: 0.6534 - precision: 0.6740 - recall: 0.9444 - true_negatives: 26.0000 - true_positives: 1139.0000 - false_negatives: 67.0000 - false_positives: 551.0000 - val_loss: 0.6473 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 68/100\n",
      "892/892 [==============================] - 1s 741us/step - loss: 0.6541 - accuracy: 0.6551 - precision: 0.6768 - recall: 0.9378 - true_negatives: 37.0000 - true_positives: 1131.0000 - false_negatives: 75.0000 - false_positives: 540.0000 - val_loss: 0.6637 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 69/100\n",
      "892/892 [==============================] - 1s 756us/step - loss: 0.6549 - accuracy: 0.6590 - precision: 0.6767 - recall: 0.9494 - true_negatives: 30.0000 - true_positives: 1145.0000 - false_negatives: 61.0000 - false_positives: 547.0000 - val_loss: 0.6332 - val_accuracy: 0.6584 - val_precision: 0.6614 - val_recall: 0.9932 - val_true_negatives: 0.0000e+00 - val_true_positives: 293.0000 - val_false_negatives: 2.0000 - val_false_positives: 150.0000\n",
      "Epoch 70/100\n",
      "892/892 [==============================] - 1s 742us/step - loss: 0.6617 - accuracy: 0.6523 - precision: 0.6715 - recall: 0.9511 - true_negatives: 16.0000 - true_positives: 1147.0000 - false_negatives: 59.0000 - false_positives: 561.0000 - val_loss: 0.6434 - val_accuracy: 0.6607 - val_precision: 0.6622 - val_recall: 0.9966 - val_true_negatives: 0.0000e+00 - val_true_positives: 294.0000 - val_false_negatives: 1.0000 - val_false_positives: 150.0000\n",
      "Epoch 71/100\n",
      "892/892 [==============================] - 1s 740us/step - loss: 0.6615 - accuracy: 0.6433 - precision: 0.6723 - recall: 0.9221 - true_negatives: 35.0000 - true_positives: 1112.0000 - false_negatives: 94.0000 - false_positives: 542.0000 - val_loss: 0.6756 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 72/100\n",
      "892/892 [==============================] - 1s 740us/step - loss: 0.6527 - accuracy: 0.6568 - precision: 0.6759 - recall: 0.9461 - true_negatives: 30.0000 - true_positives: 1141.0000 - false_negatives: 65.0000 - false_positives: 547.0000 - val_loss: 0.6652 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 73/100\n",
      "892/892 [==============================] - 1s 750us/step - loss: 0.6585 - accuracy: 0.6584 - precision: 0.6776 - recall: 0.9444 - true_negatives: 35.0000 - true_positives: 1139.0000 - false_negatives: 67.0000 - false_positives: 542.0000 - val_loss: 0.6396 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 74/100\n",
      "892/892 [==============================] - 1s 745us/step - loss: 0.6600 - accuracy: 0.6506 - precision: 0.6740 - recall: 0.9362 - true_negatives: 31.0000 - true_positives: 1129.0000 - false_negatives: 77.0000 - false_positives: 546.0000 - val_loss: 0.6686 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 75/100\n",
      "892/892 [==============================] - 1s 737us/step - loss: 0.6593 - accuracy: 0.6579 - precision: 0.6751 - recall: 0.9527 - true_negatives: 24.0000 - true_positives: 1149.0000 - false_negatives: 57.0000 - false_positives: 553.0000 - val_loss: 0.6412 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 76/100\n",
      "892/892 [==============================] - 1s 748us/step - loss: 0.6563 - accuracy: 0.6568 - precision: 0.6743 - recall: 0.9527 - true_negatives: 22.0000 - true_positives: 1149.0000 - false_negatives: 57.0000 - false_positives: 555.0000 - val_loss: 0.6526 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 77/100\n",
      "892/892 [==============================] - 1s 752us/step - loss: 0.6570 - accuracy: 0.6551 - precision: 0.6764 - recall: 0.9395 - true_negatives: 35.0000 - true_positives: 1133.0000 - false_negatives: 73.0000 - false_positives: 542.0000 - val_loss: 0.6931 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 78/100\n",
      "892/892 [==============================] - 1s 733us/step - loss: 0.6536 - accuracy: 0.6528 - precision: 0.6713 - recall: 0.9536 - true_negatives: 14.0000 - true_positives: 1150.0000 - false_negatives: 56.0000 - false_positives: 563.0000 - val_loss: 0.6830 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 79/100\n",
      "892/892 [==============================] - 1s 741us/step - loss: 0.6582 - accuracy: 0.6618 - precision: 0.6783 - recall: 0.9511 - true_negatives: 33.0000 - true_positives: 1147.0000 - false_negatives: 59.0000 - false_positives: 544.0000 - val_loss: 0.6746 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 80/100\n",
      "892/892 [==============================] - 1s 751us/step - loss: 0.6561 - accuracy: 0.6534 - precision: 0.6746 - recall: 0.9420 - true_negatives: 29.0000 - true_positives: 1136.0000 - false_negatives: 70.0000 - false_positives: 548.0000 - val_loss: 0.7237 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 81/100\n",
      "892/892 [==============================] - 1s 749us/step - loss: 0.6637 - accuracy: 0.6450 - precision: 0.6729 - recall: 0.9245 - true_negatives: 35.0000 - true_positives: 1115.0000 - false_negatives: 91.0000 - false_positives: 542.0000 - val_loss: 0.6686 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 82/100\n",
      "892/892 [==============================] - 1s 744us/step - loss: 0.6534 - accuracy: 0.6562 - precision: 0.6762 - recall: 0.9436 - true_negatives: 32.0000 - true_positives: 1138.0000 - false_negatives: 68.0000 - false_positives: 545.0000 - val_loss: 0.6748 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 83/100\n",
      "892/892 [==============================] - 1s 739us/step - loss: 0.6611 - accuracy: 0.6601 - precision: 0.6754 - recall: 0.9577 - true_negatives: 22.0000 - true_positives: 1155.0000 - false_negatives: 51.0000 - false_positives: 555.0000 - val_loss: 0.6499 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 84/100\n",
      "892/892 [==============================] - 1s 748us/step - loss: 0.6553 - accuracy: 0.6517 - precision: 0.6744 - recall: 0.9378 - true_negatives: 31.0000 - true_positives: 1131.0000 - false_negatives: 75.0000 - false_positives: 546.0000 - val_loss: 0.6607 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 85/100\n",
      "892/892 [==============================] - 1s 742us/step - loss: 0.6585 - accuracy: 0.6528 - precision: 0.6761 - recall: 0.9345 - true_negatives: 37.0000 - true_positives: 1127.0000 - false_negatives: 79.0000 - false_positives: 540.0000 - val_loss: 0.6890 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 86/100\n",
      "892/892 [==============================] - 1s 743us/step - loss: 0.6603 - accuracy: 0.6495 - precision: 0.6730 - recall: 0.9370 - true_negatives: 28.0000 - true_positives: 1130.0000 - false_negatives: 76.0000 - false_positives: 549.0000 - val_loss: 0.7341 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 87/100\n",
      "892/892 [==============================] - 1s 750us/step - loss: 0.6640 - accuracy: 0.6540 - precision: 0.6748 - recall: 0.9428 - true_negatives: 29.0000 - true_positives: 1137.0000 - false_negatives: 69.0000 - false_positives: 548.0000 - val_loss: 0.6489 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 88/100\n",
      "892/892 [==============================] - 1s 762us/step - loss: 0.6534 - accuracy: 0.6511 - precision: 0.6722 - recall: 0.9453 - true_negatives: 21.0000 - true_positives: 1140.0000 - false_negatives: 66.0000 - false_positives: 556.0000 - val_loss: 0.6539 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 89/100\n",
      "892/892 [==============================] - 1s 770us/step - loss: 0.6556 - accuracy: 0.6540 - precision: 0.6750 - recall: 0.9420 - true_negatives: 30.0000 - true_positives: 1136.0000 - false_negatives: 70.0000 - false_positives: 547.0000 - val_loss: 0.6679 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 90/100\n",
      "892/892 [==============================] - 1s 771us/step - loss: 0.6701 - accuracy: 0.6354 - precision: 0.6691 - recall: 0.9121 - true_negatives: 33.0000 - true_positives: 1100.0000 - false_negatives: 106.0000 - false_positives: 544.0000 - val_loss: 0.6542 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 91/100\n",
      "892/892 [==============================] - 1s 754us/step - loss: 0.6522 - accuracy: 0.6584 - precision: 0.6778 - recall: 0.9436 - true_negatives: 36.0000 - true_positives: 1138.0000 - false_negatives: 68.0000 - false_positives: 541.0000 - val_loss: 0.6567 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 92/100\n",
      "892/892 [==============================] - 1s 761us/step - loss: 0.6536 - accuracy: 0.6523 - precision: 0.6761 - recall: 0.9328 - true_negatives: 38.0000 - true_positives: 1125.0000 - false_negatives: 81.0000 - false_positives: 539.0000 - val_loss: 0.6594 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 93/100\n",
      "892/892 [==============================] - 1s 742us/step - loss: 0.6594 - accuracy: 0.6551 - precision: 0.6756 - recall: 0.9428 - true_negatives: 31.0000 - true_positives: 1137.0000 - false_negatives: 69.0000 - false_positives: 546.0000 - val_loss: 0.6495 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 94/100\n",
      "892/892 [==============================] - 1s 745us/step - loss: 0.6576 - accuracy: 0.6483 - precision: 0.6708 - recall: 0.9428 - true_negatives: 19.0000 - true_positives: 1137.0000 - false_negatives: 69.0000 - false_positives: 558.0000 - val_loss: 0.6742 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 95/100\n",
      "892/892 [==============================] - 1s 754us/step - loss: 0.6611 - accuracy: 0.6528 - precision: 0.6719 - recall: 0.9511 - true_negatives: 17.0000 - true_positives: 1147.0000 - false_negatives: 59.0000 - false_positives: 560.0000 - val_loss: 0.6688 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 96/100\n",
      "892/892 [==============================] - 1s 762us/step - loss: 0.6560 - accuracy: 0.6523 - precision: 0.6732 - recall: 0.9444 - true_negatives: 24.0000 - true_positives: 1139.0000 - false_negatives: 67.0000 - false_positives: 553.0000 - val_loss: 0.6611 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 97/100\n",
      "892/892 [==============================] - 1s 725us/step - loss: 0.6537 - accuracy: 0.6506 - precision: 0.6724 - recall: 0.9428 - true_negatives: 23.0000 - true_positives: 1137.0000 - false_negatives: 69.0000 - false_positives: 554.0000 - val_loss: 0.6502 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 98/100\n",
      "892/892 [==============================] - 1s 743us/step - loss: 0.6560 - accuracy: 0.6590 - precision: 0.6746 - recall: 0.9577 - true_negatives: 20.0000 - true_positives: 1155.0000 - false_negatives: 51.0000 - false_positives: 557.0000 - val_loss: 0.6828 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 99/100\n",
      "892/892 [==============================] - 1s 747us/step - loss: 0.6608 - accuracy: 0.6483 - precision: 0.6745 - recall: 0.9279 - true_negatives: 37.0000 - true_positives: 1119.0000 - false_negatives: 87.0000 - false_positives: 540.0000 - val_loss: 0.6388 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n",
      "Epoch 100/100\n",
      "892/892 [==============================] - 1s 728us/step - loss: 0.6568 - accuracy: 0.6489 - precision: 0.6745 - recall: 0.9295 - true_negatives: 36.0000 - true_positives: 1121.0000 - false_negatives: 85.0000 - false_positives: 541.0000 - val_loss: 0.6427 - val_accuracy: 0.6629 - val_precision: 0.6629 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 295.0000 - val_false_negatives: 0.0000e+00 - val_false_positives: 150.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ffb05659d80>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sequential Neural Network\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# create a sequential model\n",
    "model1 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(img_height, img_width, 3)),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "metrics = [\n",
    "    'accuracy',\n",
    "    tf.keras.metrics.Precision(),\n",
    "    tf.keras.metrics.Recall(),\n",
    "    tf.keras.metrics.TrueNegatives(),\n",
    "    tf.keras.metrics.TruePositives(),\n",
    "    tf.keras.metrics.FalseNegatives(),\n",
    "    tf.keras.metrics.FalsePositives()\n",
    "]\n",
    "\n",
    "# compile the model\n",
    "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=metrics)\n",
    "\n",
    "\n",
    "# fit the model to the training data\n",
    "model1.fit(\n",
    "    train_ds,\n",
    "    epochs=100,\n",
    "    validation_data=validation_ds,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto Encoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Input Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the shape of the input layer\n",
    "input_shape = (None, 10) # Batch size is None, 10 features\n",
    "\n",
    "# Create the input layer\n",
    "input_layer = tf.keras.layers.Input(shape=input_shape)\n",
    "\n",
    "# Print information about the input layer\n",
    "print(\"Input layer shape:\", input_layer.shape)\n",
    "print(\"Input layer dtype:\", input_layer.dtype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 16 2D Convolutional Layers with a (2,2) kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# from tensorflow.keras.layers import Conv2D\n",
    "# from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "for i in range(16):\n",
    "    model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(2,2), activation='relu', padding='same'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Max Pooling 2D layer with a (2,2) kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "maxpool_layer = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 16 Convolutional 2D Transpose layers with a (3,3) kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# add 16 Convolutional 2D Transpose layers with a (3,3) kernel\n",
    "for i in range(16):\n",
    "    model.add(tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=(3,3), strides=(2,2), padding='same', activation='relu'))\n",
    "\n",
    "\n",
    "# build the model\n",
    "model.build(input_shape=(None, 64, 64, 3))\n",
    "\n",
    "# # compile the model\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# print the summary of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3 Convolutional 2D layers using a (2,2) kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=(2,2), activation='relu', input_shape=(None, None, 3)))\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(2,2), activation='relu'))\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(2,2), activation='relu'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gabungannya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 13:43:00.833283: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-04-05 13:43:04.461702: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x1c760a70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-04-05 13:43:04.461743: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3070 Laptop GPU, Compute Capability 8.6\n",
      "2023-04-05 13:43:04.465408: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-04-05 13:43:04.548987: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 54s 453ms/step - loss: 1.8323 - accuracy: 0.0000e+00 - val_loss: 1.0935 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "90/90 [==============================] - 37s 415ms/step - loss: 0.9104 - accuracy: 0.0000e+00 - val_loss: 0.6677 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "90/90 [==============================] - 37s 415ms/step - loss: 0.6573 - accuracy: 0.0000e+00 - val_loss: 0.6423 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "90/90 [==============================] - 37s 414ms/step - loss: 0.6386 - accuracy: 0.0000e+00 - val_loss: 0.6404 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "90/90 [==============================] - 37s 414ms/step - loss: 0.6465 - accuracy: 0.0000e+00 - val_loss: 0.6614 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "90/90 [==============================] - 37s 415ms/step - loss: 0.6600 - accuracy: 0.0000e+00 - val_loss: 0.8927 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "90/90 [==============================] - 37s 415ms/step - loss: 0.6761 - accuracy: 0.0000e+00 - val_loss: 0.6472 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "90/90 [==============================] - 37s 415ms/step - loss: 0.8306 - accuracy: 0.0000e+00 - val_loss: 0.6698 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "90/90 [==============================] - 37s 414ms/step - loss: 0.6507 - accuracy: 0.0000e+00 - val_loss: 0.6452 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "90/90 [==============================] - 37s 415ms/step - loss: 0.6467 - accuracy: 0.0000e+00 - val_loss: 0.6446 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7eff8c7a2530>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "filters = 25\n",
    "activation  = 'relu'\n",
    "input_shape = (None, None, 3)\n",
    "model2 = tf.keras.models.Sequential()\n",
    "model2.add(tf.keras.layers.Input(shape=input_shape)) # add input layer\n",
    "\n",
    "# 16 2D Convolutinal layers with a (2,2) kernel\n",
    "for i in range(16):\n",
    "    model2.add(tf.keras.layers.Conv2D(kernel_size=(2,2), filters=filters, activation=activation))\n",
    "\n",
    "model2.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2))) # Max Pooling 2D layer with a (2,2) kernel\n",
    "\n",
    "# 16 Convolutional 2D Transpose layers with a (3,3) kernel\n",
    "for i in range(16):\n",
    "    model2.add(tf.keras.layers.Conv2DTranspose(kernel_size=(3,3), filters=filters, activation=activation))\n",
    "\n",
    "# 3 Convolutional 2D layers using a (2,2) kernel\n",
    "for i in range(3):\n",
    "    model2.add(tf.keras.layers.Conv2D(kernel_size=(2,2), filters=filters, activation=activation))\n",
    "\n",
    "model2.add(tf.keras.layers.Flatten())\n",
    "\n",
    "\n",
    "# compile the model\n",
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# fut the model to the training data\n",
    "model2.fit(\n",
    "    train_ds,\n",
    "    epochs=10,\n",
    "    validation_data=validation_ds\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "botnet-image",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
